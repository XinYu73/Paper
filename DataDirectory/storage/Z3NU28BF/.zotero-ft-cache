Thermal Physics

Thermal Physics
Thermodynamics and Statistical Mechanics for Scientists and Engineers
Robert F. Sekerka
Carnegie Mellon University Pittsburgh, PA 15213, USA
AMSTERDAM • BOSTON • HEIDELBERG • LONDON • NEW YORK • OXFORD PARIS • SAN DIEGO • SAN FRANCISCO • SINGAPORE • SYDNEY • TOKYO

Elsevier Radarweg 29, PO Box 211, 1000 AE Amsterdam, Netherlands The Boulevard, Langford Lane, Kidlington, Oxford OX5 1GB, UK 225 Wyman Street, Waltham, MA 02451, USA
Copyright © 2015 Elsevier Inc. All rights reserved.
No part of this publication may be reproduced or transmitted in any form or by any means, electronic or mechanical, including photocopying, recording, or any information storage and retrieval system, without permission in writing from the publisher. Details on how to seek permission, further information about the Publisher’s permissions policies and our arrangements with organizations such as the Copyright Clearance Center and the Copyright Licensing Agency, can be found at our website: www.elsevier.com/permissions.
This book and the individual contributions contained in it are protected under copyright by the Publisher (other than as may be noted herein).
Notices Knowledge and best practice in this ﬁeld are constantly changing. As new research and experience broaden our understanding, changes in research methods, professional practices, or medical treatment may become necessary.
Practitioners and researchers must always rely on their own experience and knowledge in evaluating and using any information, methods, compounds, or experiments described herein. In using such information or methods they should be mindful of their own safety and the safety of others, including parties for whom they have a professional responsibility.
To the fullest extent of the law, neither the Publisher nor the authors, contributors, or editors, assume any liability for any injury and/or damage to persons or property as a matter of products liability, negligence or otherwise, or from any use or operation of any methods, products, instructions, or ideas contained in the material herein.
Library of Congress Cataloging-in-Publication Data A catalog record for this book is available from the Library of Congress
British Library Cataloguing in Publication Data A catalogue record for this book is available from the British Library
For information on all Elsevier publications visit our website at http://store.elsevier.com/
ISBN: 978-0-12-803304-3

Dedication
To Care . . . . who cared about every word
and helped me write what I meant to say rather than what I had written
v

Tableof Contents

About the Cover xv

Preface

XVII

PARTI Thermodynamic s
1 Intr oduct ion 1.1 Temper ature 1.2 Thermodynamics Versus Statistical Mechanics 1.3 Classification of State Variabl es 1.4 Energy in Mechanics 1.5 Elementary Kinetic Theory

2 First Law of Thermodynamics 2.1 Statement of the First Law 2.2 Quasistatic Work 2.3 Heat Capacities 2.4 Work Due to Expansion of an Ideal Gas 2.5 Enthalpy

3 Second Law of Thermod ynamics 3.1 Statement of the Second Law 3.2 Carnot Cycle and Engines 3.3 Calculation of th e Entropy Chang e 3.4 Combined First and Second Laws 3.5 Statistical Interpretation of Entrop y

•••••••••
1
3 3 5 6 8 12
15 15 17 19 24 28
31 32 35 39 41 47
vii

viii Table of Contents

4 Third Law of Thermodynamics

49

4.1 Statement of the Third Law

49

4.2 Implications of the Third Law

50

5 Open Systems

53

5.1 Single Component Open System

53

5.2 Mu lticomponent Open Systems

55

5.3 Euler Theorem of Homogeneous Functions

59

5.4 Chemical Potential of Real Gases, Fugacity

64

5.5 Legen dre Transformations

67

5.6 Partial Molar Quantities

71

5.7 Entropy of Chemical Reaction

75

6 Equilibrium and Thermodynamic Potentia ls

79

6.1 Entropy Criterion

79

6.2 Energy Criterion

84

6.3 Other Equilibrium Criteria

88

6.4 Summary of Criteria

92

7 Requirements for Stabi lity

95

7.1 Stability Requirements for Entrop y

95

7.2 Stability Requirements for Internal Energy

100

7.3 Stability Requirements for Other Potentials

102

7.4 Consequences of Stability Requiremen ts

105

7.5 Extension to Many Variables

106

7.6 Principles of Le Chatlier and Le Chatlier-Braun

107

8 Monocomponent Phase Equi librium

109

8.1 Clausius-Clapeyron Equation

110

8.2 Sketches of the Thermodynamic Function s

115

8.3 Phas e Diagram in th e v, p Plane

118

Table of Contents ix

9 Two -Phase Equilibrium for a van der Waa ls Fluid

121

9.1 van der Waals Equation of State

121

9.2 Thermodynamic Functions

124

9.3 Phase Equilibrium and Miscibility Gap

127

9.4 Gibbs Free Energy

131

10 Binary Solutions

137

10.1 Thermodynamics of Binary Solutions

137

10.2 Ideal Soluti ons

142

10.3 Phase Diagram for an Ideal Solid and an Ideal Liquid

145

10.4 Regular Solution

148

10.5 General Binary Solutions

153

11 Externa l Forces and Rotating Coordinate Systems

155

11.1 Conditions for Equilibrium

155

11.2 Uniform Gravitational Field

157

11.3 Non-Uniform Gravitational Field

164

11.4 Rotating Systems

164

11.5 Electric Fields

166

12 Chemica l Reactions

167

12.1 Reactions at Constant Volume or Pressure

168

12.2 Standard States

171

12.3 Equilibr ium and Affinity

173

12.4 Explicit Equilibrium Conditions

175

12.5 Simul taneous Reactions

182

13 Thermodynam ics of Fluid-Fluid Interf aces

185

13.1 Planar Interfaces in Fluids

186

13.2 Curved Interfaces in Flu ids

197

x Table of Contents
13.3 Interface Junctions and Contact Angles 13.4 Liquid Surface Shape in Gravity
14 Thermodynamics of Solid-Flu id Interfaces
14.1 Planar Solid-Fluid Interfaces 14.2 Anisotropy of y 14.3 Curved Solid-Fluid Interfaces 14.4 Faceting of a Large Planar Face 14.5 Equilibrium Shape from the~ -Vector 14.6 Herring Formula 14.7 Legendre Transform of the Equilibrium Shape 14.8 Remarks About Solid-Solid Interfaces
PART II Statistical Mechanics
15 Entropy and Information Theory
15.1 Entropy as a Measure of Disorder 15.2 Boltzmann Eta Theorem
16 Microcanonical Ensemble
16.1 Fundamenta l Hypothesis of Statistical Mechanics 16.2 Two-Stat e Subsystems 16.3 Harmonic Oscillators 16.4 Ideal Gas 16.5 Multicomponent Ideal Gas
17 Classical Microcanonical Ensemble
17.1 Liouville's Theorem 17.2 Classical Microcanonical Ensemble

202 205
2 15
216 22 1 227 233 236 240 241 242
245 247
247 251
257
258 261 265 267 273
277
278 280

Tab le of Contents xi

18 Distinguishable Part icles with Negligible

Interaction Energies

285

18.1 Derivation of the Boltzmann Distribution

285

18.2 Two-State Subsystems

289

18.3 Harmonic Oscillators

293

18.4 Rigid Linear Rotator

303

19 Canonical Ensemble

305

19. 1 Three Derivations

305

19.2 Factorizat ion Theorem

312

19.3 Classica l Idea l Gas

313

19.4 Maxwell-Boltzmann Distribution

317

19.5 Energy Dispersion

320

19.6 Paramagnetism

321

19.7 Partition Function and Densit y of States

330

20 Classical Canonical Ensemble

337

20.1 Classical Ideal Gas

338

20.2 Law of Dulong and Petit

342

20.3 Averaging Theorem and Equipartition

343

20.4 Virial Theorem

346

20.5 Virial Coefficients

348

20.6 Use of Canonical Transforma tions

354

20.7 Rotating Rigid Polya tomi c Molecu les

356

21 Grand Canonical Ensemble

359

21.1 Derivation from Microcanonical Ensemble

360

21.2 Ideal Systems: Orbitals and Factorization

368

xii Table of Contents

21.3 Classical Ideal Gas with Internal Structure

380

21.4 Multicomponent Systems

388

21.5 Pressure Ensemb le

389

22 Entropy for Any Ensemb le

397

22.1 General Ensemble

397

22.2 Summation over Energy Levels

402

23 Un ified Treatment of Idea l Fermi, Bose, and Classical Gases 405

23.1 Integr al Formulae

406

23.2 The Functions hv(A, a)

408

23.3 Virial Expansio ns for Ideal Fermi and Bose Gases

410

23.4 Heat Capacity

412

24 Bose Condensat ion

413

24.l Bosons at Low Temperatures

413

24.2 Thermodynamic Functions

416

24.3 Condensate Region

421

25 Degenerate Fermi Gas

425

25.1 Ideal Fermi Gas at Low Temperatures

425

25.2 Free Electron Model of a Metal

428

25.3 Thermal Activation of Electrons

429

25.4 Pauli Paramagnetism

433

25.5 Landau Diamagnetism

436

25.6 Thermionic Emission

439

25.7 Semiconductors

442

26 Quantum Statistics

451

26.1 Pure States

451

26.2 Statistical States

453

Table of Contents xiii

26.3 Random Phases and External Influ ence 26.4 Time Evoluti on 26.5 Densit y Operators for Specific Ensembles 26.6 Examp les of th e Density Matrix 26.7 Indi stinguishable Particles
27 Ising Model
27.1 Ising Mod el, Mean Fie ld Treatment 27.2 Pair Sta tistics 27.3 Soluti on in One Dimension for Zero Field 27.4 Transfer Matrix 27.5 Oth er Methods of Soluti on 27.6 Monte Carlo Simulation
PARTIll Appendices
A Stirl ing 's Approximation
A.l Elem entary Mot ivation ofEq. (A.l )
A.2 Asymptotic Series
B Use of Jacobians to Convert Partial Derivatives B.l Properties of Jacobians B.2 Connect ion to Thermody namic s
C Differential Geometry of Surfaces C.l Alterna tive Formulae for ~ Vector C.2 Sur face Differe nti al Geome try C.3 ~ Vector for Genera l Surfaces C.4 Herring Form ula
D Equi librium of Two-State Systems

454 455 456 459 465
469
470 477 479 480 483 484
495
497
498 499
503
503 504
509
509 511 516 518
523

xiv Table of Contents

E Aspects of Canonical Transformations

529

E.1 Necessary and Sufficient Conditions

530

E.2 Restricted Canonical Transformations

534

F Rotation of Rigid Bodies

537

El Moment oflnertia

537

F.2 Angular Momentum

539

F.3 Kinetic Energy

540

F.4 Time Derivatives

540

F.5 Rotating Coordinate System

541

F.6 Matrix Formulation

544

F.7 Canonical Variables

546

F.8 Quantum Energy Levels for Diatomic Molecule

547

G Thermodynamic Perturbation Theory

549

G.1 Classical Case

549

G.2 Quantum Case

550

H Selected Mathematical Relations

553

H.1 Bernoulli Numbers and Polynomials

553

H.2 Euler-Maclaur in Sum Formula

554

Creation and Annihilation Operators

559

1.1 Harmonic Oscillator

559

1.2 Boson Operators

560

1.3 Fermion Operators

562

1.4 Boson and Fermion Number Operators

563

References

565

Index

569

About the Cover
To represent the many scientists who have made major contributions to the foundations of thermodynamics and statistical mechanics, the cover of this book depicts four signiﬁcant scientists along with some equations and graphs associated with each of them.
• James Clerk Maxwell (1831-1879) for his work on thermodynamics and especially the kinetic theory of gases, including the Maxwell relations derived from perfect differentials and the Maxwell-Boltzmann Gaussian distribution of gas velocities, a precursor of ensemble theory (see Sections 5.2, 19.4, and 20.1).
• Ludwig Boltzmann (1844-1906) for his statistical approach to mechanics of many particle systems, including his Eta function that describes the decay to equilibrium and his formula showing that the entropy of thermodynamics is proportional to the logarithm of the number of microscopic realizations of a macrosystem (see Chapters 15–17).
• J. Willard Gibbs (1839-1903) for his systematic theoretical development of the thermodynamics of heterogeneous systems and their interfaces, including the deﬁnition of chemical potentials and free energy that revolutionized physical chemistry, as well as his development of the ensemble theory of statistical mechanics, including the canonical and grand canonical ensembles. The contributions of Gibbs are ubiquitous in this book, but see especially Chapters 5–8, 12–14, 17, 20, and 21.
• Max Planck (1858-1947, Nobel Prize 1918) for his quantum hypothesis of the energy of cavity radiation (hohlraum blackbody radiation) that connected statistical mechanics to what later became quantum mechanics (see Section 18.3.2); the Planck distribution of radiation ﬂux versus frequency for a temperature 2.725 K describes the cosmic microwave background, ﬁrst discovered in 1964 as a remnant of the Big Bang and later measured by the COBE satellite launched by NASA in 1989.
The following is a partial list of many others who have also made major contributions to the ﬁeld, all deceased. Recipients of a Nobel Prize (ﬁrst awarded in 1901) are denoted by the letter “N” followed by the award year. For brief historical introductions to thermodynamic and statistical mechanics, see Cropper [11, pp. 41-136] and Pathria and Beale [9, pp. xxi-xxvi], respectively. The scientists are listed in the order of their year of birth:
Sadi Carnot (1796-1832); Julius von Mayer (1814-1878); James Joule (1818-1889); Hermann von Helmholtz (1821-1894); Rudolf Clausius (1822-1888); William Thomson, Lord Kelvin (1824-1907); Johannes van der Waals (1837-1923, N1910); Jacobus van’t Hoff (1852-1911, N1901); Wilhelm Wien (1864-1928, N1911); Walther Nernst (18641941, N1920); Arnold Sommerfeld (1868-1951); Théophile de Donder (1872-1957); Albert
xv

xvi About the Cover
Einstein (1879-1955, N1921); Irving Langmuir (1881-1957, N1932); Erwin Schrödinger (1887-1961, N1933); Satyendra Bose (1894-1974); Pyotr Kapitsa (1894-1984, N1978); William Giauque (1895-1982, N1949); John van Vleck (1899-1980, N1977); Wolfgang Pauli (1900-1958, N1945); Enrico Fermi (1901-1954, N1938); Paul Dirac (1902-1984, N1933); Lars Onsager (1903-1976, N1968); John von Neumann (1903-1957); Lev Landau (19081968, N1962); Claude Shannon (1916-2001); Ilya Prigogine (1917-2003, N1977); Kenneth Wilson (1936-2013, N1982).

Preface
This book is based on lectures in courses that I taught from 2000 to 2011 in the Department of Physics at Carnegie Mellon University to undergraduates (mostly juniors and seniors) and graduate students (mostly ﬁrst and second year). Portions are also based on a course that I taught to undergraduate engineers (mostly juniors) in the Department of Metallurgical Engineering and Materials Science in the early 1970s. It began as class notes but started to be organized as a book in 2004. As a work in progress, I made it available on my website as a pdf, password protected for use by my students and a few interested colleagues.
It is my version of what I learned from my own research and self-study of numerous books and papers in preparation for my lectures. Prominent among these sources were the books by Fermi [1], Callen [2], Gibbs [3, 4], Lupis [5], Kittel and Kroemer [6], Landau and Lifshitz [7], and Pathria [8, 9], which are listed in the bibliography. Explicit references to these and other sources are made throughout, but the source of much information is beyond my memory.
Initially it was my intent to give an integrated mixture of thermodynamics and statistical mechanics, but it soon became clear that most students had only a cursory understanding of thermodynamics, having encountered only a brief exposure in introductory physics and chemistry courses. Moreover, I believe that thermodynamics can stand on its own as a discipline based on only a few postulates, or so-called laws, that have stood the test of time experimentally. Although statistical concepts can be used to motivate thermodynamics, it still takes a bold leap to appreciate that thermodynamics is valid, within its intended scope, independent of any statistical mechanical model. As stated by Albert Einstein in Autobiographical Notes (1946) [10]:
“A theory is the more impressive the greater the simplicity of its premises is, the more different kinds of things it relates, and the more extended is its area of applicability. Therefore the deep impression which classical thermodynamics made on me. It is the only physical theory of universal content concerning which I am convinced that within the framework of the applicability of its basic concepts, it will never be overthrown.”
Of course thermodynamics only allows one to relate various measurable quantities to one another and must appeal to experimental data to get actual values. In that respect, models based on statistical mechanics can greatly enhance thermodynamics by providing values that are independent of experimental measurements. But in the last analysis, any model must be compatible with the laws of thermodynamics in the appropriate limit of
xvii

xviii Preface
sufﬁciently large systems. Statistical mechanics, however, has the potential to treat smaller systems for which thermodynamics is not applicable.
Consequently, I ﬁnally decided to present thermodynamics ﬁrst, with only a few connections to statistical concepts, and then present statistical mechanics in that context. That allowed me to better treat reversible and irreversible processes as well as to give a thermodynamic treatment of such subjects as phase diagrams, chemical reactions, and anisotropic surfaces and interfaces that are especially valuable to materials scientists and engineers.
The treatment of statistical mechanics begins with a mathematical measure of disorder, quantiﬁed by Shannon [48, 49] in the context of information theory. This measure is put forward as a candidate for the entropy, which is formally developed in the context of the microcanonical, canonical, and grand canonical ensembles. Ensembles are ﬁrst treated from the viewpoint of quantum mechanics, which allows for explicit counting of states. Subsequently, classical versions of the microcanonical and canonical ensembles are presented in which integration over phase space replaces counting of states. Thus, information is lost unless one establishes the number of states to be associated with a phase space volume by requiring agreement with quantum treatments in the limit of high temperatures. This is counter to the historical development of the subject, which was in the context of classical mechanics. Later in the book I discuss the foundation of the quantum mechanical treatment by means of the density operator to represent pure and statistical (mixed) quantum states.
Throughout the book, a number of example problems are presented, immediately followed by their solutions. This serves to clarify and reinforce the presentation but also allows students to develop problem-solving techniques. For several reasons I did not provide lists of problems for students to solve. Many such problems can be found in textbooks now in print, and most of their solutions are on the internet. I leave it to teachers to assign modiﬁcations of some of those problems or, even better, to devise new problems whose solutions cannot yet be found on the internet.
The book also contains a number of appendices, mostly to make it self-contained but also to cover technical items whose treatment in the chapters would tend to interrupt the ﬂow of the presentation.
I view this book as an intermediate contribution to the vast subjects of thermodynamics and statistical mechanics. Its level of presentation is intentionally more rigorous and demanding than in introductory books. Its coverage of statistical mechanics is much less extensive than in books that specialize in statistical mechanics, such as the recent third edition of Pathria’s book, now authored by Pathria and Beale [9], that contains several new and advanced topics. I suspect the present book will be useful for scientists, particularly physicists and chemists, as well as engineers, particularly materials, chemical, and mechanical engineers. If used as a textbook, many advanced topics can be omitted to suit a one- or two-semester undergraduate course. If used as a graduate text, it could easily provide for a one- or two-semester course. The level of mathematics needed in most parts of the book is advanced calculus, particularly a strong grasp of functions of several

Preface xix
variables, partial derivatives, and inﬁnite series as well as an elementary knowledge of differential equations and their solutions. For the treatment of anisotropic surfaces and interfaces, necessary relations of differential geometry are presented in an appendix. For the statistical mechanics part, an appreciation of stationary quantum states, including degenerate states, is essential, but the calculation of such states is not needed. In a few places, I use the notation of the Dirac vector space, bras and kets, to represent quantum states, but always with reference to other representations; the only exceptions are Chapter 26, Quantum Statistics, where the Dirac notation is used to treat the density operator, and Appendix I, where creation and annihilation operators are treated.
I had originally considered additional information for this book, including more of my own research on the thermodynamics of inhomogeneously stressed crystals and a few more chapters on the statistical mechanical aspects of phase transformations. Treatment of the liquid state, foams, and very small systems were other possibilities. I do not address many-body theory, which I leave to other works. There is an introduction to Monte Carlo simulation at the end of Chapter 27, which treats the Ising model. The renormalization group approach is described brieﬂy but not covered in detail. Perhaps I will address some of these topics in later writings, but for now I choose not to add to the already considerable bulk of this work.
Over the years that I shared versions of this book with students, I received some valuable feedback that stimulated revision or augmentation of topics. I thank all those students. A few faculty at other universities used versions for self-study in connection with courses they taught, and also gave me some valuable feedback. I thank these colleagues as well. I am also grateful to my research friends and co-workers at NIST, where I have been a consultant for nearly 45 years, whose questions and comments stimulated a lot of critical thinking; the same applies to many stimulating discussions with my colleagues at Carnegie-Mellon and throughout the world. Singular among those was my friend and fellow CMU faculty member Prof. William W. Mullins who taught me by example the love, joy and methodologies of science. There are other people I could thank individually for contributing in some way to the content of this book but I will not attempt to present such a list. Nevertheless, I alone am responsible for any misconceptions or outright errors that remain in this book and would be grateful to anyone who would bring them to my attention.
In bringing this book to fruition, I would especially like to thank my wife Carolyn for her patience and encouragement and her meticulous proofreading. She is an attorney, not a scientist, but the logic and intellect she brought to the task resulted in my rewriting a number of obtuse sentences and even correcting a number of embarrassing typos and inconsistent notation in the equations. I would also like to thank my friends Susan and John of Cosgrove Communications for their guidance with respect to several aesthetic aspects of this book. Thanks are also due to the folks at my publisher Elsevier: Acquisitions Editor Dr. Anita Koch, who believed in the product and shepherded it through technical review, marketing and ﬁnance committees to obtain publication approval; Editorial Project Manager Amy Clark, who guided me though cover and format design as

xx Preface
well as the creation of marketing material; and Production Project Manager Paul Prasad Chandramohan, who patiently managed to respond positively to my requests for changes in style and ﬁgure placements, as well as my last-minute corrections. Finally, I thank Carnegie Mellon University for providing me with an intellectual home and the freedom to undertake this work.
Robert F. Sekerka Pittsburgh, PA

1
Introduction

Thermal physics deals with the quantitative physical analysis of macroscopic systems. Such systems consist of a very large number, N , of atoms, typically N ∼ 1023. According to classical mechanics, a detailed knowledge of the microscopic state of motion (say, position ri and velocity vi) of each atom, i = 1, 2, . . . , N , at some time t, even if attainable, would constitute an overwhelmingly huge database that would be practically useless. More useful quantities would be averages, such as the average kinetic energy of an atom in the system, which would be independent of time if the system were in equilibrium. We might also be interested in knowing such things as the volume V of the system or the pressure p that it exerts on the walls of a containing vessel. In other words, a useful description of a macroscopic system is necessarily statistical and consists of knowledge of a few macroscopic variables that describe the system to our satisfaction.
We shall be concerned primarily with macroscopic systems in a state of equilibrium. An equilibrium state is one whose macroscopic parameters, which we shall call state variables, do not change with time. We accept the proposition, in accord with our experience, that any macroscopic system subject to suitable constraints, such as conﬁnement to a volume and isolation from external forces or sources of matter and energy, will eventually come to a state of equilibrium. Our concept, or model, of the system will dictate the number of state variables that constitute a complete description—a complete set of state variables—of that system. For example, a gas consisting of a single atomic species might be described by three state variables, its energy U, its volume V , and its number of atoms N . Instead of its number of atoms, we usually avoid large numbers and specify its number of moles, N := N /N A where NA = 6.02×1023 molecules/mol is Avogadro’s number.1 The state of a gas consisting of two atomic species, denoted by subscripts 1 and 2, would require four variables, U, V , N1, and N2. A simple model of a crystalline solid consisting of one atomic species would require eight variables; these could be taken to be U, V , N , and ﬁve more variables needed to describe its state of shear strain.2

1.1 Temperature

A price we pay to describe a macroscopic system is the introduction of a state variable, known as the temperature, that is related to statistical concepts and has no counterpart in simple mechanical systems. For the moment, we shall regard the temperature to be an

1The notation A := B means A is deﬁned to be equal to B, and can be written alternatively as B =: A. 2This is true if the total number of unit cells of the crystal is able to adjust freely, for instance by means of vacancy diffusion; otherwise, a total of nine variables is required because one must add the volume per unit cell to the list of variables. More complex macroscopic systems require more state variables for a complete description, but usually the necessary number of state variables is small.

Thermal Physics. http://dx.doi.org/10.1016/B978-0-12-803304-3.00001-6

3

Copyright © 2015 Elsevier Inc. All rights reserved.

4 THERMAL PHYSICS

empirical quantity, measured by a thermometer, such that temperature is proportional to the expansion that occurs whenever energy is added to matter by means of heat transfer. Examples of thermometers include thermal expansion of mercury in a long glass tube, bending of a bimetallic strip, or expansion of a gas under the constraint of constant pressure. Various thermometers can result in different scales of temperature corresponding to the same physical states, but they can be calibrated to produce a correspondence. If two systems are able to freely exchange energy with one another such that their temperatures

are equal and their other macroscopic state variables do not change with time, they are said to be in equilibrium.
From a theoretical point of view, the most important of these empirical temperatures is the temperature θ measured by a gas thermometer consisting of a ﬁxed number of moles N of a dilute gas at volume V and low pressure p. This temperature θ is deﬁned to be proportional to the volume at ﬁxed p and N by the equation

θ := p V , RN

(1.1)

where R is a constant. For variable p, Eq. (1.1) also embodies the laws of Boyle, Charles, and Gay-Lussac. Provided that the gas is sufﬁciently dilute (small enough N /V ), experiment shows that θ is independent of the particular gas that is used. A gas under such conditions is known as an ideal gas. The temperature θ is called an absolute temperature because it is proportional to V , not just linear in V . If the constant R = 8.314 J/(mol K), then θ is measured in degrees Kelvin, for which one uses the symbol K. On this scale,

the freezing point of water at one standard atmosphere of pressure is 273.15 K. Later, in connection with the second law of thermodynamics, we will introduce a unique thermodynamic deﬁnition of a temperature, T, that is independent of any particular thermometer. Fermi [1, p. 42] uses a Carnot cycle that is based on an ideal gas as a working substance to show that T = θ, so henceforth we shall use the symbol T for the absolute temperature.3

Example Problem 1.1. The Fahrenheit scale ◦F, which is commonly used in the United States,
the United Kingdom, and some other related countries, is based on a smaller temperature interval. At one standard atmosphere of pressure, the freezing point of water is 32 ◦F and the boiling point of water is 212 ◦F. How large is the Fahrenheit degree compared to the Celsius degree?
The Rankine scale R is an absolute temperature scale but based on the Fahrenheit degree. At one standard atmosphere of pressure, what are the freezing and boiling points of water on the Rankine scale? What is the value of the triple point of water on the Rankine scale, the Fahrenheit scale and the Celsius scale? What is the value of absolute zero in ◦F?
3The Kelvin scale is deﬁned such that the triple point of water (solid-liquid-vapor equilibrium) is exactly 273.16 K. The Celsius scale, for which the unit is denoted ◦C, is deﬁned by T(◦C) = T(K) − 273.15.

Chapter 1 • Introduction 5
Solution 1.1. The temperature interval between the boiling and freezing points of water at one standard atmosphere is 100 ◦C or 212 − 32 = 180 ◦F. Therefore, 1 ◦F = 100/180 = 5/9 ◦C = (5/9) K. The freezing and boiling points of water are 273.15 × (9/5) = 491.67 R and 373.15 × (9/5) = 671.67 R. The triple point of water is 273.16 × (9/5) = 491.688 R = 32.018 ◦F = 0.01 ◦C. The value of absolute zero in ◦F is −(491.67 − 32) = −459.67 ◦F.
In the process of introducing temperature, we alluded to the intuitive concept of heat transfer. At this stage, it sufﬁces to say that if two bodies at different temperatures are brought into “thermal contact,” a process known as heat conduction can occur that enables energy to be transferred between the bodies even though the bodies exchange no matter and do no mechanical work on one another. This process results in a new equilibrium state and a new common temperature for the combined body. It is common to say that this process involves a “transfer of heat” from the hotter body (higher initial temperature) to the colder body (lower initial temperature). This terminology, however, can be misleading because a conserved quantity known as “heat” does not exist.4 We should really replace the term “transfer of heat” by the longer phrase “transfer of energy by means of a process known as heat transfer that does not involve mechanical work” but we use the shorter phrase for simplicity, in agreement with common usage. The ﬁrst law of thermodynamics will be used to quantify the amount of energy that can be transferred between bodies without doing mechanical work. The second law of thermodynamics will then be introduced to quantify the maximum amount of energy due to heat transfer (loosely, “heat”) that can be transformed into mechanical work by some process. This second law will involve a new state variable, the entropy S, which like the temperature is entirely statistical in nature and has no mechanical counterpart.
1.2 Thermodynamics Versus Statistical Mechanics
Thermodynamics is the branch of thermal physics that deals with the interrelationship of macroscopic state variables. It is traditionally based on three so-called laws (or a number of postulates that lead to the same results, see Callen [2, chapter 1]). Based on these laws, thermodynamics is independent of detailed models involving atoms and molecules. It results in criteria involving state variables that must be true of systems that are in equilibrium with one another. It allows us to develop relationships among measurable quantities (e.g., thermal expansion, heat capacity, compressibility) that can be represented by state variables and their derivatives. It also results in inequalities that must be obeyed by any naturally occurring process. It does not, however, provide values of the quantities with which it deals, only their interrelationship. Values must be provided by experiments or by models based on statistical mechanics. For an historical introduction to thermodynamics, see Cropper [11, p. 41].
4Such a quantity was once thought to exist and was called caloric.

6 THERMAL PHYSICS

Statistical mechanics is based on the application of statistics to large numbers of atoms (or particles) that obey the laws of mechanics, strictly speaking quantum mechanics, but in limiting cases, classical mechanics. It is based on postulates that relate certain types of averages, known as ensemble averages, to measurable quantities and to thermodynamic state variables, such as entropy mentioned above. Statistical mechanics can be used to rationalize the laws of thermodynamics, although it is based on its own postulates which were motivated by thermodynamics. By using statistical mechanics, speciﬁc models can be analyzed to provide values of the quantities employed by thermodynamics and measured by experiments. In this sense, statistical mechanics appears to be more complete; however, it must be borne in mind that the validity of its results depends on the validity of the models. Statistical mechanics can, however, be used to describe systems that are too small for thermodynamics to be applicable. For an excellent historical introduction to statistical mechanics, see Pathria and Beale [9, pp. xxi-xxvi].
A crude analogy with aspects of mathematics may be helpful here: thermodynamics is to statistical mechanics as Euclidean geometry is to analytic geometry and trigonometry. Given the few postulates of Euclidean geometry, which allow things such as lengths and angles to be compared but never measured, one can prove very useful and general theorems involving the interrelationships of geometric forms, for example, congruence, similarity, bisections, conditions for lines to be parallel or perpendicular, and conditions for common tangency. But one cannot assign numbers to these geometrical quantities. Analytic geometry and trigonometry provide quantitative measures of the ingredients of Euclidean geometry. These measures must be compatible with Euclidean geometry but they also supply precise information about such things as the length of a line or the size of an angle. Moreover, trigonometric identities can be quite complicated and transcend simple geometrical construction.

1.3 Classiﬁcation of State Variables

Much of our treatment will be concerned with homogeneous bulk systems in a state of
equilibrium. By bulk systems, we refer to large systems for which surfaces, either external
or internal, make negligible contributions. As a simple example, consider a sample in the shape of a sphere of radius R and having volume V = (4/3)πR3 and surface area A = 4πR2. If each atom in the sample occupies a volume a3, then for a R, the ratio of the number
of surface atoms to the number of bulk atoms is approximately

r

=

4π(R/a)2 (4/3)π(R/a)3 − 4π(R/a)2

∼

3(a/R)

1.

(1.2)

For a sufﬁciently large sphere, the number of surface atoms is completely negligible
compared to the number of bulk atoms, and so presumably is their energy and other properties. More generally, for a bulk sample having N atoms, roughly N 2/3 are near the surface, so the ratio of surface to bulk atoms is roughly r ∼ N −1/3. For a mole of atoms, we have N ∼ 6 × 1023 and r ∼ 10−8. In deﬁning bulk samples, we must be careful to

Chapter 1 • Introduction 7

exclude samples such as thin ﬁlms or thin rods for which one or more dimension is small compared to others. Thus, a thin ﬁlm of area L2 and thickness H L contains roughly N ∼ L2H/a3 atoms, but about 2L2/a2 of these are on its surfaces. Thus, the ratio of surface to bulk atoms is r ∼ a/H which will not be negligible for a sufﬁciently thin ﬁlm. We must also exclude samples that are ﬁnely subdivided, such as those containing many internal cavities.
From the considerations of the preceding paragraph, atoms of bulk samples can be regarded as being equivalent to one another, independent of location. It follows that certain state variables needed to describe such systems are proportional to the number of atoms. For example, for a homogeneous sample, total energy U ∝ N and total volume V ∝ N , provided we agree to exclude from consideration small values of N that would violate the idealization of a bulk sample.5 State variables of a homogeneous bulk thermodynamic system that are proportional to its number of atoms are called extensive variables. They are proportional to the “extent” or “size” of the sample. For a homogeneous gas consisting of three atomic species, a complete set of extensive state variables could be taken to be U, V , N1, N2, and N3, where the Ni are the number of moles of atomic species i.
There is a second kind of state variable that is independent of the “extent” of the sample. Such a variable is known as an intensive variable. An example of such a variable would be a ratio of extensive variables, say U/V , because both numerator and denominator are proportional to N . Another example of an intensive variable would be a derivative of some extensive variable with respect to some other extensive variable. This follows because a derivative is deﬁned to be a limit of a ratio, for example,

dU = lim U(V +

V ) − U(V ) .

dV

V →0

V

(1.3)

If other quantities are held constant during this differentiation, the result is a partial derivative ∂U/∂V , which is also an intensive variable, but its value will depend on which other variables are held constant. It will turn out that the pressure p, which is an intensive state variable, can be expressed as

p

=

−

∂U ∂V

(1.4)

provided that certain other variables are held constant; these variables are the entropy S, an extensive variable alluded to previously, as well as all other extensive variables of a remaining complete set. Another important intensive variable is the absolute temperature T, which we shall see can also be expressed as a partial derivative of U with respect to the entropy S while holding constant all other extensive variables of a remaining complete set.
Since the intensive variables are ratios or derivatives involving extensive variables, we will not be surprised to learn that the total number of independent intensive variables is one less than the total number of independent extensive variables. The total number of

5The symbol ∝ means “proportional to.”

8 THERMAL PHYSICS

independent intensive variables of a thermodynamic system is known as its number of degrees of freedom, usually a small number which should not be confused with the huge number of microscopic degrees of freedom 6N for N particles that one would treat by classical statistical mechanics.
In Chapter 5, we shall return to a systematic treatment of extensive and intensive variables and their treatment via Euler’s theorem of homogeneous functions.

1.4 Energy in Mechanics
The concept of energy is usually introduced in the context of classical mechanics. We review such considerations brieﬂy in order to shed light on some aspects of energy that will be important in thermodynamics.

1.4.1 Single Particle in One Dimension

A single particle of mass m moving in one dimension, x, obeys Newton’s law

d2x m dt2

=

F,

(1.5)

where t is the time and F(x) is the force acting on the particle when it is at position x. We

introduce the potential energy function

x
V (x) = − F(u) du,
x0

(1.6)

which is the negative of the work done by the force on the particle when the particle moves from some position x0 to position x. Then the force F = −dV /dx can be written in terms of the derivative of this potential function. We multiply Eq. (1.5) by dx/dt

to obtain

dx m
dt

d2x dt 2

+

dV dx

dx dt

=

0,

(1.7)

which can be rewritten as

d 1 mv 2 + V = 0, dt 2

(1.8)

where the velocity v := dx/dt. Equation (1.8) can then be integrated to obtain

1 mv 2 + V = E, 2

(1.9)

where E is independent of time and known as the total energy. The ﬁrst term in Eq. (1.9) is known as the kinetic energy and the equation states that the sum of the kinetic and potential energy is some constant, independent of time. It is important to note, however, that the value of E is undetermined up to an additive constant. This arises as follows: If some constant V0 is added to the potential energy V (x) to form a new potential V˜ := V +V0, the same force results because

Chapter 1 • Introduction 9

− dV˜ dx

= − d (V dx

+

V0)

=

−

dV dx

= F.

(1.10)

Thus, Eq. (1.9) could equally well be written

1 mv 2 + V˜ = E˜ , 2

(1.11)

where E˜ is a new constant. Comparison of Eq. (1.11) with Eq. (1.9) shows that E˜ = E + V0,

so the total energy shifts by the constant amount V0. Therefore, only differences in energy

have physical meaning; to obtain a numerical value of the energy, one must always

measure energy relative to some well-deﬁned state of the particle or, what amounts to

the same thing, adopt the convention that the energy in some well-deﬁned state is equal

to zero. In view of Eq. (1.6), the potential energy V (x) will be zero when x = x0, but the

choice of x0 is arbitrary. In classical mechanics, it is possible to consider more general force laws such as F(x, t)

in which case the force at point x depends explicitly on the time that the particle is at point x. In that case, we can obtain (d/dt)(1/2)mv 2 = Fv where Fv is the power supplied

by the force. Similar considerations apply for forces of the form F(x, v , t) that can depend

explicitly on velocity as well as time. In such cases, one must solve the problem explicitly

for the functions x(t) and v (t) before the power can be evaluated. In these cases, the total

energy of the system changes with time and it is not possible to obtain an energy integral

as given by Eq. (1.9).

1.4.2 Single Particle in Three Dimensions

The preceding one-dimensional treatment can be generalized to three dimensions with a

few modiﬁcations. In three dimensions, where we represent the position of a particle by the vector r with Cartesian coordinates x, y, and z, Eq. (1.5) takes the form

d2r m dt2

=

F,

(1.12)

where F(r) is now a vector force at the point r. The mechanical work done by the force on

the particle along a speciﬁed path leading from rA to rB is now given by

Wr A to r B =

F · dr. path

According to the theorem of Stokes, one has

(1.13)

(∇ × F) · dA = F · dr, closed loop,

(1.14)

where the integral on the right is a line integral around a closed loop and the integral on the left is over an area that subtends that loop. For a force such that ∇ × F = 0, we see that the line integral around any closed loop is equal to zero. Thus, if we integrate from A to B along path 1 and from B back to A along some other path 2 we get zero. But the latter integral is just the negative of the integral from A to B along path 2, so the integral from A to B is the same along path 1 as along path 2. For such a force, it follows that the work

10 THERMAL PHYSICS

rB
WAB = F · dr, any path,
rA

(1.15)

is independent of path and depends only on the end points. Such a force is called a conservative force and may be represented as the gradient of a potential

r
V (r) = − F(r ) · dr
r0
such that F = −∇V . In this case, it follows that the work

(1.16)

rB

rB

WAB = − ∇V · dr = − dV = V (rA) − V (rB).

rA

rA

(1.17)

For such a conservative force, we can dot the vector v := dr/dt into Eq. (1.12) to obtain

dr m
dt

·

d2r dt 2

+

dr dt

·

∇V

=

0.

(1.18)

Then by noting that

d

dr d2r

dV dr

(1/2)m v dt

·

v

=

m dt

·

dt 2

and

= · ∇V, dt dt

(1.19)

we are led immediately to Eq. (1.8) and its energy integral Eq. (1.9) just as in one dimension, except now v 2 = v · v in the kinetic energy.

1.4.3 System of Particles

We next consider a system of particles, k = 1, 2, . . . , N , having masses mk, positions rk, and velocities vk = drk/dt. Each particle is assumed to be subjected to a conservative force

Fk = −∇kV (r1, r2, . . . , rN ),

(1.20)

where ∇k is a gradient operator that acts only on rk. Then by writing Newton’s equations in the form of Eq. (1.12) for each value of k, summing over k and proceeding as above, we obtain

d [T + V ] = 0, dt

(1.21)

where the total kinetic energy

T :=

N

1 2

mk vk

·

vk

k=1

(1.22)

and

dV dt

=

N

drk dt

· ∇kV .

k=1

(1.23)

Furthermore, we can suppose that the forces on each particle can be decomposed into internal forces Fi due to the other particles in the system and to external forces Fe, that is,

Chapter 1 • Introduction 11

F = Fi + Fe. Since these forces are additive, we also have a decomposition of the potential, V = V i + V e, into internal and external parts. The integral of Eq. (1.21) can therefore be
written in the form

T + Vi + Ve = E,

(1.24)

where E is the total energy constant. This suggests a related decomposition of T which we proceed to explore.
We introduce the position vector of the center of mass of the system of particles, deﬁned by

R := 1 M

N

mk rk ,

k=1

(1.25)

where M :=

N k=1

mk

is

the

total

mass

of

the

system.

The

velocity

of

the

center

of

mass

is

V := dR = 1 dt M

N

mk vk .

k=1

(1.26)

The kinetic energy relative to the center of mass, namely T i, can be written

T i :=

1 2

N

mk(vk − V) · (vk − V) = T

− 1 MV 2. 2

k=1

(1.27)

Eq. (1.27) may be veriﬁed readily by expanding the left-hand side to obtain four terms and then using Eq. (1.26). The term (1/2)MV 2 is recognized as the kinetic energy associated with motion of the center of mass of the system. Equation (1.24) can therefore be written

T i + V i + 1 MV 2 + V e = E. 2

(1.28)

The portion of this energy exclusive of the kinetic energy of the center of mass and the external forces, namely U = T i + V i, is an internal energy of the system of particles and is the energy usually dealt with in thermodynamics. Thus, when energies of a thermody-
namic system are compared, they are compared under the assumption that the state of overall motion of the system, and hence its overall motional kinetic energy, (1/2)MV 2, is unchanged. This is equivalent to supposing that the system is originally at rest and
remains at rest. Moreover, it is usually assumed that there are no external forces so the interaction energy V e is just a constant. Thus, the energy integral is usually viewed in the
form

U

=:

T

i

+

Vi

=

E

−

1 MV 2 2

−

Ve

=:

U0,

(1.29)

where U0 is a new constant. If such a system does interact with its environment, U is no longer a constant. Indeed, if the system does work or if there is heat transfer from its environment, U will change according to the ﬁrst law of thermodynamics, which is taken up in Chapter 2.

12 THERMAL PHYSICS

Sometimes one chooses to include conservative external forces in the energy used in thermodynamics. Such treatments require the use of a generalized energy that includes potential energy due to conservative external forces, such as those associated with gravity or an external electric ﬁeld. In that case, one deals with the quantity

U˜ =: T i + V i + V e = E − 1 MV 2. 2

(1.30)

In terms of chemical potentials, which we shall discuss in Chapter 12, such external forces give rise to gravitational chemical potentials and electrochemical potentials that play the role [6, p. 122] of intrinsic chemical potentials when external ﬁelds are present. It is also possible to treat uniformly rotating coordinate systems by including in the thermodynamic energy the effective potential associated with ﬁctitious centrifugal forces [7, p. 72].

1.5 Elementary Kinetic Theory

More insight into the state variables temperature T and pressure p can be gained by considering the elementary kinetic theory of gases. We consider a monatomic ideal gas having particles of mass m that do not interact and whose center of mass remains at rest. Its kinetic energy is

T

=1 2

N

m drk dt

· drk dt

=1 2

N

mv2k .

k=1

k=1

(1.31)

If the gas is in equilibrium, the time average T of this kinetic energy is a constant. This kinetic energy represents the vigor of motion of the atoms, so it is natural to suppose that it increases with temperature because temperature can be increased by adding energy due to heat transfer. A simple and fruitful assumption is to assume that T is proportional to the temperature. In particular, we postulate that the time average kinetic energy per atom is related to the temperature by6

1T N

=

1 2N

N

mv2k

=

3 2 kBT ,

k=1

(1.32)

where kB is a constant known as Boltzmann’s constant. In fact, kB = R/NA where R is the gas constant introduced in Eq. (1.1) and NA is Avogadro’s number. We shall see that Eq. (1.32) makes sense by considering the pressure of an ideal gas.
The pressure p of an ideal gas is the force per unit area exerted on the walls of a containing box. For simplicity, we treat a monatomic gas and assume for now that each atom of the gas has the same speed v , although we know that there is really a distribution of speeds given by the Maxwell distribution, to be discussed in Chapter 19. We consider

6If the center of mass of the gas were not at rest, Eq. (1.27) would apply and T would have to be replaced by T i. In other words, the kinetic energy (1/2)MV 2 of the center of mass makes no contribution to the temperature.

Chapter 1 • Introduction 13

an inﬁnitesimal area dA of a wall perpendicular to the x direction and gas atoms with velocities that make an angle of θ with respect to the positive x direction. In a time dt, all atoms in a volume v dt dA cos θ will strike the wall at dA, provided that 0 < θ < π/2. Each atom will collide with the wall with momentum m v cos θ and be reﬂected with the same momentum,7 so each collision will contribute a force (1/dt)2m v cos θ , which is the
time rate of change of momentum. The total pressure (force per unit area) is therefore

p= 1 2

n(v dt dA cos θ)(2m v cos θ) dA dt

= nm v 2 cos2 θ

= nm vx2 ,

(1.33)

where n is the number of atoms per unit volume and the angular brackets denote an
average over time and all θ. The factor of 1/2 arises because of the restriction 0 < θ < π/2. Since the gas is isotropic, vx2 = vy2 = vz2 = (1/3) v 2 . Therefore,8

p

=

1 nm

v2

3

=

2T 3nN

=

nkB T

=

NR T,
V

(1.34)

where Eq. (1.32) has been used. Equation (1.34) is the well-known ideal gas law, in agreement with Eq. (1.1) if the absolute temperature is denoted by T. In the case of an ideal gas, all of the internal energy is kinetic, so the total internal energy is U = T . Eq. (1.34) therefore leads to p = (2/3)(U/V ), which is also true for an ideal monatomic gas.

These simple relations from elementary kinetic theory are often used in thermodynamic examples and are borne out by statistical mechanics.

7Reﬂection with the same momentum would require specular reﬂection from perfectly reﬂecting walls, but
irrespective of the nature of actual walls, one must have reﬂection with the same momentum on average to avoid
a net exchange of energy. 8If we had accounted for a Maxwell distribution of speeds, this result would still hold provided that we
interpret v 2 to be an average of the square of the velocity with respect to that distribution. See Eqs. (20.28-20.30)
for details.

2
First Law of Thermodynamics

The ﬁrst law of thermodynamics extends the concept of energy from mechanical systems to thermodynamic systems, speciﬁcally recognizing that a process known as heat transfer can result in a transfer of energy to the system in addition to energy transferred by mechanical work. We ﬁrst state the law and then discuss the terminology used to express it. As stated below, the law applies to a chemically closed system, by which we mean that the system can exchange energy with its environment by means of heat transfer and work but cannot exchange mass of any chemical species with its environment. This deﬁnition is used by most chemists; many physicists and engineers use it as well but it is not universal. Some authors, such as Callen [2] and Chandler [12], regard a closed system as one that can exchange nothing with its environment. In this book, we refer to a system that can exchange nothing with its environment as an isolated system.

2.1 Statement of the First Law

For a thermodynamic system, there exists an extensive function of state, U, called the internal energy. Every equilibrium state of a system can be described by a complete set of (macroscopic) state variables. The number of such state variables depends on the complexity of the system and is usually small. For now we can suppose that U depends on the temperature T and additional extensive state variables needed to form a complete set.1 Alternatively, any equilibrium state can be described by a complete set of extensive state variables that includes U. For a chemically closed system, the change U from an initial to a ﬁnal state is equal to the heat, Q, added to the system minus the work, W, done by the system, resulting in2

U = Q − W.

(2.1)

Q and W are not functions of state because they depend on the path taken during the process that brings about the change, not on just the initial and ﬁnal states. Eq. (2.1)

1There are other possible choices of a complete set of state variables. For example, a homogeneous isotropic ﬂuid composed a single chemical component can be described by three extensive variables, the internal energy U, the volume V , and the number of moles N. One could also choose state variables T, V , and N and express U as a function of them, and hence a function of state. Alternatively, U could be expressed as a function of T, the pressure p, and N. In Chapter 3, we introduce an extensive state variable S, the entropy, in which case U can be expressed as a function of a complete set of extensive variables including S, known as a fundamental equation.
2In agreement with common usage, we use the terminology “heat transferred to the system” or “heat added to the system” in place of the longer phrase “energy transferred to the system by means of a process known as heat transfer that does not involve mechanical work.”

Thermal Physics. http://dx.doi.org/10.1016/B978-0-12-803304-3.00002-8

15

Copyright © 2015 Elsevier Inc. All rights reserved.

16 THERMAL PHYSICS

actually deﬁnes Q, since U and W can be measured independently, as will be discussed in detail in Section 2.1.1.
If there is an inﬁnitesimal amount of heat δQ transferred to the system and the system does an inﬁnitesimal amount of work δW, the change in the internal energy is

dU = δQ − δW, inﬁnitesimal change.

(2.2)

For an isolated system, U = 0, and for such a system, the internal energy is a constant.

2.1.1 Discussion of the First Law
As explained in Chapter 1, the term internal energy usually excludes kinetic energy of motion of the center of mass of the entire macroscopic system, as well as energy associated with overall rotation (total angular momentum). The internal energy also usually excludes the energy due to the presence of external ﬁelds, although it is sometimes redeﬁned to include conservative potentials. We will only treat thermodynamic systems that are at rest with respect to the observer (zero kinetic energy due to motion of the center of mass or total angular momentum). For further discussion of this point, see Landau and Lifshitz [7, p. 34].
We emphasize that W is positive if work is done by the system on its environment. Many authors, however, state the ﬁrst law in terms of the work W = −W done by the environment on the system by some external agent. In this case, the ﬁrst law would read
U = Q + W . This is especially common3 in Europe [14] and Russia [7]. The symbol applied to any state function means the value of that function in the ﬁnal
state (after some process) minus the value of that function in the initial state. Speciﬁcally, U := U(ﬁnal state) − U(initial state). As mentioned above, Q and W are not state
functions, although their difference is a state function. As will be illustrated below, Q and W depend on the details of the process used to change the state function U. In other words, Q and W depend on the path followed during a process. Therefore, it makes no sense to apply the symbol or the differential symbol d to Q or W. We use δQ and δW to denote inﬁnitesimal transfers of energy to remind ourselves that Q and W are not state functions. Some authors [6, 12] use a d with a superimposed strikethrough (d) instead of δ.
The ﬁrst law of thermodynamics is a theoretical generalization based on many experiments. Particularly noteworthy are the experiments of Joule who found that for two states of a closed thermodynamic system, say A and B, it is always possible to cause a transition that connects A to B by a process in which the system is thermally insulated, so δQ = 0 at every stage of the process. This also means that Q = 0 for the whole process.

3Fermi [1] uses the symbol L for the work done by the system; note that the Italian word for work is ‘lavoro’ (cognate labor). The introductory physics textbook by Young and Freedman [13] also states the ﬁrst law of thermodynamics in terms of the work done by the system. Landau and Lifshitz [7] use the symbol R ≡ −W (‘rabota’) to denote the work done on the system. Chandler [12] and Kittel and Kroemer [6] use W ≡ −W to denote the work done on the system. This matter of notation and conventions can cause confusion, but we have to live with it.

Chapter 2 • First Law of Thermodynamics 17

Thus by work alone, either the transformation A → B or the transformation B → A is possible. Since the energy change due to work alone is well deﬁned in terms of mechanical concepts, it is possible to establish either the energy difference UA − UB or its negative UB − UA. The fact that one of these transformations might be impossible is related to concepts of irreversibility, which we will discuss later in the context of the second law of thermodynamics.
According to the ﬁrst law, as recognized by Rudolf Clausius in 1850, heat transfer accounts for energy received by the system in forms other than work. Since U can be measured and W can be determined for any mechanical process, Q is actually deﬁned by Eq. (2.1). It is common to measure the amount of energy due to heat transfer in units of calories. One calorie is the amount of heat necessary to raise the temperature of one gram (10−3 kg) of water from 14 ◦C to 15 ◦C at standard atmospheric pressure. The mechanical equivalent of this heat is 1 calorie = 4.184 J = 4.184 × 107 erg. The amount of heat required to raise the temperature by T of an arbitrary amount of water is proportional to its mass.
It was once believed that heat was a conserved quantity called caloric, and hence the unit calorie, but no such conserved quantity exists. This discovery is usually attributed to Count Rumford who noticed that water used to cool a cannon during boring would be brought to a boil more easily when the boring tool became dull, resulting in even less removal of metal. Thus, “heat” appears to be able to be produced in virtually unlimited amounts by doing mechanical work, and thus cannot be a conserved quantity. Therefore, we must bear in mind that heat transfer refers to a process for energy transfer and that there is actually no identiﬁable quantity, “heat,” that is transported. From an atomistic point of view, we can think of conducted heat as energy transferred by means of microscopic atomic or molecular collisions in processes that occur without the transfer of matter and without changing the macroscopic physical boundaries of the system under consideration. Heat can also be transferred by radiation that is emitted or absorbed by a system.
We can enclose a system of interest and a heat source of known heat capacity (see Section 2.3) by insulation to form a calorimeter, assumed to be an isolated system, and allow the combined system to come to equilibrium. The temperature change of the heat source will allow determination of the amount of energy transferred from it (or to it) by means of heat transfer and this will equal the increase (or decrease) in energy of the system of interest.4

2.2 Quasistatic Work

If a thermodynamic system changes its volume V by an amount dV and does work against an external pressure pext, it does an inﬁnitesimal amount of work

δW = pext dV .

(2.3)

4If the heat source changes volume, it could exchange work with its environment and this would have to be taken into account.

18 THERMAL PHYSICS

This external pressure can be established by purely mechanical means. For example, an external force Fext acting on a piston of area A would give rise to an external pressure pext = Fext/A. Note that Eq. (2.3) is valid for a ﬂuid system even if the process being considered is so rapid and violent that an internal pressure of the system cannot be deﬁned during the process. This equation can also be generalized for a more complex system as long as one uses actual mechanical external forces and the distances through which they displace portions of the system, for example, pushing on part of the system by a rod or pulling on part of a system by a rope.
If an isotropic system (same in all directions, as would be true for a ﬂuid, a liquid or a gas) expands or contracts sufﬁciently slowly (hence the term “quasistatic”) that the system is practically in equilibrium at each instant of time, it will have a well-deﬁned internal pressure p. Under such conditions, p ≈ pext and the system will do an inﬁnitesimal amount of work

δW = p dV , quasistatic work.

(2.4)

Note that δW and dV are positive if work is done by the system and both are negative if work is done on the system by an external agent.
Eq. (2.4) applies only to an idealized process. For an actual change to take place, we need p to be at least slightly different from pext to provide a net force in the proper direction. This requires (p − pext) dV > 0. Thus pext dV < p dV which, in view of Eq. (2.3), may be written

δW < p dV , actual process.

(2.5)

For the case of quasistatic work, it will be necessary for p to be slightly greater than pext for the system to expand (dV > 0); conversely, it will be necessary for p to be slightly less than pext for the system to contract. These small differences are assumed to be second order and are ignored in writing Eq. (2.4). Consistent with this idealization, a process of
quasistatic expansion can be reversed to a process of quasistatic contraction by making an inﬁnitesimal change in p. Therefore, quasistatic work is also called reversible work.5
We can combine Eq. (2.4) with Eq. (2.5) to obtain

δW ≤ p dV

(2.6)

with the understanding that the inequality applies to all actual processes (which are irreversible) and the equality applies to the idealized process of reversible quasistatic work.
For a ﬁnite change of V , the quasistatic work can be computed by integration:

W=

p dV , quasistatic work.

path

(2.7)

To evaluate this integral, we must specify the path that connects the initial and ﬁnal states of the system. It makes no sense to write this expression with lower and upper limits of

5A process involving quasistatic work will be reversible only if all other processes that go on in the system are reversible. For example, an irreversible chemical reaction would be forbidden.

Chapter 2 • First Law of Thermodynamics 19

V2, p2 II

p

I V1, p1

V1

V

V2

FIGURE 2–1 Illustration of quasistatic work for a system whose states can be represented by points in the V , p plane. The system makes a quasistatic transition from a state at V1, p1 to a state V2, p2 by two different paths, I and II. According to Eq. (2.7), the quasistatic work is the area under each curve and is obviously greater for path II. The difference in work is the area between the paths. Since U for the two paths is the same, the difference in the heat Q for the two paths is also equal to the area between the paths.

integration unless the path is clearly speciﬁed. For a system whose equilibrium states can be represented by points in the V , p plane, the quasistatic work is represented by the area under the curve that represents the path that connects the initial and ﬁnal states, as illustrated in Figure 2–1. Since the areas under two curves that connect the same two end points can be different, the quasistatic work W clearly depends on the path. Since Q = U + W and U is independent of path, Q also depends on path.
If work and heat are exchanged with a system, it is important to recognize that the internal energy of the system will not be partitioned in any way that allows part of it to be associated with heat and part with work. That is because work and heat refer to processes for changing the energy of a system and lose their identity once equilibrium is attained and the energy of the system is established. On the other hand, other state variables of the system can differ depending on the relative amounts of heat and work that bring about the same change of internal energy. For example, consider two alternative processes in which the internal energy of an ideal gas is increased by exactly the same amount, the ﬁrst by means of only work done by a constant external pressure pext and the second by means of only heat transfer. In the case of only work, the volume of the gas will necessarily be decreased but in the case of only heat transfer, the volume of the system will not be changed. Therefore, the two processes result in different thermodynamic states, even though both result in the same internal energy.

2.3 Heat Capacities

We can deﬁne heat capacities for changes in which the work done by the system is the quasistatic work given by Eq. (2.4). In that case, the ﬁrst law takes the form

dU = δQ − p dV .

(2.8)

20 THERMAL PHYSICS

The heat capacity at constant volume, CV , is deﬁned to be the ratio of the inﬁnitesimal amount of heat δQ needed to raise the temperature by an inﬁnitesimal amount dT while holding the volume constant, namely

CV :=

δQ = dT V

∂U

∂T

,
V

(2.9)

where the last expression, a partial derivative at constant volume, follows from Eq. (2.8).
The heat capacity is an extensive quantity and should not be confused with the speciﬁc heat, which is the heat capacity per unit mass, which is intensive.6

The heat capacity at constant pressure, Cp, is deﬁned to be the ratio of the inﬁnitesimal amount of heat δQ needed to raise the temperature by an inﬁnitesimal amount dT

while holding the pressure constant, namely

Cp :=

δQ = dT p

∂U ∂T

+p
p

∂V ∂T

,
p

(2.10)

where the last expression again follows from Eq. (2.8). Note that the partial derivatives of

U in Eqs. (2.9) and (2.10) are not the same because different variables are held constant.

Thus

∂U ∂T

=
p

∂U ∂T

+
V

∂U ∂V T

∂V ∂T

.
p

(2.11)

Example Problem 2.1. The speciﬁc heat of silver at 20 ◦C is 0.0558 cal g−1 K−1. Here we
ignore the small difference between constant volume and constant pressure for this condensed phase. What is the heat capacity of 3 kg of silver? How many Joules of energy are needed to raise the temperature of 3 kg of silver from 15 ◦C to 25 ◦C?
Solution 2.1. The heat capacity of 3 kg of silver is 3000 × 0.0558 = 167 cal K−1. The temperature interval is 10 K so the energy required is 1670 cal × 4.184 J/cal = 6990 J. We only keep three signiﬁcant ﬁgures because the speciﬁc heat was only given to three ﬁgures.

2.3.1 Heat Capacity of an Ideal Gas

One mole of an ideal gas obeys the equation of state

pV = RT , one mole of ideal gas,

(2.12)

where T is the absolute temperature and R is the gas constant. Equation (2.12) is essentially a deﬁnition of an ideal gas, based on experiments for real dilute gases that obey Eq. (1.1) that was used to deﬁne the empirical temperature θ. For such a real dilute gas, Joule conducted experiments in which the gas was conﬁned originally to a subvolume V1 of an insulated rigid container having overall volume V2. The remainder of the volume, V2 − V1 was initially evacuated (see Figure 3–2). In these experiments, Q = 0 because the

6Analogous intensive quantities such as the heat capacity per atom, per molecule, or per mole are often used.

Chapter 2 • First Law of Thermodynamics 21

container is insulated and W = 0 because the overall container having volume V2 is rigid. Therefore, by the ﬁrst law, the internal energy U remains constant. In the experiments, the gas was allowed to expand internally from V1 to V2. Joule observed that the temperature T of the gas remained practically unchanged during the process. More accurate experiments were performed later by Thomson (Lord Kelvin) and Joule by causing the gas to expand through a porous plug until a steady state is reached and measuring the temperature of the exiting gas directly. For hydrogen, there was hardly appreciable change in temperature; see the treatise by Planck [15, p. 50] for details. Therefore, the internal energy of such a dilute gas is practically independent of its volume. For an ideal gas, we shall assume that U is strictly independent of its volume, V , and therefore only a function of T. We shall see later that this conclusion can be derived by applying the second law of thermodynamics for a gas that obeys Eq. (2.12).7
Therefore, for an ideal gas, the second term on the right-hand side of Eq. (2.11) is zero. The second term on the right of Eq. (2.10) can be evaluated by means of Eq. (2.12), resulting in8

Cp = CV + R, one mole of ideal gas.

(2.13)

We observe that Cp is larger than CV by an amount needed to supply the work p dV done by the gas as it expands at constant pressure. The value of CV depends on the type of gas under consideration and can be derived by means of statistical mechanics. For a mole of gas, we shall see that each translational or rotational degree of freedom of a gas molecule, made up of atoms that are considered to be point particles, contributes an amount R/2 to CV . For a monatomic gas, each atom has three translational degrees of freedom, translation along x, y, and z, so CV = 3R/2. A diatomic gas molecule would have six total degrees of freedom (three translational degrees for each atom) but the distance of separation of the two atoms remains practically constant due to strong chemical bonds. The atoms of a diatomic gas can execute vibrations along the line joining them, but these vibrations are hardly excited except at very high temperatures.9 Thus only ﬁve degrees of freedom are usually active (three translational and two rotational) and CV = 5R/2 for a diatomic gas. Similarly, if we neglect vibrational degrees of freedom for polyatomic gases, six degrees of freedom are usually active (three translational and three rotational) and CV = 3R. This leads to the values listed in Table 2–1.

7By calculating derivatives of the entropy, it can be shown that dU = CV dT + (Tα/κT − p)dV , where α is the isobaric compressibility and κ is the isothermal compressibility. From the ideal gas law, α = 1/T and β = 1/p, so the coefﬁcient of dV vanishes and U depends only on T.
8As deﬁned by Eqs. (2.9) and (2.10), the heat capacities CV and Cp are extensive. Thus they depend not only on the substance under consideration but also on the amount of that substance. One can obtain intensive quantities
by dividing by the number of moles or the mass. These intensive quantities depend only on the substance under
consideration. Here we deal with one mole, which is equivalent to dividing the extensive heat capacities by the
number of moles being considered. 9If partially excited, the contribution of a vibrational degree of freedom would depend on temperature. If fully
excited, a vibrational degree of freedom would contribute R/2 for kinetic energy and R/2 for potential energy, for a total of R. Polyatomic gases with linear molecules behave somewhat like diatomic molecules insofar as rotational
degrees of freedom are concerned. See Section 21.3 for a detailed discussion of ideal gases with internal structure.

22 THERMAL PHYSICS

Table 2–1 Heat Capacities per Mole of Ideal Gases

Molecule

CV

Cp

γ = Cp/CV

monatomic diatomic polyatomic

3R/2 5R/2 3R

5R/2 7R/2 4R

5/3 ≈ 1.67 7/5 = 1.40 4/3 ≈ 1.33

It is assumed that the atoms are point particles, translational and rotational degrees of freedom are totally excited, and vibrational degrees of freedom of diatomic and polyatomic gases are not excited.

2.3.2 General Relationship of Cp to CV
By means of a general result of thermodynamics, it will turn out that Cp is always larger than CV . For the moment, we state this result without proof but will derive it after we cover the second and third laws of thermodynamics. First, we need to deﬁne two other measurable quantities: isobaric coefﬁcient of thermal expansion:

isothermal compressibility:

α := 1 V

∂V

∂T

,
p

κT

:=

−1 V

∂V

∂p

.
T

(2.14) (2.15)

The signs in Eqs. (2.14) and (2.15) have been chosen so that κT is positive and α is usually positive.10 The general result (see Eq. (5.32)) is

Cp

=

CV

+

TV α2 κT .

(2.16)

From the form of Eq. (2.16), we observe that Cp ≥ CV for any substance, which is not obvious from their deﬁnitions. From stability considerations, it will be shown in Section 7.4 that Cp ≥ CV ≥ 0. For an ideal gas, we readily calculate from Eq. (2.12) that α = 1/T and κT = 1/p, in which case Eq. (2.16) becomes Eq. (2.13) for N = 1 mole of gas. For condensed phases, |α| 1/T and κT 1/p, but the second term in Eq. (2.16) is quadratic in α so the difference between Cp and CV is very small. Thus, the difference between Cp and CV is very important for gases but small and often negligible for liquids and solids.

10This agrees with our intuition and with experiment. It can be proven from general thermodynamic stability considerations (see Chapter 7) that κT is positive. α is usually positive but negative values of α are possible, for example, for water below about 4 ◦C.

Chapter 2 • First Law of Thermodynamics 23

Example Problem 2.2. The equation of state for one mole of a van der Waals ﬂuid is
(p + a/v 2)(v − b) = RT ,

where p is the pressure, v is the volume per mole, T is the temperature, and a and b are constants. Calculate the following quantities and show that they agree with the results for an ideal gas in the limit a = b = 0:
(a) The isothermal compressibility, κT = −(1/v )(∂v /∂p)T (b) The isobaric coefﬁcient of thermal expansion, α = (1/v )(∂v /∂T )p (c) The molar heat capacity difference, (Cp − CV )/N (d) Show directly that (∂p/∂T )v = α/κT . Why is this true?
Solution 2.2. We ﬁrst take the differential of the given equation to obtain

dp

v −b +

p

−

a v2

+

2ab v3

dv = R dT.

(a)

κT

=

−

1 v

∂v ∂p

=1 Tv

v −b

p−

a v2

+

2ab v3

−1 → 1 p

for an ideal gas,

(b)

α

=

1 v

∂v ∂T

p

=

R v

p

−

a v2

+

2ab v3

−1
→

R pv

=

1 T

for an ideal gas,

(c)

(Cp − CV )/N

=

Tvα2 κT

=

R2T v −b

p−

a v2

+

2ab v3

−1

→

R2T pv

=R

for an ideal gas,

(d)

∂p ∂T

v

=

v

R −

b

=

−

∂v ∂T

/
p

∂v ∂p

T

=

α κT

.

This relation is generally true, not just true for the van der Waals ﬂuid, as can be seen from the differential

dv =

∂v ∂T

dT +
p

∂v

∂p

dp.
T

24 THERMAL PHYSICS

2.4 Work Due to Expansion of an Ideal Gas

We calculate the work due to expansion of one mole of an ideal gas that obeys the equation of state Eq. (2.12). For simplicity, we will further assume that the gas has a constant heat capacity CV at constant volume. According to Eq. (2.9), this results in

dU = CV dT ; U = CV T + constant.

(2.17)

2.4.1 Reversible Isothermal Process

For a reversible isothermal process, the path in the V , p plane is an equilateral hyperbola, pV = constant, where the value of the constant depends on T. We assume that this path joins two states that satisfy p1V1 = p2V2, so the quasistatic work is

W=

p dV = RT T= constant

V2 V1

dV V

= RT ln(V2/V1),

one mole.

(2.18)

For V2 > V1 the gas expands and does positive work, as shown in Figure 2–2. For the reverse transformation from V2 to V1, the gas contracts and does negative work; in this case, the environment of the gas does positive work on the gas. Since U depends only on T, we have U1 = U2 so U = 0. Therefore, by the ﬁrst law, Q = W for this process.

2.4.2 Reversible Isobaric Expansion Followed by Isochoric Transformation

We assume the path to be a reversible expansion from V1 to V2 at constant pressure p1 (isobaric expansion) followed by lowering the pressure to p2 at constant volume V2 (isochoric transformation). This is illustrated by the dashed line in Figure 2–3. The quasistatic work is

V2

V2

W = p1

dV +

p dV = p1(V2 − V1)

V1

V2

(2.19)

because the second integral is zero. The temperature will change throughout this process.
In general, the end points will have different temperatures, T1 = p1V1/R and T2 = p2V2/R, and the change in internal energy will be U = CV (T2 − T1). If the end points happen to satisfy p1V1 = p2V2, then T1 = T2, but during the process T will not be constant. In general, Q = U + W, but if T1 = T2, then U = 0 and Q = W. Then the work given by Eq. (2.19) can also be written as RT1(V2 − V1)/V1 = RT2(V2 − V1)/V1 and is greater than that given by Eq. (2.18) with T = T1 = T2. The reader is invited to prove this statement mathematically.

2.4.3 Isochoric Transformation Followed by Reversible Isobaric Expansion
We assume the path to consist of lowering the pressure to p2 at constant volume V1 followed by reversible expansion from V1 to V2 at constant pressure p2. This is illustrated by the dot-dashed line in Figure 2–3. The quasistatic work is

Chapter 2 • First Law of Thermodynamics 25

V1, p1 p

V1, p1 p

V2, p2

V1

V

V2

FIGURE 2–2 Illustration of quasistatic work for isothermal expansion of one mole of an ideal gas. The system makes a quasistatic transition from a state at V1, p1 to a state V2, p2 such that pV = RT . The work done by the gas is equal to the area under the curve.

V2, p2

V1

V

V2

FIGURE 2–3 Illustration of quasistatic work for one mole of an ideal gas. The dashed line represents
an isobaric expansion at pressure p1 followed by an isochoric transformation at V2. The dot-dashed line represents an isochoric transformation at V1 followed by an isobaric transformation at pressure p2. The full line represents an isothermal transformation from V1, p1 to V2, p2, which is only possible if V1p1 = V2p2.

V1

V2

W=

p dV + p2

dV = p2(V2 − V1),

V1

V1

(2.20)

which is clearly smaller than that given by Eq. (2.19). If the end points happen to be at the same temperature, the work given by Eq. (2.20) can be written RT1(V2 − V1)/V2 = RT2(V2 − V1)/V2 and is less than that given by Eq. (2.18) with T = T1 = T2.

2.4.4 Reversible Adiabatic Expansion

We assume that the gas is perfectly insulated from its surroundings so that δQ = 0 at each stage of the process. Such processes are called adiabatic processes.11 We allow the
gas to expand quasistatically, and therefore reversibly, from a state V2, p2 to a state V3, p3. Applying the ﬁrst law to each stage of this process gives

CV dT = −p dV ,

(2.21)

which by Eq. (2.12) may be rewritten in the form

dT CV T

+ R dV V

= 0,

one mole of ideal gas.

(2.22)

11Some authors use the word adiabatic to mean that δQ = 0 and that the process is reversible, but we use adiabatic to mean only δQ = 0. An irreversible adiabatic process is illustrated in Section 2.4.5. See Eq. (3.13) for the entropy change of an adiabatic process.

26 THERMAL PHYSICS

Taking the logarithmic derivative of Eq. (2.12) gives dT/T = dp/p + dV /V which allows Eq. (2.22) to be recast in the form

CV

dp p

+

(CV

+ R) dV V

= 0.

(2.23)

Eq. (2.23) is a differential equation for the path in the V , p plane. It can be integrated to

give

ln p + γ ln V = constant,

(2.24)

where γ := (CV + R)/CV = Cp/CV > 1. Exponentiating Eq. (2.24) gives a more usual form

pV γ = p2V2γ = p3V3γ = K = constant.

(2.25)

The path of the system is represented by the solid line in Figure 2–4. The quasistatic work

is therefore

W =K

V3 V −γ dV = K V 1−γ

V3
=

V2

1 − γ V2

p3V3 − p2V2 1−γ

= CV (T2 − T3).

(2.26)

We have labored to produce this result which, however, could have been derived simply by applying the ﬁrst law with Q = 0 to give W = − U = −CV (T3 − T2). Nevertheless, we see clearly how the quasistatic work integral depends on path.
Just as Eq. (2.23) is a differential equation for the path in the V , p plane, Eq. (2.22) is the differential equation of the path in the T, V plane. It could be integrated directly, but the same result can be obtained by substitution of Eq. (2.12) into Eq. (2.25) to obtain

TV γ −1 = constant.

(2.27)

V2, p2 p

V3, p3 V3 V

V3∗, p3 V3∗

FIGURE 2–4 The solid line represents a reversible adiabatic expansion for one mole of an ideal gas for γ = 5/3.
The dotted line represents, for the sake of comparison, an isothermal expansion from the same initial state. The point at V3∗, p3 is the ﬁnal state for an irreversible adiabatic expansion at constant external pressure p3. In this irreversible case, the system starts in the state V2, p2, “leaves the page” as it progresses through non-equilibrium states, and “reenters the page,” ultimately coming to equilibrium at the state V3∗, p3, which is represented by a circled point.

Chapter 2 • First Law of Thermodynamics 27

Note that γ − 1 = R/CV , consistent with Eq. (2.22). Similarly,

T p(γ −1)/γ

= constant.

(2.28)

2.4.5 Irreversible Adiabatic Expansion

Here again we assume that the gas is perfectly insulated from its surroundings so that δQ = 0 at each stage of the process. We start out at the same state V2, p2 as for the reversible adiabatic process treated above, but we allow the gas to expand suddenly

against a constant reduced external pressure p3 that is chosen to have the same value as p3 for the ﬁnal state of the reversible adiabatic expansion considered above. During this expansion, the pressure of the gas is not well-deﬁned, so we cannot represent this process
by a path in Figure 2–4. Because this process is irreversible, it will come to equilibrium in a state having temperature T3∗ and volume V3∗ different from those for the reversible case. The work done will be W = p3(V3∗ − V2) and the change in internal energy will be
U = CV (T3∗ − T2). Since Q = 0 we will have W = − U, which becomes

p3(V3∗ − V2) = CV (T2 − T3∗).

(2.29)

By using Eq. (2.12), we can write p3V3∗ = RT3∗ and p3V2 = RT2p3/p2, in which case Eq. (2.29) can be written in the form

T3∗ T2

=

CV + R p3/p2 CV + R

= 1 − q + qr,

(2.30)

where r := p3/p2 and q := (γ − 1)/γ . In this same notation, Eq. (2.28) for the reversible adiabatic expansion leads to

T3 = rq. T2 We shall see that T3∗ > T3. This is illustrated in Figure 2–5.

(2.31)

1.4 1.2

T3∗/T2 T3/T2

0.5

1r

1.5

2

0.8

0.6
FIGURE 2–5 Graphs of T3/T2 for a reversible adiabatic process, Eq. (2.30), and T3∗/T2 for an irreversible adiabatic process, Eq. (2.31), versus r = p3/p2 for q = 2/5, which corresponds to γ = 5/3. The straight line corresponds to T3∗/T2 and shows that T3∗ > T3 for r = 1.

28 THERMAL PHYSICS

We ﬁrst note for r = 1 that T3∗ = T3 = T2 as expected. Then we take derivatives with respect to r to obtain

d T3∗ = q; d T3 = qrq−1.

dr T2

dr T2

(2.32)

These derivatives are also equal for r = 1, so the curve represented by Eq. (2.31) is tangent

to the line represented by Eq. (2.30) at r = 1. Since q − 1 = −1/γ is negative, we see that the slope of a graph of T3∗ versus r is less than that of T3 versus r for any r < 1. Moreover, the slope of a graph of T3∗ versus r is greater than that of T3 versus r for any r > 1. Hence, T3∗ > T3 for any r = 1, which means that the irreversible adiabatic expansion results in a ﬁnal state with greater temperature than the reversible adiabatic expansion. The same

would be true for contraction, in which case V3 < V2 and r > 1. For the end points of the two processes, Eq. (2.12) can be written p3V3 = RT3 and p3V3∗ = RT3∗. Taking the ratio of
these equations gives

V3∗ = T3∗ . V3 T3

(2.33)

From this result, we see that V3∗ > V3. In summary, irreversible adiabatic expansion or contraction against a constant external pressure p3 results in a different ﬁnal state (larger temperature and volume) than a reversible adiabatic expansion to a ﬁnal state12 having

pressure p3.

2.5 Enthalpy

The enthalpy (sometimes called the heat function) is deﬁned by H := U + pV .

(2.34)

Since U, p, and V are all functions of state, H is also a function of state. In general,

dH = dU + p dV + V dp.

(2.35)

For quasistatic work such that Eq. (2.8) holds, Eq. (2.35) becomes

dH = δQ + V dp.

(2.36)

By combining Eqs. (2.10) and (2.36), we obtain

Cp :=

δQ = dT p

∂H ∂T

.
p

(2.37)

12The ﬁnal state depends on the details of the irreversible process. Here we have considered only a speciﬁc case and demonstrated that the ﬁnal state is different from that for a reversible adiabatic process. Later we shall introduce a new state variable S, the entropy, in which case it can be shown that the entropy change for a reversible adiabatic process is zero but that for an irreversible adiabatic process is positive.

Chapter 2 • First Law of Thermodynamics 29

Comparison of Eq. (2.37) with Eq. (2.9) shows that H plays the same role at constant p as U does at constant V . We will see that this role is very general after developing the second law and studying Legendre transformations. In essence, the dependence of U on V is replaced by the dependence of H on p. Thus, if Q = 0 and W = 0, we have U = 0, so energy is conserved and U is a constant. From Eq. (2.36) we see that for δQ = 0 and constant p we have dH = 0, so H is a constant. Actually, a less restrictive condition than constant p sufﬁces for ﬁnite changes. If Q = 0 and the only work done by the system is against a pressure reservoir with constant pressure pr, the ﬁrst law gives U = −pr V which can be written in the form

(U + prV ) = 0.

(2.38)

Then if p = pr in the initial and ﬁnal states of the system, Eq. (2.38) becomes H = 0; Q = 0 and p = pr in initial and ﬁnal states.

(2.39)

Example Problem 2.3. We saw above that the internal energy, U, of an ideal gas was inde-
pendent of volume, V , and therefore only a function of temperature, T . Use this information together with the deﬁnition of H to show that ∂H/∂p T = 0, which means that the enthalpy of an ideal gas is a function of only the temperature, T .
Solution 2.3. We take the partial derivative of Eq. (2.34) while holding T constant to obtain

∂H = ∂U

∂V + V + p ∂V .

∂p T

∂V T ∂p T

∂p T

(2.40)

For an ideal gas, (∂U/∂V )T = 0 so the ﬁrst term on the right vanishes. From the ideal gas law V = NRT /p we obtain

∂V ∂p

T

=

−

NRT p2

= −V . p

Hence the last two terms on the right of Eq. (2.40) cancel, and we are left with

(2.41)

∂H ∂p

= 0,
T

ideal gas.

(2.42)

Actually, Eq. (2.42) follows from more elementary considerations. Substitution of the ideal gas law into Eq. (2.34) for one mole gives H = U(T ) + RT , so we see immediately that H depends only on T . Differentiation with respect to T gives our former result Cp = CV + R.

Example Problem 2.4. As heat is supplied to ice at temperature 0 ◦C and atmospheric
pressure, the ice melts to become water, still at its melting point 0 ◦C, until all of the ice has
melted. The heat needed to melt the ice is 80 cal/g. How much does the enthalpy change if one

30 THERMAL PHYSICS

mole of ice is melted? Show that this is equivalent to an effective heat capacity that is a Dirac delta function at the melting point.
What would you have to know to calculate the corresponding change of the internal energy U and what would that change be?

Solution 2.4. Integration of Eq. (2.36) at constant p gives an enthalpy change H = Q. One mole of ice has a mass of 18 g, so H = 18 g/mol × 80 cal/g = 1440 cal/mol. Since the temperature does not change during melting, an effective heat capacity can be deﬁned formally by

Cpeff = H δ(T − TM),

(2.43)

where TM is the melting point and δ(T − TM) is the Dirac delta function. Equation (2.43) can be justiﬁed by integration from TM − to TM + . From a different perspective, a graph of H versus T has a discontinuous step at TM whose formal derivative is a delta function. See Section 3.4.1 for a more thorough discussion.
From Eq. (2.15) at constant p we obtain U = H − p V so we would have to know
V to evaluate U. We can estimate V as follows: The volume of ice shrinks about 9% on melting and its density is about 1 g/cm3. So for one mole, V ≈ −0.09 × 1 cm3/g × 18 g/mol = −1.6 cm3/mol = −1.6 × 10−6 m3/mol. One standard atmosphere is p = 1.01 × 105 N/m2. Thus p V = −0.16 J/mol = −0.04 cal/mol, which is a negligible correction. So U ≈ H for melting
of ice. This is typical for melting of condensed phases. On the other hand, for the water-steam transition, V ≈ 2.24 × 10−2 m3/mol, roughly 1000 times larger in magnitude than for melting.
So for evaporation, p V ≈ 6 cal/mol. But for the evaporation transition, H = 9720 cal/mol so
the difference between U and H is larger but still practically negligible.

3
Second Law of Thermodynamics

Even though the ﬁrst law of thermodynamics is obeyed, there are additional limitations on processes that can occur naturally. The second law of thermodynamics deals quantitatively with these limitations and is expressed in terms of an inequality that is obeyed by changes of a new state function, the entropy S, which is postulated to exist. These limitations are due to the fact that all natural processes in thermodynamic systems are irreversible. The boundary between natural processes and processes that are forbidden by thermodynamics can be characterized in terms of idealized processes that are reversible. For an idealized reversible process, which is hypothetical, the entropy change obeys an equality and this allows the entropy change to be calculated. If a system, by virtue of suitable constraints, is such that all natural processes are forbidden by the second law, it is in a state of thermodynamic equilibrium. This leads to a criterion for thermodynamic equilibrium in terms of the entropy.
Historically, the entropy function was discovered by studying limitations that occur during the process of transformation of heat into work, even though energy is conserved. Theoretically, these processes were imagined to be accomplished by engines that exchange heat with external heat sources, do mechanical work, and return to their original thermodynamic state after each cycle. These processes were assumed to obey the following postulates [1, p. 30]:
Postulate of Kelvin: “A transformation whose only ﬁnal result is to transfer into work heat extracted from a source which is at the same temperature throughout is impossible.”

Postulate of Clausius: “A transformation whose only ﬁnal result is to transfer heat from a body at a given temperature to a body at a higher temperature is impossible.”
These historical postulates forbid the existence of a process in which a virtually inﬁnite amount of work can be obtained by extracting with 100% efﬁciency heat from a huge thermal source (e.g., the ocean). An engine that would accomplish such a process is sometimes called a perpetual motion machine of the second kind.1 In fact, many people have come up with clever ideas and claims of such perpetual motion machines and have attempted to patent them, but careful analysis has always shown that some irreversible

1A perpetual motion machine of the ﬁrst kind is one that would violate the conservation of energy itself, which is already ruled out by the ﬁrst law of thermodynamics.

Thermal Physics. http://dx.doi.org/10.1016/B978-0-12-803304-3.00003-X

31

Copyright © 2015 Elsevier Inc. All rights reserved.

32 THERMAL PHYSICS

process occurs such that their efﬁciency cannot exceed the theoretical efﬁciency (see Eq. (3.27)) allowed by the second law.
Fermi [1, pp. 31-34] has shown that the postulates of Kelvin and Clausius are equivalent. The key phrase in each of them is “only ﬁnal result.” One can certainly transfer heat from a refrigerator to a room at higher temperature, but other things must change in the process, for example, work must be expended by a motor. Based on these postulates, a Carnot engine, which is a hypothetical reversible engine, and other imagined irreversible engines can be used [1, chapter IV] to develop a logical process that leads to a classical formula for the entropy (see Eq. (3.33)).
Rather than dwell on this historical justiﬁcation of the second law, we shall state it as a postulate in very general terms and then relate it to its historical roots.

3.1 Statement of the Second Law

For a thermodynamic system, there exists a function of state, S, called the entropy. S is a function of a complete set of extensive state variables that includes the internal energy, U. For all other extensive variables held ﬁxed, S is a monotonically increasing function of the internal energy U. For a homogeneous system, S is an extensive function and its slope ∂S/∂U = 1/T, where the positive quantity T is the absolute temperature.2 If the system is a composite system, S is the sum of the entropies of its constituent subsystems.
An isolated system is a chemically closed system for which δQ = 0 and δW = 0, so dU = 0 and U is a constant. Therefore also Q = 0, W = 0, and U = 0. For an isolated system, changes of S obey the inequality

S ≥ 0, isolated system, allowed changes,

(3.1)

where the inequality corresponds to a natural irreversible process and the equality corresponds to a hypothetical idealized reversible process.
If the entropy of an isolated system is a maximum subject to its internal and external constraints, all natural irreversible processes are forbidden by Eq. (3.1) so the system is in a state of equilibrium. This leads to the following equilibrium criterion:

Entropy criterion for equilibrium: The criterion for an isolated thermodynamic system to be in internal equilibrium is that its total entropy be a maximum with respect to variation of its internal extensive parameters, subject to external constraints and any remaining internal constraints. Isolation constitutes the external constraints of chemical closure, perfect thermal insulation and zero external work, which require the internal energy to be constant.
For example, consider an isolated composite system consisting of two subsystems having different temperatures and separated by an insulating wall (internal constraint). If

2For a homogeneous system, the absolute thermodynamic temperature is deﬁned by a partial derivative 1/T : = ∂S/∂U or alternatively by T = ∂U/∂S, where all other members of the complete set of extensive variables are held constant. Thus T exists independent of any particular measuring device (thermometer). See Fermi [1, p. 45] for a related discussion in terms of the Carnot cycle.

Chapter 3 • Second Law of Thermodynamics 33

the wall is then allowed to conduct heat (removal of an internal constraint), the energies of the two systems will change until the temperatures are equalized and a new equilibrium, corresponding to a state of higher entropy, is established.
In Chapter 6 we will discuss the application of this entropy criterion for equilibrium and deduce from it several alternative and useful criteria for equilibrium.

3.1.1 Discussion of the Second Law

The second law of thermodynamics is a postulate. The fact that it is believed to be true is based on extensive experimental testing. It can be rationalized on the basis of statistical mechanics, which of course is based on its own postulates. It can also be derived, as is done in classical thermodynamics for chemically closed systems, from other postulates of Kelvin or Clausius, as stated above. In order to make contact with the historical development of the second law and to derive equations that allow calculation of the entropy, we ﬁrst digress to apply Eq. (3.1) to a composite system consisting of sources of heat and work.
We consider an isolated composite system having total entropy Stot and apply Eq. (3.1) in the form

Stot ≥ 0, isolated system, allowed changes.

(3.2)

We assume that our composite system consists of a chemically closed system of interest having entropy S, a heat source having entropy Ss, and a purely mechanical system capable only of exchanging work. By deﬁnition, there is no entropy associated with this purely mechanical system, so the total entropy of our composite system is

Stot = S + Ss.

(3.3)

The heat source is assumed to be a homogeneous thermodynamic system whose only
function is to exchange heat; it does no work, has a ﬁxed number of moles of each chemical component, a temperature Ts and an internal energy Us. Thus dSs = (1/Ts)dUs by deﬁnition of the absolute temperature of the heat source. We denote by δQ a small amount of heat extracted from the source.3 From the ﬁrst law we have −δQ = dUs, so dSs = −δQ/Ts. Thus dStot = dS − δQ/Ts and for inﬁnitesimal changes, Eq. (3.2) becomes

dS

≥

δQ ,

chemically closed system, allowed changes.

Ts

(3.4)

In Eq. (3.4), the term chemically closed system pertains to the system of interest, having entropy S. The inequality pertains to a natural irreversible process and the equality pertains to an idealized reversible process. Thus

dS

>

δQ ,

chemically closed system, natural irreversible changes.

Ts

(3.5)

3δQ is assumed to be so small and the heat source has, by deﬁnition, a sufﬁciently large heat capacity that it remains practically unchanged during this process.

34 THERMAL PHYSICS

For reversible heat ﬂow, which is an idealization that separates irreversible heat ﬂow from forbidden heat ﬂow, Ts can differ only inﬁnitesimally from T, the temperature of the system, so we have

dS

=

δQ ,

chemically closed system, idealized reversible changes.

T

(3.6)

Equations (3.5) and (3.6) are sometimes offered as a statement of the second law, although the distinction between Ts and T is not always made.4
If our system of interest were simply another heat source capable of no other change, we would have dS = dU/T by deﬁnition of its absolute temperature. Then δW = 0 so dU = δQ from the ﬁrst law and we would have dS = δQ/T. For spontaneous heat conduc-

tion, a natural irreversible process, we would need

dStot = dS + dSs = δQ

1− 1 T Ts

> 0,

(3.7)

which results in δQ(Ts − T) > 0. This means that spontaneous heat conduction, with no other change, occurs only from a higher temperature to a lower temperature, in agreement with our intuition and the postulate of Clausius stated above.
For ﬁnite changes, we can integrate Eq. (3.4) to obtain

S≥

δQ , chemically closed system, allowed changes,

Ts

(3.8)

where the equality sign is for a reversible process and requires Ts = T. Our system of interest can do work (on the mechanical subsystem) of amount

W = − U + δQ,

(3.9)

provided that Eq. (3.8) is satisﬁed. We emphasize that our system of interest is not isolated, so its entropy can be made to decrease by extracting heat reversibly. Therefore, if a chemically closed system is not isolated, its entropy can increase or decrease, and the process that brings about this change can be either reversible or irreversible, depending on the relationship of S to δQ/Ts for that process.
In classical thermodynamics, one often speaks of heat reservoirs. A heat reservoir is a heat source with such a large heat capacity that its temperature remains constant.5 If the heat source in Eq. (3.8) is replaced by a heat reservoir of temperature Tr from which an amount of heat Qr is extracted, we obtain

S ≥ Qr , chemically closed system, allowed changes. Tr

(3.10)

4See the footnote on page 48 of Fermi [1] for further discussion of Ts. Some books [5, 16] write dS > δQ/T which is more restrictive than Eq. (3.5); such an equation applies to a process in which the heat conduction
between the heat source and the system of interest is reversible but other processes that take place within the
system of interest are irreversible. 5For example, if a heat source has a constant heat capacity Cr and an amount of heat Qr is extracted from it,
its temperature would change by Tr = − Qr /Cr . For a reservoir, Cr is assumed to be so large that Tr can be made arbitrarily small, and therefore zero for all practical purposes.

Chapter 3 • Second Law of Thermodynamics 35

If the heat source consists of a number of such reservoirs, Eq. (3.8) becomes S ≥ Qr , chemically closed system, allowed changes r Tr
and Eq. (3.9) is replaced by

(3.11)

W = − U + Qr.
r

(3.12)

If the amounts of heat Qr in Eqs. (3.11) and (3.12) are very small, the sums can be replaced by integrals, and the result is essentially the same as Eqs. (3.8) and (3.9).
A system surrounded by perfectly insulating walls requires δQ = 0 and is said to be adiabatic. For an adiabatic system, Eq. (3.8) becomes

S ≥ 0, chemically closed adiabatic system, allowed changes.

(3.13)

But Eq. (3.9) yields W = − U, so such a system is not isolated and can still do work. Chandler [12, p. 8] states the second law by means of Eq. (3.13) which applies to transformations that are adiabatically accessible, those corresponding to the inequality being irreversible and those corresponding to the equality being reversible.
For a cyclic process, the system returns to its original state after each cycle. Since S is a state function, S = 0 for a cyclic process and Eq. (3.11) becomes

0 ≥ Qr , cyclic process, chemically closed system, allowed changes. r Tr

(3.14)

For a continuous distribution of reservoirs,

0≥

δQ , cyclic process, chemically closed system, allowed changes.

Tr

(3.15)

For an adiabatic cyclic process, δQ = 0, so Eq. (3.15) becomes 0 ≥ 0 and compatibility

would require the equality sign to hold, consistent with the fact that an adiabatic cyclic

process is reversible.

3.2 Carnot Cycle and Engines
In classical thermodynamics, the second law of thermodynamics is usually rationalized by considering processes involving the conversion of work to heat by engines that return to their original thermodynamic state after one cycle. Comparison is made to a hypothetical engine, known as a Carnot engine, which is imagined to execute a reversible cycle. The Carnot cycle pertains to an idealized engine in which the working substance is one mole6 of an ideal gas. There are four segments to the cycle, as depicted in Figure 3–1. All segments involve reversible processes, so the whole cycle is reversible. Segment AB is a reversible isothermal expansion in which an amount of heat |Q2| = Q2 is extracted from a heat source at a high temperature T2. Segment BC is a reversible adiabatic expansion. Segment CD
6We could also consider any ﬁxed number of moles of an ideal gas.

36 THERMAL PHYSICS

A

T2

D

B

p

T1

C

V
FIGURE 3–1 The Carnot cycle in the V , p plane. The working substance is an ideal gas and the cycle consists of four reversible segments. AB is isothermal expansion at temperature T2, BC is adiabatic expansion, CD is isothermal compression at temperature T1, and DA is adiabatic compression. The ﬁgure is drawn for γ = 5/3.

is a reversible isothermal compression in which an amount of heat |Q1| = − Q1 is given up to a heat sink at temperature T1. Both the source and the sink are assumed to be heat reservoirs, so their temperatures do not change. Finally, segment DA is a reversible adiabatic compression. In order for these segments to form a closed cycle, we can apply Eq. (2.27) to each of the adiabatic segments to obtain

T2VBγ −1 = T1VCγ −1; T2VAγ −1 = T1VDγ −1.

(3.16)

Division of one of these equations by the other and extraction of the γ − 1 root gives

VA = VD . VB VC

(3.17)

Combining Eq. (3.17) with the ideal gas law gives

pA = pD , pB pC

(3.18)

so the geometry of the cycle is completely known and simple to express.
On the adiabatic segment BC, δQ = 0 so we have WBC = − UBC = CV (T2 − T1). This exactly cancels the work CV (T1 − T2) done by the gas on the other adiabatic segment. The work done by the gas on the isothermal expansion segment AB is RT2 ln(VB/VA). Recalling that U depends only on T for an ideal gas means that UAB = 0 for that segment, so

|Q2| = RT2 ln(VB/VA).

(3.19)

Similarly, for the isothermal compression segment CD, we obtain

|Q1| = −RT1 ln(VD/VC ) = RT1 ln(VB/VA),

(3.20)

where Eq. (3.17) has been used in the last step. Dividing Eq. (3.19) by Eq. (3.20) we obtain

|Q1| = |Q2| .

T1

T2

(3.21)

Chapter 3 • Second Law of Thermodynamics 37

For the entire cycle, U = 0 so the total work done by the gas during the cycle is W = |Q2|− |Q1|. The efﬁciency of the cycle is therefore

η

:=

W |Q2|

=

1−

|Q1| |Q2|

=

1

−

T1 . T2

(3.22)

This efﬁciency is always less than unity except for a heat sink at absolute zero, which is deemed to be impossible.
Let us examine the meaning of Eq. (3.21) in terms of the second law. Since the entropy is a function of state, we have S = 0 for a cycle. Applying Eq. (3.11) with the equality, for our reversible cycle, we obtain

0 = Q2 + Q1 = |Q2| − |Q1|

T2 T1 T2

T1

(3.23)

in agreement with Eq. (3.21). Beginning with the Carnot cycle, Fermi [1, chapter IV] proves a number of other things
based on the Kelvin/Clausius postulates. These are used to rationalize the existence of the entropy and to formulate the second law. Here, we take the opposite approach by quoting the main results and demonstrating how they follow from the second law.

• Any reversible engine working between the same two temperatures T2 and T1 has the same efﬁciency as a Carnot engine. We follow the same procedure as we did in deriving
Eq. (3.23) except that the amounts of heat are now |Q2| and |Q1| which might differ from those for a Carnot engine. Thus we obtain

0 = Q2 + Q1 = |Q2| − |Q1| .

T2 T1

T2

T1

(3.24)

It follows that the ratio |Q1|/|Q2| = T1/T2 is the same as for a Carnot engine. From Eq. (3.12) with U = 0, the amount of work done in the cycle is now W =
|Q2| − |Q1|, so

η := W = 1 − |Q1| = 1 − T1 = η.

|Q2|

|Q2 |

T2

(3.25)

• Any irreversible engine working between the same two temperatures T2 and T1 has a smaller efﬁciency than a Carnot engine. This result follows by applying Eq. (3.11) with the inequality to obtain (superscript i for irreversible)

0 > Qi2 + Qi1 = |Qi2| − |Qi1| ,

T2 T1

T2

T1

(3.26)

which leads to |Qi1|/|Qi2| > T1/T2. The amount of work done in the cycle is now Wi = |Qi2| − |Qi1|, resulting in

ηi

:=

Wi |Qi2 |

=

1−

|Qi1 | |Qi2 |

<

η.

(3.27)

38 THERMAL PHYSICS

• In a cycle of any reversible engine that receives heat δQ from a number of sources at

temperature T,

δQ = 0. T

(3.28)

This follows from Eq. (3.8) with the equality by recognizing that S = 0 for a cycle. In

classical thermodynamics, Eq. (3.28) is deduced by arguing that any reversible cycle can

be approximated to arbitrary accuracy by a very large number of small Carnot cycles.

It is actually Eq. (3.28) that was used to deduce that a state function, now known as the

entropy, exists. By integrating from point A to point B along some reversible path and

the back again to A along some other reversible path, we create a reversible cycle. Since

the integral from B to A along the return path is the negative of the integral from A to B

along that path, it follows that

B δQ

=

B δQ

.

A T reversible path I

A T reversible path II

(3.29)

Since the values of the integrals in Eq. (3.29) depend only on their end points, their integrand must be the differential of some function, namely dS = δQ/T, which is Eq. (3.6). In mathematics, 1/T would be called an integrating factor for δQ.

• In a cycle of any irreversible engine that receives heat δQ from a number of sources at

temperature Ts,

δQ < 0. Ts

This follows from Eq. (3.11) with the inequality by recognizing that

(3.30) S = 0 for a cycle.

Example Problem 3.1. Analyze a Carnot refrigerator in which heat |Q1| = Q1 is extracted
(from the refrigerator) at a low temperature T1 and given to a Carnot engine running in reverse; then |Q2| = − Q2 is extracted from that Carnot engine and given to a sink at higher temperature T2.

Solution 3.1. The magnitudes |Q2| and |Q1| are still given, respectively, by Eqs. (3.19) and (3.20), so Eq. (3.21) still applies. But now an amount of work W = − W > 0 must be done on the
system, where W = Q1 + Q2 = |Q1| − |Q2| = − W . Thus

|Q1| W

=

T2

T1 −

T1

.

(3.31)

We see that only a small amount of work W must be provided to extract |Q1| from the refrigerator provided that T1 is not too much lower than T2. Since an amount of heat |Q2| = |Q1|(T2/T1) must be given up to the source, the cooling of a refrigerator can result in a large amount of
heat given up to the surrounding room. Of course the process that takes place in an actual
refrigerator is irreversible, so even a larger ratio of the removed heat to the work W is required
than given by Eq. (3.31). Indeed, by using Eq. (3.26) for an irreversible engine, we obtain the inequality |Qi1|/W < T1/(T2 − T1).

Chapter 3 • Second Law of Thermodynamics 39

The considerations that led to Eq. (3.31) can also be applied to analyze a heat pump that adds an incremental amount of heat from an inexpensive source at temperature T1 to heat a room at temperature T2. In that case, a more meaningful quantity is

|Q2| W

=

T2

T2 −

T1

.

(3.32)

Thus the heat pump will require only a small amount of work to provide |Q2| if the source
temperature T1 is close to T2. For a real (irreversible) heat pump we would have |Qi2|/W < T2/(T2 − T1).

3.3 Calculation of the Entropy Change

From Eq. (3.29) it follows that the change in entropy of a system that begins in state A and ends in state B is given by

S ≡ S(B) − S(A) =

B δQ ,

any reversible path connecting A and B.

AT

(3.33)

In Eq. (3.33), we emphasize that the path of integration is any reversible path. Since S is function of state, the entropy change S(B)−S(A) will be the same no matter how the system changes from A to B, for example by an irreversible process, but it can only be calculated by using a reversible path. In practice, one uses some convenient reversible path to make the computation simple. Equation (3.33) only deﬁnes the difference in entropy between states. We could choose some standard state O and then calculate the differences S(A) − S(O) and S(B) − S(O). Later we will encounter the third law of thermodynamics, according to which there is a standard state whose entropy can be taken to be zero.

Example Problem 3.2. The heat capacity at constant volume of a number of substances can
be represented empirically by an equation of the form

CV = a + bT + cT 2,

(3.34)

where a, b, and c are constants. Calculate the change in internal energy and the change in entropy when the temperature changes from T1 to T2 at constant volume.

Solution 3.2. At constant volume, we have dU = CV dT and dU = δQ = T dS. Thus,

U = U2 − U1 = T2 CV dT = aT + bT 2/2 + cT 3/3 T2

T1

T1

(3.35)

and

S = S2 − S1 = T2 CV /T dT = a ln T + bT + cT 2/2 T2 .

T1

T1

(3.36)

40 THERMAL PHYSICS

Example Problem 3.3. Consider an isolated composite system consisting of two subsystems,
(1) and (2) respectively, having ﬁxed volumes V1 and V2 and heat capacities at constant volume at temperature T of C1(T ) and C2(T ). Suppose that the subsystems are separated initially by an insulating wall and are at equilibrium with initial temperatures T1 < T2. Then let very small amounts of energy pass very slowly through the wall by heat transfer so that each subsystem
passes through a series of equilibrium states until the system comes to a ﬁnal equilibrium state.
Calculate the temperatures of the subsystems at each stage of the process and study the total
entropy change until a maximum entropy has been reached.

Solution 3.3. At some intermediate stage of the process, the changes in energy and entropy will be given by

T1∗

T2∗

0 = (U) = C1(T ) dT + C2(T ) dT

T1

T2

(3.37)

and

(S) = T1∗ C1(T ) dT + T2∗ C2(T ) dT ≥ 0.

T1

T

T2

T

(3.38)

Then take differentials of these expressions to obtain

0 = C1(T1∗) dT1∗ + C2(T2∗) dT2∗

(3.39)

and

d

(S)

=

C1(T1∗) T1∗

dT1∗

+

C2(T2∗) T2∗

dT2∗

≥

0.

Substitution of Eq. (3.39) into Eq. (3.40) gives

(3.40)

d

(S) = C1(T1∗)

1 T1∗

−

1 T2∗

dT1∗ ≥ 0,

(3.41)

iwTt1s∗him≤chaTxf2∗iomr<upmTo2sivatativleueaecdahTt1∗sstoaregmqeeuoinfretehswe(1ep/qrTou1∗cilei−bssr1.iuW/mTh2∗et)enm≥Tp1∗0ei.rnaIcntruevraeiesTwes1∗ot=of

Eq. (3.37), this requires T1 <

TT22∗∗

, d (S) = 0 and S will reach = Teq. This can be seen in

principle by integrating Eq. (3.41) from T1 to Teq, but that would require speciﬁcation of C1(T )

and C2(T ) to enable T2∗ to be expressed as a function of T1∗. Nevertheless, the ﬁnal result will

satisfy

Teq

Teq

0 = (U) =

C1(T ) dT +

C2(T ) dT

T1

T2

(3.42)

and

(S) = Teq C1(T ) dT + Teq C2(T ) dT > 0.

T1

T

T2

T

(3.43)

For the simple case when C1 and C2 are independent of T , the reader is invited to carry out these calculations explicitly.

Chapter 3 • Second Law of Thermodynamics 41

3.4 Combined First and Second Laws

For a chemically closed system, the ﬁrst law gives

dU = δQ − δW.

(3.44)

For a simple7 homogeneous isotropic system for which U depends only on S and V ,

dU =

∂U ∂S

dS +
V

∂U

∂V

dV .
S

(3.45)

For a reversible transformation in this system, for which the only work is the quasistatic work, we have

δQ = T dS; δW = p dV ; reversible.

(3.46)

Substitution of Eq. (3.46) into Eq. (3.44) gives dU = T dS − p dV .

(3.47)

We can therefore identify the derivatives

T=

∂U

∂S

;
V

−p =

∂U

∂V

.
S

(3.48)

We emphasize that Eq. (3.47) holds for all inﬁnitesimal changes of U(S, V ) within the

ﬁeld of equilibrium states. Equation (3.46), which is only true for reversible processes, was

only used to identify the derivatives in Eq. (3.45). Equations that give explicit forms of the functions T(S, V ) and p(S, V ) are known as equations of state. If all8 equations of state are

known, Eq. (3.47) can be integrated to recover the function U(S, V ), except for an additive

constant which has to do with the arbitrary zero of energy. If the second partial derivatives

of U are continuous, as we shall assume to be the case for thermodynamic functions, the

order of partial differentiation does not matter and we obtain

∂T ∂V

=
S

∂2U ∂V ∂S

=

∂2U ∂S∂V

=−

∂p ∂S

.
V

(3.49)

(∂T/∂V )S = − ∂p/∂S V is an example of a Maxwell relation. In Chapter 5 we will take up Maxwell relations for systems that depend on several variables.
Since Eq. (3.44) holds even for irreversible transformations and Eq. (3.47) is generally
true, we can eliminate dU to obtain

p dV − δW = T dS − δQ.

(3.50)

7Note that Eqs. (3.45) and (3.47) hold only for a chemically closed system in which no chemical reactions are occurring. If chemical reactions are allowed, U would depend on additional variables (progress variables of the reactions). Equation (3.6) would not hold if these reactions were irreversible. See Eq. (5.128) for further clariﬁcation.
8For open systems, one must include the numbers of moles of each chemical component, N1, N2, . . . , Nκ as additional variables in U, in which case there are more equations of state (see Chapter 5). In general, U depends on a complete set of extensive state variables.

42 THERMAL PHYSICS

For reversible transformations, Eq. (3.46) holds and both sides of Eq. (3.50) are zero. But for an irreversible process, Eq. (3.46) no longer applies. Instead, Eq. (3.5) applies and Eq. (3.50) leads to an interesting inequality. We divide Eq. (3.50) by T and rearrange to obtain

p dV − δW + δQ = dS.

T

T

Then we subtract δQ/Ts from both sides of Eq. (3.51) and apply Eq. (3.5) to obtain

p dV − δW + δQ 1 − 1 = dS − δQ > 0, natural, irreversible.

T

T Ts

Ts

(3.51) (3.52)

The ﬁrst term on the left of Eq. (3.52) is due to the process of irreversible work and the second term on the left is due to the irreversible process of heat conduction between the external source and the system. These terms can be regarded [16, pp. 95-95] as representing entropy production during independent irreversible processes and are separately positive. A positive value of the ﬁrst term leads to the inequality W < p dV , in agreement with Eq. (2.5). If we substitute W = pext dV where pext is an effective pressure of purely mechanical origin as in Eq. (2.3), this work inequality becomes (p − pext) dV > 0. The second term is the same as in Eq. (3.7), derived for the case in which the system was considered to be a heat source that could do no work.
We can rearrange Eq. (3.47) in the form

dS = 1 dU + p dV

T

T

(3.53)

from which it follows that

1= T

∂S ∂U

;
V

p= T

∂S ∂V

.
U

(3.54)

Equations that give 1/T and p/T as functions of U and V are also equations of state. If we know these functions, Eq. (3.53) can be integrated to recover S(U, V ). We also have the Maxwell relation (∂(1/T)/∂V )U = ∂(p/T)/∂U V .
Since the entropy is postulated to be a monotonically increasing function of the
internal energy, the internal energy is also a monotonically increasing function of the entropy. The inverse transformation between S(U, V ) and U(S, V ) is therefore unique,
and either of these functional forms can be chosen to give a complete representation of the thermodynamic system.9 One speaks of the entropy representation S(U, V ) or the energy representation U(S, V ). Either of these equations can be regarded as a fundamental equation of the system and either contains complete information about the
system.

9For more complicated systems, both S and U depend on an additional set of extensive variables, but these behave just like V .

Chapter 3 • Second Law of Thermodynamics 43

Example Problem 3.4. For a hypothetical thermodynamic system, T = (4/A)(U/V )3/4 and
p = 3U/V , where A is a constant. Find the fundamental equation in the entropy representation.

Solution 3.4. We readily calculate 1/T = (A/4)(V /U)3/4 and p/T = (3A/4)(U/V )1/4 so Eq. (3.53) takes the form

dS = (A/4)(V /U)3/4 dU + (3A/4)(U/V )1/4 dV ,

(3.55)

which integrates to give S = AU1/4V 3/4 + S0, where S0 is a constant.

Example Problem 3.5. This problem concerns one mole of an ideal monatomic gas that
obeys the equation pV = RT , where p is the pressure, V is the volume, T is absolute temperature, and R is the universal gas constant. The gas has a heat capacity (per mole) at constant volume of CV = (3/2)R. In its initial state, it is in equilibrium at temperature T1 and volume V1 in the left chamber of a box, as shown in Figure 3–2. The right chamber of the box, which has volume V2 − V1, is initially evacuated. The two chambers are surrounded by exterior walls that are rigid and impenetrable. The chambers are separated initially by an interior wall that is rigid, impenetrable, and insulating. Under various conditions detailed below, the gas is allowed to expand and ﬁnally comes to equilibrium in the total volume V2.
Apply the ﬁrst and second laws of thermodynamics, the deﬁnition of CV , the ideal gas equation of state, and integration to answer the following questions.
(a) Suppose, by whatever means, that the gas expands into the total volume V2 and comes to equilibrium at temperature T2. What is the change, S, in entropy of the gas from its initial to its ﬁnal state?
(b) The entire system is maintained at constant temperature T1 by contact with a heat reservoir. The gas is allowed to expand by means of an external agent that moves the internal wall separating the chambers very slowly (such that the gas is practically in equilibrium at each stage of the process) until the gas occupies the entire volume V2. What is the change, U, in its internal energy? How much external work, W, does the system do on the external agent that moves the wall? How much heat, Q, is added to the system during this process? Compare Q to the relevant S and deduce whether this process is reversible or irreversible.

V1 Ideal gas

V2−V1 Vacuum

FIGURE 3–2 A monatomic ideal gas at temperature T1 initially occupies the left chamber of the box. The right chamber of the box, which has volume V2 − V1, is evacuated. The interior wall that separates the gas from the evacuated chamber is rigid, impenetrable and insulating, but can be moved or ruptured.

44 THERMAL PHYSICS

(c) The entire system is insulated and the wall separating the chambers is suddenly ruptured, allowing the gas to ﬁll the entire volume V2. How much external work, W, does the system do? What is the ﬁnal temperature of the gas? Compare Q to the relevant S and deduce whether this process is reversible or irreversible.
(d) The entire system is insulated. The gas is allowed to expand by means of an external agent which moves the internal wall separating the chambers very slowly (such that the gas is practically in equilibrium at each stage of the process) until the gas occupies the entire volume V2. What is the ﬁnal temperature, T2, of the gas? Compare Q to the relevant S and deduce whether this process is reversible or irreversible.

Solution 3.5.

(a) Since S is a state function, S depends only on the initial and ﬁnal states of the system, irrespective of how the system gets from the initial state to the ﬁnal state. We substitute the ideal gas law and the equation dU = CV dT into Eq. (3.53) to obtain

dT dV

dS = CV

T

+R V

,

(3.56)

which integrates to give

S = CV ln(T2/T1) + R ln(V2/V1), one mole of ideal gas.

(3.57)

(b) U depends only on T for an ideal gas, so U = 0. Thus from the ﬁrst law, W = Q. Since the work is quasistatic, W = p dV where the integral is to be carried out along an isothermal path T = T1. Therefore we can use p = RT1/V and take the constants RT1 outside the integral to obtain

Q = W = RT1

V2 dV V1 V

= RT1 ln(V2/V1).

Since T2 = T1 for this process, part (a) gives S = R ln(V2/V1) so

S = Q/T1

(3.58) (3.59)

and the process is reversible (as expected for quasistatic work). Note that the entropy increases for this reversible process. In this case, entropy increase does not automatically imply irreversibility because the system is not isolated. Similarly, for reversible adiabatic contraction, both Q and S are negative, and the entropy of the system decreases. This does not violate Eq. (3.1) because the system is not isolated. (c) W = 0 because the outer wall is rigid and there is no way to do mechanical work on the environment of the system. Since Q = 0, we conclude from the ﬁrst law that U = 0.
Since U depends only on T , we have T2 = T1. (During the process itself, which we shall see is irreversible, T is at best inhomogeneous and probably undeﬁned.) The change in entropy, from part (a), is again S = R ln(V2/V1) > 0. Therefore, since δQ = 0 at every stage of the process,

S > δQ = 0, T

(3.60)

so the process is irreversible as expected.

Chapter 3 • Second Law of Thermodynamics 45

(d) Q = 0 because the system is insulated. The work is quasistatic so δW = p dV , and since
δQ = 0 at each stage of the process, the ﬁrst law gives dU + p dV = 0. Since dU = CV dT , this becomes CV dT + RT dV /V = 0. Division by T (which is not constant in this process) yields CV dT /T + R dV /V = 0 which integrates to give

CV ln(T2/T1) + R ln(V2/V1) = 0.

(3.61)

Thus, S = 0 and

S = δQ = 0, T

so the process is reversible and isentropic, as expected for this quasistatic process with
adiabatic walls. By means of Eq. (2.27), the ﬁnal temperature can be written more succinctly as T2 = T1(V1/V2)2/3, so the temperature drops, as expected, for this reversible adiabatic expansion.

3.4.1 Latent Heat

When a substance melts or evaporates, heat must be supplied to partially or totally break atomic bonds and rearrange structure, and hence to change the phase to a state of higher disorder, which we shall see later is a state of higher entropy. Melting and vaporization processes are generally carried out at constant pressure, for example, atmospheric pressure. The heat needed to change the phase reversibly at constant pressure and temperature is known as latent heat. Heat must be supplied when a solid melts to become a liquid (heat of melting); the same amount is given up when a liquid freezes to become a solid (latent heat of fusion). When a liquid becomes a gas, it is necessary to supply heat (heat of vaporization); when a gas condenses to become a liquid, the same amount of heat is given up (latent heat of condensation). These are generally reported as positive quantities, usually per mole or per unit mass.
Consider, for example, the melting of ice, which takes place at atmospheric pressure at a temperature of 0 ◦C = 273.15 K. As we supply heat to cold ice, it is warmed from below its melting point to 273.15 K where melting occurs and water begins to form. As heat continues to be supplied, the ice-water mixture remains at 273.15 K until all of the ice melts. This requires 80 calories of heat per gram of ice, the latent heat of fusion. Further heating causes the temperature of the water to rise.
Processes such as this, which take place at constant pressure, may be analyzed conveniently in terms of the enthalpy, H = U +pV previously introduced in connection with the ﬁrst law (see Section 2.5). We saw that dH = dU + p dV + V dp which in view of Eq. (3.47) becomes

dH = T dS + V dp.

(3.62)

But at constant pressure we have

dH = Cp dT ,

(3.63)

46 THERMAL PHYSICS

where Cp is the heat capacity at constant pressure. Equation (3.63) applies in the absence of phase change, say for TI ≤ T < TM and also for TM < T ≤ TW, where TI is the initial temperature of the ice, TM is the melting point and TW is the ﬁnal temperature of the water. At T = TM, H increases by the amount HM, the latent heat of fusion. The total change in H is therefore

TM

TW

H=

Cp(ice) dT + HM +

Cp(water) dT .

TI

TM

(3.64)

H as a function of T is shown in Figure 3–3a. Formally, the effective heat capacity at

the melting point can be represented as a delta function (the formal derivative of a step

function) as shown in Example Problem 2.4.

By combining Eq. (3.62) with Eq. (3.63) at constant pressure, we obtain

dS = Cp dT , T

(3.65)

which can be integrated to ﬁnd the entropy change that occurs prior to melting and subsequent to melting. During the melting itself, we integrate10 Eq. (3.62) at constant p to obtain SM = HM/TM, which is called the entropy of fusion. Therefore, the total change of entropy is given by

S = TM Cp(ice) dT + HM + TW Cp(water) dT .

TI

T

TM

TM

T

(3.66)

S as a function of T is shown in Figure 3–3b. If the range of temperature is not large, Cp(ice) and Cp(water) can be considered to be
practically independent of T, so we have the simpliﬁcations

H ≈ Cp(ice)(TM − TI) + HM + Cp(water)(TW − TM)

(3.67)

1750 1500 1250 1000
750 500 250

ΔHM

7

6

5

4

3

ΔSM

2

1

265 270 275 280 285 290 295

265 270 275 280 285 290 295

(a)

(b)

FIGURE 3–3 (a) Enthalpy change H in cal/mol and (b) entropy change S in cal/(mol K) as a function of temperature T in K for melting of ice. The curvature of the logarithms in S is not apparent on this scale. The jumps are related by HM = TM SM. (a) Enthalpy H versus T and (b) Entropy S versus T .

10We assume that the whole process is done slowly and carefully so that it is reversible.

Chapter 3 • Second Law of Thermodynamics 47

and

S

≈

Cp(ice) ln

TM TI

+

HM TM

+ Cp(water) ln

TW . TM

(3.68)

To get an idea of the magnitudes involved, we approximate Cp(ice) ≈ Cp(water) ≈ 1 cal/g K, take TI = −10 ◦C and TW = 20 ◦C. Then for every mole of H2O (18 g/mol) we have

H = (189 + 1440 + 351) cal/mol = 1980 cal/mol

(3.69)

and

S = (0.67 + 5.27 + 1.27) cal/K mol = 7.21 cal/K mol.

(3.70)

For many monatomic substances, SM = HM/TM ∼ R ≈ 2 cal/K mol, an empirical rule known as Richard’s rule. For ice, the entropy of fusion is much larger (5.27 cal/K mol) because of the complexity of the H2O molecule. For vaporization, a similar empirical rule known as Trouton’s rule leads to the estimate SV = HV /TV ∼ 10.5R ≈ 21 cal/K mol, as compared to 26 cal/K mol for water. The fact that the entropy of vaporization is larger than the entropy of fusion is because essentially all atomic bonds must be broken for evaporation and because of the large volume change from liquid to gas.

3.5 Statistical Interpretation of Entropy
The entropy S enters classical thermodynamics as a mysterious state function whose changes can be calculated from Eq. (3.33). Unlike other state variables such as the internal energy U or the pressure p, it has no roots in classical mechanics. Its existence is related to the fact that the absolute temperature T is regarded in thermodynamics to be a state variable, and the entropy S turns out to be its conjugate variable.11 A more thorough understanding of entropy requires a statistical analysis. Later we will discuss entropy in the context of the formal postulates that underlie statistical mechanics. For now, we give a brief statistical interpretation based on a few simple ideas.

3.5.1 Relationship of Entropy to Microstates

In order to understand entropy, we must appreciate that for every macrostate of a system, which corresponds to a ﬁxed energy and other extensive parameters, there are a number of compatible microstates, and the system could be in any one of them.12 In fact, it could progress through a number of compatible microstates as time evolves. If we assume that the probability of a given microstate is 1/ , it is reasonable to postulate that the entropy is a function of the number of microstates, that is,

S = f ( ).

(3.71)

11In the differential dU = T dS − p dV , T is said to be conjugate to S and −p is conjugate to V . For a more general deﬁnition of conjugate variables, see Section 5.5.
12According to quantum mechanics, the system will have a discrete set of energy eigenstates, which are
actually countable. See Chapters 16 and 26 for details.

48 THERMAL PHYSICS

For an isolated system, natural processes are those that correspond to an increase in S. Moreover, S is deﬁned to be an increasing function of the internal energy and we would expect the number of compatible microstates to increase with energy. We therefore anticipate that f ( ) will be a monotonically increasing function of , which turns out to be the case.
Once Eq. (3.71) is accepted, the form of the function f ( ) can be determined by considering an isolated composite system S made up of two subsystems having entropies S1 and S2. Since S is assumed to be additive for composite systems, we have

S = S1 + S2.

(3.72)

If the number of microstates for S1 is 1 and that for S2 is 2, then for the total system S the number of microstates is 1 2. Therefore, Eq. (3.72) may be written

f ( 1 2) = f ( 1) + f ( 2).

(3.73)

In Eq. (3.73), we ﬁrst set 2 = 1 to obtain f ( 1) = f ( 1) + f (1),

(3.74)

from which we conclude that f (1) = 0. Then we differentiate Eq. (3.73) partially with respect to 2 to get (the prime denotes the derivative with respect to the argument)

1f ( 1 2) = f ( 2)

(3.75)

and again set 2 = 1 to get

f ( 1) = k ,
1

(3.76)

where k = f (1) is a constant. We then integrate Eq. (3.76) to obtain f ( 1) = k ln 1 + C where C is a constant. Since f (1) = 0, we conclude that C = 0. Therefore, returning to our general notation, we have

S = k ln .

(3.77)

In order for S to be a monotonically increasing function of , we must choose k > 0. For an isolated system, Eq. (3.77) is a fundamental equation that relates entropy to
statistical mechanical concepts. It states that the entropy is proportional to the logarithm of the number of microstates that are compatible with a given macrostate. The constant of proportionality k depends on the units used to measure S. In order to agree with classical thermodynamics, we need to choose k = kB which is known as Boltzmann’s constant:

kB = 1.381 × 10−16 erg/K = 1.381 × 10−23 J/K = 3.301 × 10−24 cal/K.

(3.78)

It is related to the gas constant R = NAkB where NA = 6.022 mol−1 is Avogadro’s number (also known as Loschmidt-Zahl in the German literature). Hence

R = 8.314 × 10−7 erg/(mol K) = 8.314 J/(mol K) = 1.987 cal/(mol K).

(3.79)

For a more rigorous justiﬁcation of Eq. (3.77) in the context of information theory and the microcanonical ensemble, see Chapter 15, particularly Eq. (15.14), and Chapter 16.

4
Third Law of Thermodynamics

The third law of thermodynamics is the latest of the three laws of thermodynamics to be developed. It insures that the entropy remains well-deﬁned at the absolute zero of temperature and allows one to deﬁne a zero of entropy that is consistent with statistical mechanics. This avoids having to deal with entropy differences; instead, we can deal with entropies as absolute quantities, analogous to absolute temperature but unlike energy.

4.1 Statement of the Third Law
The entropy S of a thermodynamic system in internal equilibrium approaches a universal constant S0, independent of phase, as the absolute temperature T tends to zero. Alternatively, one could say that S → S0 in a state for which the quantity (∂U/∂S){ext} → 0, where {ext} stands for the remaining members of a complete set of extensive variables. By convention, and in agreement with statistical mechanics, the value of this universal constant S → S0 is taken to be zero. Since entropy is a monotonically increasing function of temperature, this convention results in the entropy being a positive quantity.

4.1.1 Discussion of the Third Law

According to statistical mechanics, as motivated by Eq. (3.77), the entropy of an isolated system is given by

S = kB ln ,

(4.1)

where kB is Boltzmann’s constant and is the number of microstates that correspond to a given macrostate. If at absolute zero only a unique ground state of the system is occupied, then = 1 and S = 0. Possibly the ground state could be degenerate, in which case
= 1 even at T = 0. But this degeneracy would have to be massive to make a signiﬁcant difference in the entropy of a macroscopic system at T = 0. Indeed, to get a contribution S = 10−10R = 10−10kBNA for one mole at absolute zero would require the ground state degeneracy 0 to satisfy 10−10NA = ln 0, where NA is Avogadro’s number. This yields
0 ∼ e6×1013 ∼ 102.6×1013. But such a huge degeneracy is contrary to experience. As the ground state of a quantum system is approached (as T → 0), the number of accessible quantum states decreases quite rapidly and is no longer of exponential order, even though
there could still be a ground state of much smaller degeneracy. An illuminating discussion
of this point has been presented by Benjamin Widom [17, chapter 5].
The third “law” is an extension by Max Planck [15, p. 273] of the so-called Nernst
postulate [2, p. 277] that was made in an attempt to justify an empirical rule of Thomsen
and Berthelot for chemical reactions that take place at constant temperature and pressure.

Thermal Physics. http://dx.doi.org/10.1016/B978-0-12-803304-3.00004-1

49

Copyright © 2015 Elsevier Inc. All rights reserved.

50 THERMAL PHYSICS

Nernst conjectured that their empirical rule for equilibrium, which is equivalent to minimizing the enthalpy change H of the reaction, would be in agreement with the proper thermodynamic criterion obtained by minimizing an appropriate change in free energy1 of the reaction, provided that the entropy change S tends to zero as T → 0. This can be interpreted to mean that the entropy S itself tends to some constant, independent of the extent of the reaction, as T → 0. For convenience, Planck set this entropy constant to zero, which agrees with the convention used to deﬁne entropy in statistical mechanics. Callen [2, p. 30] states the third law as an independent postulate, namely that S = 0 in a state for which ∂U/∂S = 0 (which is true at absolute zero by deﬁnition of the thermodynamic temperature). From the point of view of classical thermodynamics, one could deal with entropy differences and it would not be necessary to adopt a state of zero entropy; however, doing so leads to simplicity and builds a strong bridge to statistical mechanics.

4.2 Implications of the Third Law

The third law has certain implications regarding heat capacities and other properties of materials as T → 0. From Eq. (3.47) with dV = 0, we obtain CV dT = T dS where CV is the heat capacity at constant volume. The change in entropy at constant volume from one temperature to another is given by CV /T dT. Thus

S(T1, V ) =

T1 CV (T , V ) dT .

0

T

(4.2)

In order for this integral to converge, it is necessary for CV to depend on T in such a way that CV → 0 as T → 0. Recall that CV was taken to be a constant for an ideal gas; clearly such an ideal gas becomes impossible as T → 0. For insulating solids, one ﬁnds both theoretically and experimentally that CV ∝ T3 as T → 0. For metals, nearly free electrons contribute to the heat capacity and CV ∝ T as T → 0. Similar considerations apply to the heat capacity at constant pressure. From Eq. (3.62) with dp = 0, we obtain Cp dT = T dS,
where Cp is the heat capacity at constant pressure. Thus

S(T1, p) =

T1 Cp(T , p) dT

0

T

(4.3)

and it is necessary2 for Cp → 0 as T → 0. An interesting experimental veriﬁcation of the third law has been discussed by Fermi

[1, p. 146]. At temperatures below T0 = 292 K, gray tin (α, diamond cubic) is the stable form and above this temperature, white tin (β, tetragonal) is stable. These are allotropic

forms of pure tin. It turns out, however, that white tin can exist (in internal equilibrium)

below 292 K, even though it is unstable with respect to transformation to gray tin. It is also

1This is the change G of the Gibbs free energy of the reaction, whose deﬁnition and properties we explore
later. 2In order for the integrals in Eqs. (4.2) and (4.3) to converge at T = 0, it will sufﬁce for CV or Cp to go to zero
very weakly as T → 0, for instance ∝ T where > 0.

Chapter 4 • Third Law of Thermodynamics 51
White S
Gray

0K

292 K

T

FIGURE 4–1 Entropies S of gray and white tin as a function of absolute temperature T . Below T0 = 292 K, gray tin is stable and above this temperature white tin is stable. The full curves denote stable phases and the dashed
curves denote unstable phases. White tin can be supercooled below T0 so its heat capacity can be measured and its entropy can be calculated. The jump in entropy at T0 between gray tin and white tin is due to the latent heat of transformation.

possible to measure the heat capacities of both forms of tin down to very low temperatures. One can therefore evaluate the entropy of white tin at 292 K in two different ways, the ﬁrst by integrating its heat capacity from absolute zero and the second by integrating the heat capacity of gray tin from absolute zero and then adding the entropy associated with transformation to white tin at 292 K. See Figure 4–1 for a graphic illustration. Thus (with subscripts g and w for gray and white), we have

Sw(292 K ) =

292 K Cw(T ) dT = 12.30 cal/mol K,

0

T

(4.4)

and

Sg(292 K ) =

292 K Cg(T ) dT = 10.53 cal/mol K.

0

T

(4.5)

The heat of transformation from gray to white tin is Hg→w = 535 cal/mol so the entropy of transformation is Sg→w = Hg→w/T0 = 535/292 = 1.83 cal/mol K. Adding this to the result of Eq. (4.5) gives 12.36 cal/mol K, in reasonable agreement with Eq. (4.4).
The third law can also shed light on the behavior of the coefﬁcient of thermal expansion, α, and the compressibility, κT , as T → 0. Since S → 0 as T → 0 independent of V or p, one has

∂S

= 0;

∂V T =0

∂S

= 0.

∂p T =0

(4.6)

Through a Maxwell relation (see Eq. (5.90)), it can be shown that

∂S ∂p

=−
T

∂V ∂T

= −V α,
p

(4.7)

where α is the coefﬁcient of isobaric thermal expansion. Indeed, it has been veriﬁed experimentally that α → 0 as T → 0. By means of another Maxwell relation (see Eq. (5.86))

52 THERMAL PHYSICS

∂S ∂V

=
T

∂p ∂T

= α/κT ,
V

(4.8)

where κT is the coefﬁcient of isothermal compressibility. Thus, κT must either remain nonzero as T → 0 or go to zero more slowly than α.

See Lupis [5, pp. 21-23] for further discussion of experimental veriﬁcation of the third

law as well as a discussion of some of its other consequences, particularly consequences

concerning chemical reactions. See Fermi [1, p. 150] for an excellent discussion of the

entropy of mercury vapor.

5
Open Systems

Until now we have dealt with chemically closed thermodynamic systems in which there is no exchange of chemical components with the environment. Such chemically closed systems can receive heat Q from the environment and do work W on their environment. Their change in internal energy is given by U = Q − W, which for inﬁnitesimal changes is dU = δQ − δW. For reversible changes in a simple isotropic system, the (quasistatic) work is δW = p dV , where p is the pressure and V is the volume. The heat received in a reversible change is δQ = T dS, where T is the absolute temperature and S is the entropy. If the mole numbers of each chemical component are constant (no chemical reactions), the combined ﬁrst and second laws (see Chapter 3) lead to

dU = T dS − p dV .

(5.1)

Open systems can exchange chemical components with their environment. Consequently the number of moles of each chemical component, Ni, for i = 1, 2, . . . , κ, are variables. This requires several modiﬁcations. The ﬁrst law must be amended to read

U = Q − W + Ech,

(5.2)

where Ech is the energy (sometimes called chemical heat) that is added to the system when chemical components are exchanged with its environment. Moreover, U now becomes a
function of S, T and all of the Ni, so additional terms are needed in Eq. (5.1). This also sets the stage for changes of Ni due to chemical reactions within the system, which can even occur for a chemically closed system for which Ech = 0. We shall ﬁrst treat an open system having a single component and then go on to treat multicomponent systems.

5.1 Single Component Open System

If the simple chemically closed isotropic system discussed above has only one chemical
component and is now opened to allow exchange of that component with the environment, U must be regarded as a function of S, V , and N , the number of moles1 of that component. Then the differential of the internal energy becomes

dU = T dS − p dV + μ dN,

(5.3)

where now

T=

∂U

∂S

;
V ,N

−p =

∂U

∂V

;
S,N

μ=

∂U

∂N

.
S,V

(5.4)

1Instead of N, we could use the mass, M or the number of atoms N . Then the resulting chemical potentials would be per unit mass or per atom instead of per mole.

Thermal Physics. http://dx.doi.org/10.1016/B978-0-12-803304-3.00005-3

53

Copyright © 2015 Elsevier Inc. All rights reserved.

54 THERMAL PHYSICS

The quantity μ, introduced originally by Gibbs [3], is called the chemical potential, by analogy to the thermal potential T. We shall see later that μ can be expressed as a function of only p and T. It is the internal energy per mole2 of component added reversibly to the system at constant S and V . Nevertheless, Eq. (5.3) is a relationship among state functions and always holds for inﬁnitesimal changes within the ﬁeld of equilibrium states.

5.1.1 Ideal Gas

The chemical potential of a monocomponent ideal gas can be written in the form

μ(T ,

p)

=

μ∗(T

)

+

RT

ln

p

=

RT

ln

p p∗(T

)

,

(5.5)

where p∗(T) is a function of temperature with dimensions of pressure. In this standard but misleading notation, μ∗(T) is a function of temperature only but does not have the dimensions of an energy. This can be ﬁxed by writing μ∗(T) + RT ln p = μ∗(T) + RT ln p0 +
RT ln p/p0, where p0 is a reference pressure, usually taken to be one atmosphere. Then the quantity μ0(T, p0) = μ∗(T) + RT ln p0 is the chemical potential of this ideal gas at p0 and
we can write Eq. (5.5) in the form

μ(T , p) = μ0(T , p0) + RT ln p/p0.

(5.6)

Moreover, if p0 is equal to one atmosphere, it is often omitted from formulas with the understanding that all pressures are expressed in atmospheres. In this case, the term RT ln p0 = 0, so numerically μ∗(T) = μ0(T, p0), even though the dimensions do not agree. We avoid this shortcut in the interest of clarity, so pressures can be measured in any units.
Even though each term on the right of Eq. (5.6) depends on p0, their sum is independent of p0. Even for a real gas, liquid, or solid, μ(T, p) must be independent of any reference pressure such as p0.

Example Problem 5.1. For N moles of an ideal gas, the equation of state Eq. (2.12) takes the
form pV = NRT . Show that its chemical potential can be expressed as a function of only its concentration c = N/V and the temperature. At the standard temperature T0 = 25 ◦C and a pressure of one standard atmosphere (1.01325 × 105 Pa), the volume of one mole of an ideal gas
is 22.4 l. If one mole of gas remains at temperature T0 but is compressed so that it occupies only 2 l, how much does its chemical potential change compared to that at standard temperature
and pressure?

Solution 5.1. We substitute p = cRT into Eq. (5.5) to obtain

μ = μ∗(T ) + RT ln cRT = μ∗(T ) + RT ln RT + RT ln c.

(5.7)

2Since U is only deﬁned up to an additive constant, μ is similarly only deﬁned up to a compatible additive constant. In practice, one usually adopts so-called standard states and deals with the quantities μ − μ0, where μ0 refers to the standard state.

Chapter 5 • Open Systems 55

The change in chemical potential at temperature T0 is μ = RT0 ln c/c0 = RT0 ln(22.4/2) = 2.416RT0. We have T0 = 25 + 273.15 = 298.15 K, so RT0 = 2479 J and μ = 5868 J. Alternatively, we could evaluate the new pressure, which would be p = 11.2 atmospheres, and use Eq. (5.6) to
get the same answer. At a given temperature, we see that the chemical potential of an ideal gas
is just a measure of concentration, or pressure, on a logarithmic scale.

Example Problem 5.2. According to statistical mechanics, the chemical potential per atom of
a monatomic gas having atoms of mass m is given by kBT ln[n/nQ(T )], where kB is Boltzmann’s constant, n is the number of atoms per unit volume, and nQ(T ) is the quantum concentration given by nQ(T ) = (mkBT /2πh¯ 2)3/2, where h¯ = h/2π and h is Planck’s constant. This result
is based on a convention for the zero of energy used to deduce the quantum states of a free particle; see Section 19.3.1 for details. Find explicit expressions for p∗(T ) and μ∗(T ) in Eq. (5.5).

Solution 5.2. To obtain the chemical potential per mole, we simply multiply the given

chemical potential per atom by Avogadro’s number NA and recall that NAkB = R. The ideal gas law can similarly be converted to obtain p = nkBT . Therefore,

μ = RT ln

p

nQ(T )kBT

(5.8)

from which we identify

p∗(T ) = nQ(T )kBT = (mkBT /2πh¯ 2)3/2kBT .

(5.9)

Of course μ∗(T ) = −RT ln p∗(T ). Formally, numerical evaluation of μ∗(T ) involves taking the logarithm of a quantity with dimensions of pressure, but the units in which pressures are expressed will cancel when μ is evaluated, as illustrated by Eq. (5.8).

5.2 Multicomponent Open Systems

The generalization of Eq. (5.3) to open multicomponent systems is straightforward. U now

depends on the variable set S, V , N1, N2, . . . , Nκ for a system of κ chemical components. Then

κ

dU = T dS − p dV + μi dNi,

(5.10)

i=1

where

T=

∂U

∂S

;
V ,{Ni }

−p =

∂U

∂V

;
S,{Ni }

μi =

∂U

∂ Ni

.
S,V ,{Ni }

(5.11)

Here, {Ni} stands for the entire set N1, N2, . . . , Nκ , and {Ni} stands for that same set but with Ni missing. Since this notation is cumbersome, we will often omit these subscripts, but they should always be borne in mind to avoid confusion. Equation (5.11) deﬁnes κ + 2
intensive variables (p, T, and κ chemical potentials, one for each chemical component),
although we shall see that only κ + 1 of them are independent (see Eq. (5.45)). One says

56 THERMAL PHYSICS

that such a thermodynamic system has κ + 1 degrees of freedom. These thermodynamic
degrees of freedom should not be confused with the number of degrees of freedom (typically of order 1023) of the underlying microscopic system. Equation (5.11) is valid for all inﬁnitesimal changes of S, V , {Ni} within the ﬁeld of equilibrium states and these changes are reversible.

5.2.1 Maxwell Relations for Open Systems

In general, Maxwell relations are obtained by equating the mixed second derivatives of a function of two or more variables. Suppose that we have some function f of three variables, x, y, and z. Then

df =

∂f ∂x

dx +
y,z

∂f ∂y

dy +
z,x

∂f

∂z

dz
x,y

(5.12)

and3

∂2f

∂2f

∂2f

∂2f

∂2f

∂2f

∂x∂y = ∂y∂x ; ∂y∂z = ∂z∂y ; ∂z∂x = ∂x∂z .

(5.13)

Equations (5.12) and (5.13) can be extended to any number of dependent variables. If we apply Eq. (5.13) to the ﬁrst two members of Eq. (5.10), we obtain

∂T

= − ∂p

.

∂V S,{Ni}

∂S V ,{Ni}

(5.14)

Since all Ni are held constant in Eq. (5.14), it would also hold for a chemically closed system in which there are no chemical reactions. For an open system, we have additional Maxwell relations such as

∂T

= ∂μi

,

∂Ni S,V ,{Ni }

∂S V ,{Ni }

(5.15)

and for i = j

− ∂p

= ∂μi

,

∂Ni S,V ,{Ni }

∂V S,{Ni}

(5.16)

∂ μi

=

∂Nj S,V ,{Nj }

∂ μj ∂ Ni

.
S,V ,{Ni }

(5.17)

For a system having κ chemical components, the number of these Maxwell relations is (κ + 2)(κ + 1)/2.
Additional Maxwell relations may be obtained by solving Eq. (5.10) for the differential of another variable, for example,

3These relations are true if the derivatives exist and are continuous, which we will assume to be the case for thermodynamic functions.

Chapter 5 • Open Systems 57

dS = 1 dU + p dV −

T

T

κ

μi T

dNi.

i=1

(5.18)

Then

∂(1/T )

=

∂V

U,{Ni }

∂(p/T )

∂U

,
V ,{Ni }

(5.19)

∂(1/T )

= − ∂(μi/T )

,

∂Ni U,V {Ni }

∂U

V ,{Ni }

(5.20)

and for i = j

∂(p/T ) =−
∂Ni U,V {Ni }

∂(μi/T ) ∂V

,
U,{Ni }

(5.21)

∂(μi/T )

=

∂ Nj

U,V ,{Nj }

∂(μj/T ) ∂ Ni

.
U,V ,{Ni }

(5.22)

Maxwell relations may be used to simplify thermodynamic expressions and also to derive formulae for desired quantities in terms of experimentally measurable quantities.

Example: relationship of Cp to CV: A useful result of Maxwell relations is the general formula (previously quoted in Eq. (2.16) without proof ) that connects the heat capacity
at constant pressure Cp to that at constant volume, CV . Here, we deal with a chemically closed system in the absence of chemical reactions, so we drop the subscripts {Ni} for the sake of simplicity. From the deﬁnitions CV := (δQ/dT)V and Cp := (δQ/dT)p and δQ = dU + p dV for quasistatic work, we have

CV =

∂U ∂T V

and

(5.23)

CP =

∂U ∂T

+p
p

∂V ∂T

=
p

∂U + ∂T V

∂U ∂V T

∂V ∂T

+p
p

∂V ∂T

.
p

(5.24)

Therefore,

Cp = CV +

∂U + p ∂V T

∂V .
∂T p

(5.25)

To get the derivative (∂U/∂V )T , we make use of the fact that the entropy is a function of state with differential

dS = 1 dU + p dV = 1

T

T

T

∂U ∂T

dT +
V

1 T

∂U ∂V

+p TT

dV ,

(5.26)

where we now regard S to be a function of T and V . Therefore

∂ ∂V

1 T

∂U ∂T V

=∂ 1

T

∂T T

∂U + p ∂V T T

,
V

(5.27)

58 THERMAL PHYSICS

which becomes

1 T

∂2U ∂V ∂T

=

1 T

∂2U ∂T∂V

−

1 T2

∂U ∂V

+p
T

+1 T

∂p

∂T

.
V

After cancellation of the mixed partial derivatives, Eq. (5.28) gives4

(5.28)

∂U ∂V

+p =T
T

∂p ∂T

,
V

which may be substituted into Eq. (5.25) to give

(5.29)

Cp = CV + T

∂p ∂T V

∂V

∂T

.
p

(5.30)

Finally, we use the relation5

∂p ∂T V

∂T ∂V

p

∂V ∂p

= −1
T

(5.31)

to eliminate ∂p/∂T V . Then the deﬁnitions of the coefﬁcient of expansion α := (1/V ) (∂V /∂T)p and the compressibility κT := −(1/V ) ∂V /∂p T lead to

Cp

=

CV

+

TV α2 ,
κT

(5.32)

which is the same as Eq. (2.16). The isothermal compressibility κT is always positive whereas the coefﬁcient of thermal expansion α is usually positive but can be negative or even zero, as it is for water near 4 ◦C. Since Eq. (5.32) depends on α2, we see that
Cp − CV ≥ 0. For gases, Cp can be considerably larger than CV but for condensed phases the difference between them is relatively small.

Example: relationship of Cp to CV, alternative method: For a reversible change we have δQ = T dS, so we can write

Thus

CV = T

∂S ∂T V

and

Cp = T

∂S ∂T

=T
p

∂S ∂T

+T
V

∂S ∂V

T

∂V ∂T

.
p

(5.33) (5.34)

Cp = CV + T

∂S ∂V

T

∂V ∂T

.
p

(5.35)

4This is called the Helmholtz equation and sometimes written (∂U/∂V )T = T 2 ∂(p/T )/∂T V . 5This relation follows immediately from the differential dV = (∂V /∂T)p dT + ∂V /∂p T dp by setting dV = 0 and solving for the remaining partial derivative.

Chapter 5 • Open Systems 59

To ﬁnd an expression for (∂S/∂V )T , we invent a new state function6 F := U − TS so that

dF = dU − T dS − S dT = −S dT − p dV .

(5.36)

Regarding F to be a function of T and V , we see that

∂S ∂V

=
T

∂p ∂T

,
V

so Eq. (5.35) becomes Eq. (5.30) and Eq. (5.32) follows as above.

(5.37)

5.2.2 Other Maxwell Relations
Maxwell relations can be obtained by equating the mixed second partial derivatives of any state function. This is usually done by deﬁning other functions that are related to U and S by means of Legendre transformations. A number of speciﬁc examples are presented in Section 5.5.1. Tables of some Maxwell relations and a mnemonic diagram for remembering them are given by Callen [2, chapter 7] but many others exist and can be derived as needed.

5.3 Euler Theorem of Homogeneous Functions

A function f (x, y, z) is said to be a homogeneous function of degree n with respect to the variables x, y, and z if

f (λx, λy, λz) = λnf (x, y, z),

(5.38)

where λ is some parameter. Note that Eq. (5.38) requires a very special type of function and

that many functions are not homogeneous. For a homogeneous function of degree n, the

Euler theorem states that

x

∂f ∂x

+y
y,z

∂f ∂y

+z
z,x

∂f ∂z

= nf (x, y, z).
x,y

(5.39)

This theorem, illustrated for three dependent variables, holds for any number of dependent variables.

Proof. We differentiate Eq. (5.38) partially with respect to λ to obtain

∂f

(λx, λy, λz) ∂ (λx)

∂ (λx) ∂λ

+

∂f

(λx, λy, λz) ∂ (λy )

∂ (λy ) ∂λ

+

∂f

(λx, λy, ∂ (λz)

λz)

∂ (λz) ∂λ

=

nλn−1 f

(x, y, z)

(5.40)

and note that ∂(λx)/∂λ = x, ∂(λy)/∂λ = y and ∂(λz)/∂λ = z. After the differentiation is done, we set λ = 1 in Eqs. (5.40) and (5.39) results. Note especially that if the function f depends on additional variables, say u and v , such that

f (λx, λy, λz, u, v ) = λnf (x, y, z, u, v ),

(5.41)

6This state function is actually the Helmholtz free energy, a useful thermodynamic potential that we shall deﬁne later. For now, it is just a convenient state function that will allow us to get the desired result.

60 THERMAL PHYSICS

Eq. (5.39) still holds, with no corresponding terms for u and v . In other words, Eq. (5.41) should be interpreted to mean that f is homogeneous in the variables x, y, and z; the variables u and v are held constant during differentiation and are simply irrelevant insofar as homogeneity with respect to x, y, and z is concerned.

Examples: The function φ(x, y, z) := x2 + y2 + z4/(x2 + y2) is a homogeneous function of degree 2 in x, y, and z. We have ∂φ/∂x = 2x − 2xz4/(x2 + y2)2, ∂φ/∂y = 2y − 2yz4/(x2 + y2)2, and ∂φ/∂z = 4z3/(x2 + y2). Thus

∂φ x ∂x

+

y

∂φ ∂y

+

z

∂φ ∂z

=

2x2

−

2x2z4 (x2 + y2)2

+ 2y2

−

2y2z4 (x2 + y2)2

+

4z3 x2 + y2

=

2φ.

The function ψ(x, y, z) := sin(x/y) + z2/x2 is a homogeneous function of degree zero in x, y, and z. We have ∂ψ/∂x = (1/y) cos(x/y) − 2z2/x3, ∂ψ/∂y = −(x/y2) cos(x/y) and ∂ψ/∂z = 2z/x2, which yields x∂ψ/∂x + y∂ψ/∂y + z∂ψ/∂z = 0.
The function η(x, y, z) := x3 + y3 + z2 is not a homogeneous function with respect to the variables x, y, and z. The function ζ(x, y, z) := x3z + y3z2 is not a homogeneous function
with respect to the variables x, y, and z, but it is a homogeneous function of degree 3 in x
and y with z held constant. Then x(∂ζ /∂x)y,z + y ∂ζ /∂y x,z = 3ζ . Note that it is not necessary for n to be an integer, and that n can even be negative.
Thus, the function φ(x, y, z) := (x/yz)1/3 + (1/x)1/3 is a homogeneous function of degree
n = −1/3 in x, y, and z and Eq. (5.39) holds, as the reader may verify.

5.3.1 Euler Theorem Applied to Extensive Functions

We note that U, which is extensive, is a homogeneous function of degree one in the extensive variables S, V , N1, N2, . . . , Nκ . Thus,

U(λS, λV , λN1, λN2, . . . , λNκ ) = λU(S, V , N1, N2, . . . , Nκ ).

(5.42)

For example, if we double all of the extensive variables on which U depends, we will obtain a system that is twice as large but whose intensive variables are unchanged,7 so we will
have twice as much of the same thermodynamic state. Applying the Euler theorem for n = 1, we obtain

κ
U = TS − pV + μiNi.
i=1

(5.43)

We call this the Euler equation for U. By taking its differential, we obtain

κ

κ

dU = T dS + S dT − p dV − V dp + μi dNi + Ni dμi.

i=1

i=1

(5.44)

7This follows because the intensive variables are partial derivatives of the extensive variable U with respect to the extensive variables on which U depends, so any constant multiple such as 2 will cancel.

Chapter 5 • Open Systems 61

By comparing with Eq. (5.10), we deduce that

κ
0 = S dT − V dp + Ni dμi.
i=1

(5.45)

Eq. (5.45) is the Gibbs-Duhem equation for a multicomponent system. It shows that T, p, and the μi are not independent intensive variables because changes in them are related. Thus for a κ component system, there are only κ + 1 independent intensive variables.
For a monocomponent system, there are two independent intensive variables, say p and T, and μ(p, T) can be regarded to be a function of them.8 In that case, Eq. (5.45) can be divided by N and written in the form

dμ = −s dT + v dp,

(5.46)

where s := S/N is the entropy per mole and v := V /N is volume per mole (molar volume). If the functions s(T, p) and v (T, p) are known (these are the two equations of state of the system), Eq. (5.46) can be integrated to determine μ up to an additive constant that results from the arbitrary zero of energy. For a two component system, there would be three independent intensive variables, say p, T, and μ1, and then μ2(p, T, μ1). For a three component system, there would be four independent intensive variables, etc.

Example Problem 5.3. By using the chemical potential of an ideal gas given by Eqs. (5.5) and
(5.46), determine its equations of state. From these results, calculate the enthalpy per mole h and the internal energy per mole u and comment on their dependence on pressure. Deduce the relationship between the molar heat capacities cV and cp at constant volume and constant pressure and compare with Eq. (2.13).

Solution 5.3. We have v = one equation of state. Also, s

=∂μ−/(∂∂pμ/T∂=T )RpT=/p−, dwμh∗ic(Th

just reproduces the ideal gas law, which is )/dT − R ln p, which is the other equation

of state. Thus, by dividing the Euler equation Eq. (5.43) for a single component by N, we obtain

u = Ts − pv + μ, so the molar enthalpy

h

=

u

+

pv

=

μ

+

Ts

=

μ∗(T )

−

T

dμ∗(T ) ,

dT

(5.47)

which is a function of only the temperature, independent of pressure. Moreover,

u = h − pv = μ∗(T ) − T dμ∗(T ) − RT , dT

(5.48)

which is also a function of only the temperature, independent of v . We readily compute cp = dh/dT = −T d2μ∗(T )/dT 2 and cv = du/dT = cp − R in agreement with Eq. (2.13), even if cp and cv depend on T .

8We could make other choices, such as regarding T and μ as the independent variables, and then writing p(T, μ).

62 THERMAL PHYSICS

Composition: For multicomponent systems, one often regards the independent intensive variables as being p, T, and composition, where composition9 is designated by the κ − 1
independent mole fractions

Xi := Ni/N,

(5.49)

where N =

κ i=1

Ni

is

the

total

number

of

moles.

Note

that

the

Xi

are

intensive

variables,

because they are ratios of extensive variables. Moreover, we have

κ
Xi = 1
i=1

(5.50)

so only κ −1 of them are independent, as already stated. Taking the differential of Eq. (5.50) gives

κ
dXi = 0
i=1

(5.51)

so we note that it is impossible to take a partial derivative with respect to one of the Xi while holding all of the others constant. In particular, we cannot calculate chemical potentials by taking a single partial derivative with respect to an Xi, that is,

μi =

∂U ∂Xi S,V ,{Xi }

(5.52)

because the right-hand side is meaningless.
For a system with two components, we could take a set of the independent intensive variables to be p, T, and X1, in which case μ1(p, T, X1) and μ2(p, T, X1). For three components, independent intensive variables could be p, T, X1, and X2, in which case μ1(p, T, X1, X2), μ2(p, T, X1, X2), and μ3(p, T, X1, X2). To recover an extensive description, we could add to these variable sets N or any one of the Ni.

Enthalpy of a multicomponent system: Recall that we deﬁned the enthalpy H := U + pV . For a multicomponent system

κ
dH = dU + p dV + V dp = T dS + V dp + μi dNi,
i=1

(5.53)

9For a mass based description, we can describe composition by the mass fractions ωi := Mi/M, where Mi is

the mass of the ith component and M =

κ i=1

Mi

is

the

total

mass.

The

relationship

of

the

ωi

to

the

Xi

is

nonlinear

and depends on the molecular masses, mi. Speciﬁcally, ωi = miXi/ j mjXj.

Chapter 5 • Open Systems 63

where Eq. (5.10) has been used. Thus, H is a natural function10 of S, p, and the Ni and we have

T=

∂H ;
∂S p,{Ni}

V=

∂H ;
∂p S,{Ni}

μi =

∂H .
∂Ni S,p,{Ni }

(5.54)

Furthermore, with regard to homogeneity, we see that

H(λS, p, λN1, λN2, . . . , λNκ ) = λH(S, p, N1, N2, . . . , Nκ )

(5.55)

because p, being intensive, does not participate. Thus, application of the Euler theorem gives

κ
H = TS + μiNi
i=1

(5.56)

which is in agreement with Eq. (5.43) once the deﬁnition of H is used. So we actually get nothing new (except self-consistency) and Eq. (5.45) follows as well.

5.3.2 Euler Theorem Applied to Intensive Functions

Intensive functions are homogeneous functions of degree zero with respect to extensive variables. For example, the energy u := U/N per mole or the energy uV := U/V per unit volume are intensive. They are therefore homogeneous functions of degree zero in the variables S, V , N1, N2, . . . , Nκ , which means that they can depend only on ratios of these variables, which ratios are themselves intensive. To see this formally, note that

u

=

U(S, V , N1, N2, . . . , Nκ ) N

=

U(λS, λV , λN1, λN2, . . . , λNκ ) λN

and then choose λ = 1/N to deduce

(5.57)

u = U(s, v , X1, X2, . . . , Xκ ),

(5.58)

where s = S/N is the entropy per mole and v = V /N is the volume per mole. But since the Xi are not all independent we can omit the last of them and write, in terms of κ + 1 independent variables,

u = u(s, v , X1, X2, . . . , Xκ−1)

(5.59)

whose differential turns out to be
κ −1
du = T ds − p dv + (μi − μκ ) dXi.
i=1

(5.60)

10A natural function is a thermodynamic potential that contains information equivalent to a fundamental equation (for U or S) and whose independent variables are either members of the original complete set of extensive variables (on which U or S depends) or their conjugate variables (which are the partial derivatives of U or S with respect to their extensive variables).

64 THERMAL PHYSICS

Equation (5.60) can be veriﬁed by taking the differential of Eq. (5.57) and using Eqs. (5.10) and (5.43) to simplify the result. Thus

du

=

dU N

−

U N2

dN

=

1 N

κ
T dS − p dV + μi dNi
i=1

−

1 N2

κ
TS − pV + μiNi
i=1

dN .

(5.61)

But ds = dS/N − (S/N 2) dN , dv = dV /N − (V /N 2) dN and dXi = dNi/N − (Ni/N 2) dN , so Eq. (5.61) becomes

κ
du = T ds − p dv + μi dXi,
i=1

(5.62)

which reduces to Eq. (5.60) after dXκ is eliminated. Note in this derivation that the total number of moles N was treated as a variable, even though the result appears as if we just treated it as a constant and divided by it.
In a similar way, we can deduce that

uV = u(sV , c1, c2, . . . , cκ ),

(5.63)

where sV := S/V is the entropy per unit volume and the ci := Ni/V are the concentrations of each component (in moles per unit volume). The corresponding differential is

κ
duV = T dsV + μi dci.
i=1

(5.64)

Similar considerations apply to other intensive variables, such as the enthalpy h := H/N per mole, which is a function of s, p, X1, X2, . . . , Xκ−1 and whose differential is

κ −1
dh = T ds + v dp + (μi − μκ ) dXi.
i=1

(5.65)

5.4 Chemical Potential of Real Gases, Fugacity

As a further application of Eq. (5.46), we treat the dependence of the chemical potential of a pure non-ideal gas on temperature and pressure by means of a function known as the fugacity (see, for example, Denbigh [18, p. 125]). To do this, we replace Eq. (5.5) by

μ(T , p) = μ∗(T ) + RT ln f ; f → p as p → 0.

(5.66)

The fugacity f (T, p) is an effective pressure11 that replaces the pressure p of an ideal gas. Equation (5.66) is based on the idea that all gases will tend toward ideal gas behavior if sufﬁciently dilute, which will be the case for ﬁxed temperature at sufﬁciently low pressure. Therefore, the function μ∗(T) is precisely the same function of T as for the corresponding ideal gas.

11One can also employ a dimensionless fugacity f D = f /p0, where p0 is a reference pressure, by adding a term RT ln p0 to μ∗(T ). Then if p0 = 1 atmosphere and pressures are measured in atmospheres, the term RT ln p0 = 0 numerically.

Chapter 5 • Open Systems 65

1400
1200
1000
800 f
600
400
200

O2 Ideal CO2

200 400 600 800 1000 p
FIGURE 5–1 Fugacity f (atmospheres) versus pressure p (atmospheres) of O2 and CO2 at T = 200 ◦C based on a cubic spline ﬁt of data of Darken and Gurry [19, p. 210]. The middle line is for an ideal gas for which f = p. The lowest data points are for p = 50 atmospheres for which f = 50.5 atmospheres for O2 and 47.8 atmospheres for CO2.

The general dependence of the fugacity on pressure may be deduced by integrating the

equation

v (T , p) =

∂μ(T , p) ∂p

= RT
T

∂ ln f ∂p

;
T

f → p as p → 0.

(5.67)

In order to avoid a singularity and to incorporate the condition on f at low pressures, we

rewrite Eq. (5.67) in the form

∂ ln(f /p) ∂p

=

v (T , p)

−

1 .

T

RT

p

Then integration on pressure at constant temperature from 0 to p gives

(5.68)

ln(f /p) = p v (T , p ) − 1 dp .

0

RT

p

(5.69)

If the gas is ideal, the integrand vanishes and one obtains simply f = p. Depending on the
temperature, many gases behave like ideal gases at atmospheric pressure p0, but at high pressures the deviations from ideality can be quite signiﬁcant. Figure 5–1 shows a plot of fugacity versus pressure for the gases O2 and CO2 at a temperature of 200 ◦C, as well as for an ideal gas, for which f = p at all temperatures. Note the opposite deviations from ideality.

Example Problem 5.4. Suppose that a non-ideal gas has an expansion (called a virial
expansion) in terms of pressure of the form

v (T , p) = 1 1 + B˜ p + C˜ p2 + · · · = 1 + B˜ + C˜ p + · · · ,

RT

p

p

(5.70)

66 THERMAL PHYSICS

where B˜ (T ) and C˜ (T ) are virial coefﬁcients that depend on the temperature. Calculate the
fugacity of this gas. For a simple model based on a potential consisting of a hard repulsive core of diameter σ1, an attractive potential well of constant depth ε in the annular region between a sphere of diameter σ2 and the repulsive core, and zero potential beyond, the ﬁrst virial coefﬁcient is given by

B˜ (T ) = 2π σ13 − (eε/kBT − 1)(σ23 − σ13) .

3

kBT

(5.71)

If this is the only important virial coefﬁcient, discuss brieﬂy the effect of temperature on the fugacity.
Solution 5.4. Equation (5.69) becomes

p
ln[f (T , p)/p] = [B˜ + C˜ p + · · · ]dp = B˜ (T )p + (C˜ (T )/2)p2 + · · · .
0

(5.72)

Thus,

f (T , p) = p exp[B˜ (T )p + (C˜ (T )/2)p2 + · · · ].

(5.73)

The ﬁrst virial coefﬁcient given by Eq. (5.71) becomes B˜ (T ) = −(2π/3)(σ23 − σ13)(eε/kBT /kBT ) at low temperatures and B˜ (T ) = (2π/3)(σ13/kBT ) at high temperatures. It therefore changes sign from negative to positive as the temperature increases. If this is the only important virial
coefﬁcient, f < p and varies strongly with temperature for low temperatures and f > p and
varies weakly with temperature for high temperatures.

Example Problem 5.5. For the previous example, compare the chemical potential difference
μ(T , p) − μ(T , p0) for a real gas with that for a condensed phase (solid or liquid) for which the molar volume is given approximately by v (T , p) = v (T , p0)[1−κT (p−p0)], where the isothermal compressibility κT is evaluated at p0.
Solution 5.5. For the real gas,

μ(T , p) − μ(T , p0) = RT ln(p/p0) + B˜ (T )(p − p0) + (C˜ (T )/2)(p2 − p20) + · · · .

(5.74)

The term RT ln(p/p0) is very important and the other terms represent a small correction unless the pressure is very large.
For a condensed phase, the integral of ∂μ(T , p)/∂p T = v (T , p) at constant temperature yields

μ(T , p) − μ(T , p0) = v (T , p0)[(p − p0) − (κT /2)(p − p0)2], solid or liquid.

(5.75)

Except for very large pressure differences, this difference is small compared to RT . Therefore, for gases the chemical potential has a signiﬁcant dependence on pressure but for
condensed phases it is practically independent of pressure.

Chapter 5 • Open Systems 67

5.5 Legendre Transformations

Legendre transformations are frequently used in thermodynamics to deﬁne new functions that depend on a convenient variable set. An example is the enthalpy function H = U +pV discussed in Chapter 2 with differential given by Eq. (5.53) for a multicomponent system. In Chapter 6 we will show how some of these functions can be used to formulate useful criteria for thermodynamic equilibrium. Here we cover some formal aspects of such transformations.
We treat a system having κ chemical components and for which dU is given by Eq. (5.10) which we write in the schematic form

κ +2
dU = pi dEi.
i=1

(5.76)

The extensive variables E1 = S, E2 = V , and Ei+2 = Ni for i = 1, 2, . . . , κ. Evidently

pi =

∂U ,
∂Ei {Ei}

(5.77)

so the corresponding (intensive) potentials are p1 = T, p2 = −p, and pi+2 = μi for i = 1, 2, . . . , κ. The variables pi and Ei are called conjugate variables. We now deﬁne a Legendre transform by means of the function

Lj := U − pjEj = U − Ej

∂U ∂ Ej

,
{Ej }

(5.78)

obtained by subtracting from U the product of the conjugate variables pj and Ej. We obtain

κ +2
dLj = dU − pj dEj − Ej dpj = −Ej dpj + pi dEi.
i=j

(5.79)

We can regard Lj to be a function of pj and the remaining Ei for i = j. In other words, Lj depends on the slope of the function U with respect to Ej. Moreover, Lj itself is the Ej = 0 intercept of a graph of U versus Ej. Since a curve may be deﬁned by the envelope of its tangent lines, a knowledge of intercept Lj as a function of slope pj is equivalent to a knowledge of U as a function of Ej, regarding all of the remaining Ei, for i = j to be ﬁxed. See Callen [2, p. 140] for an extended discussion of this equivalence. Given the function Lj, Eq. (5.79) yields

Ej = −

∂ Lj ∂ pj

.
{Ej }

(5.80)

We can therefore write the inverse of Eq. (5.78) in the form

U = Lj + pjEj = Lj − pj

∂ Lj ∂ pj

.
{Ej }

(5.81)

68 THERMAL PHYSICS

We note the reciprocity (with appropriate sign changes) of the relationship between

U and Lj, so they can be regarded as Legendre transforms of one another. We next obtain a useful relation between second derivatives of Legendre transforms.

We have

∂2U ∂ Ej2

=

∂ pj ∂ Ej

= − ∂pj ∂ (∂ Lj /∂ pj )

=

−1/

∂ 2 Lj ∂ p2j

.

(5.82)

Thus if U is a convex function (positive second derivative) of Ej, then Lj will be a concave function (negative second derivative) of pj.

Simple example: For a single variable E, suppose that U = A + BE2, where A and B are constants. Then p = ∂U/∂E = 2BE and L = U − pE = A − BE2 = A − p2/4B. For the inverse transformation, we start with L(p) and obtain E = −∂L/∂p = p/2B. Then U = L + pE = A + p2/4B = A + BE2. We also have ∂2U/∂E2 = 2B and ∂2L/∂p2 = −1/(2B).
We could make an additional Legendre transformation by selecting a second pair of
conjugate variables, say pkEk, and subtracting from Lj. This produces a function

Ljk := Lj − pkEk = U − pjEj − pkEk = Lk − pjEj := Lkj,

(5.83)

which can be thought of as a double Legendre transform of the original U. We will then have

κ +2
dLjk = −Ej dpj − Ek dpk + pi dEi
i=j,k

(5.84)

and we can regard Ljk to be a function of pj, pk and the remaining Ei, where i = j, k.

This process can be continued up to κ + 1 successive Legendre transforms. Since the

Euler equation is U =

κ +2 i=1

piEi,

we

see

that

κ

+

2

Legendre

transforms

of

U

would

lead

identically to zero. The total number of possible transforms is therefore 2κ+2 − 2.

5.5.1 Speciﬁc Legendre Transforms
We end this section by identifying several speciﬁc Legendre transforms that play an important role in thermodynamics and statistical mechanics.

Helmholtz free energy F: We deﬁne the Helmholtz free energy by the Legendre transformation

F := U − TS

(5.85)

with differential

κ
dF = −S dT − p dV + μi dNi.
i=1

(5.86)

Effectively, the dependence of U on S is replaced by the dependence of F on T, whereas both U and F depend on V and {Ni}. Thus, F is useful in situations where T is a control

Chapter 5 • Open Systems 69

variable. We note that S = −(∂F/∂T)V ,Ni and ∂2U/∂S2 = −1/(∂2F/∂T2). A number of Maxwell relations can be deduced from dF, one being (∂S/∂V )T,{Ni} = ∂p/∂T V ,{Ni}.

Enthalpy H: We have previously mentioned the enthalpy deﬁned by

H := U + pV

(5.87)

with differential

κ
dH = T dS + V dp + μi dNi.
i=1

(5.88)

Effectively, the dependence of U on V is replaced by the dependence of H on p. We note that V = ∂H/∂p S,Ni and ∂2U/∂V 2 = −1/(∂2H/∂p2). A Maxwell relation is ∂T/∂p S,{Ni} = (∂V /∂S)p,{Ni}.

Gibbs free energy G: The Gibbs free energy is a double Legendre transformation from U or a single Legendre transformation from F or H and is deﬁned by

G := U − TS + pV = F + pV = H − TS.

(5.89)

It has a differential

κ
dG = −S dT + V dp + μi dNi.
i=1

(5.90)

The control variables for G are T and p as opposed to S and V for U. G is especially important for the study of chemical reactions that take place at various temperatures and atmospheric pressure. We note that S = −(∂G/∂T)p,Ni and V = ∂G/∂p T,Ni as well as ∂2H/∂S2 = −1/(∂2G/∂T2) and ∂2F/∂V 2 = −1/(∂2G/∂p2). One Maxwell relation is ∂S/∂p T,{Ni} = −(∂V /∂T)p,{Ni}. Other useful Maxwell relations involving the chemical potentials are ∂μi/∂p T,{Ni} = (∂V /∂Ni)T,p,{Ni } =: V¯i and (∂μi/∂T)p,{Ni} = −(∂S/∂Ni)T,p,{Ni } =: S¯i. The quantities V¯i and S¯i are known respectively as the partial molar volume and the partial molar entropy and are examples of partial molar quantities discussed in Section 5.6.

Kramers potential K : The Kramers potential, also known as the grand potential and often denoted by , is obtained by transforming all variables in U except V . It is deﬁned by

κ
K := U − TS − μiNi
i=1

(5.91)

and has a differential

κ
dK = −S dT − p dV − Ni dμi.
i=1

(5.92)

70 THERMAL PHYSICS

K depends on T, V , and all of the chemical potentials μi. We note that S = −(∂K /∂T)V ,{μi} and Ni = −(∂K /∂μi)T,V ,{μi}, where {μi} stands for the entire set {μi} of chemical potentials but with μi missing. The potential K is closely related to the grand canonical ensemble of
statistical mechanics and is also useful in problems involving surfaces and interfaces.

Massieu functions: The functions F, H, G, and K , which are known as thermodynamic potentials, are all Legendre transforms of the internal energy U. One can also begin with the entropy whose differential is given by Eq. (5.10), namely

κ
dS = (1/T ) dU + (p/T ) dV − (μi/T ) dNi.
i=1

(5.93)

Its Legendre transforms are known as Massieu functions. For example,12

M1(1/T , V , {Ni}) := S − (1/T )U ≡ S[1/T ],

(5.94)

where the last notation has been used by Callen [2, p. 151]. It has a differential
κ
dM1 = −U d(1/T ) + (p/T ) dV − (μi/T ) dNi.
i=1

(5.95)

This differential leads to the Maxwell relation

∂U

=−

∂V 1/T ,{Ni}

∂(p/T ) ∂(1/T )

= −p + T
V ,{Ni }

∂p

∂T

,
V ,{Ni }

(5.96)

which is the same as Eq. (5.29). For an ideal gas, p/T = NR/V and Eq. (5.96) yields (∂U/∂V )T,{Ni} = 0. Thus, the fact that U depends only on T for an ideal gas, which was deduced on the basis of experiments on dilute gases, follows from the ideal gas equation
of state and the second law. Some other Massieu functions are

and13

M2(U, p/T , {Ni}) : = S − (p/T )V ≡ S[p/T ];
κ
dM2 = (1/T ) dU − V d(p/T ) − (μi/T ) dNi
i=1

(5.97)

M3(1/T , p/T , {Ni}) : = S − (1/T )U − (p/T )V ≡ S[(1/T , p/T ];
κ
dM3 = −U d(1/T ) − V d(p/T ) − (μi/T ) dNi.
i=1

(5.98)

One could also add quantities such as μ1/T to S to obtain a function S[μ1/T] that depends on μ1/T instead of N1. The total number of possible transforms of the entropy is 2κ+2 − 2,
just as for the transforms of the thermodynamic potentials.

12M1 is sometimes denoted by and called the Helmholtz free entropy. 13M3 is sometimes denoted by (or by Planck) and is called the Gibbs free entropy.

Chapter 5 • Open Systems 71

Natural variables: The natural variables of a thermodynamic potential are the set of
independent variables that give complete information about the system under consid-
eration. For isotropic multicomponent ﬂuids, the natural variables of the entropy are the set of extensive variables U, V , {Ni}, where {Ni} = N1, N2, . . . , Nκ . For the internal energy, the natural variables are S, V , and {Ni}. Since S is a monotonically increasing function of U with other extensive variables held constant, one can always transform uniquely from S(U, V , {Ni}) to U(S, V , {Ni}) and vice versa for these fundamental equations. For the thermodynamic potentials, the natural variables are those independent variables that result from Legendre transformation. For example, any of the functions F(T, V , {Ni}), H(U, p, {Ni}), G(T, p, {Ni}), K (T, V , {μi}), M3(1/T, p/T, {Ni}) contain complete information about a system. It is possible and sometimes useful to express these functions in terms of
other variable sets, as discussed in the next section.

5.6 Partial Molar Quantities

This section applies to any extensive state function that can be expressed in terms of the complete variable set T, p, {Ni} for a homogeneous system having κ chemical components. For example, we could consider the internal energy U(T, p, {Ni}), even though the natural variables for U are the set S, V , {Ni}. We could also consider the entropy S(T, p, {Ni}) or the enthalpy H(T, p, {Ni}), etc. Of course a transformation of variables is necessary to convert from the set of natural variables of a function to the set T, p, {Ni}, except for G(T, p, {Ni}) where these are also its natural variables. As we shall see in Chapter 6, the temperature T and the pressure p are uniform for phases in mutual
equilibrium, so functions expressed in terms of these intensive variables are particularly
important. For the generic extensive function Y (T, p, N1, N2, . . . , Nκ ), the partial molar quantities
Y˜i are deﬁned as derivatives14

Y¯i :=

∂Y .
∂Ni T ,p,{Ni }

(5.99)

Since Y is an extensive function in the variables N1, N2, . . . , Nκ , we have

Y (T , p, λN1, λN2, . . . , λNκ ) = λY (T , p, N1, N2, . . . , Nκ )

(5.100)

so the Euler theorem gives

κ
Y = Y¯iNi.
i=1

(5.101)

Since T and p are held constant in the deﬁnition Eq. (5.99), we can differentiate the equations that deﬁne H, F, and G to obtain H¯ i = U¯ i + pV¯i, F¯i = U¯ i − TS¯i, and

14Instead of the mole numbers Ni, we could use the masses Mi of each chemical component. Then one could develop a parallel treatment in terms of partial speciﬁc quantities deﬁned by Y˜i := (∂Y /∂Mi)T,p,{Mi}.

72 THERMAL PHYSICS

G¯ i = U¯ i − TS¯i + pV¯i. Therefore, these partial molar quantities obey the same algebra as their deﬁnitions. Since the natural variables for G are T, p, {Ni}, we observe that G¯ i ≡ μi, which is just a special symbol for this very important partial molar quantity. By the same

reasoning as for Y , the corresponding Euler equations in terms of partial molar quantities are H = i H¯ iNi, F = i F¯iNi, and G = i G¯ iNi = i μiNi. Given the algebra of the
partial molar quantities just mentioned, the ﬁrst two of these are in agreement with the

Euler equations H = TS + i μiNi and F = −pV + i μiNi. For our further development, we take the volume V (T, p, N1, N2, . . . , Nκ) as a spe-
ciﬁc example, but the procedure is quite general and applies to any extensive function Y (T, p, N1, N2, . . . , Nκ ). If the partial molar volumes V¯i were constants, Eq. (5.101) for V would have the obvious interpretation that V¯i was the volume per mole actually
occupied by species i, in which case the total volume would be a linear function of the Ni. But Eq. (5.101) for Y = V is true even when the V¯i vary with composition as well as T and p. From the form of Eq. (5.99), it is clear that the V¯i are intensive
variables, so they can only depend on the ratios of the Ni. Thus, they can be expressed as functions of the independent variable set T, p, X1, X2, . . . , Xκ−1. Written out in full, we

have

κ
V (T , p, N1, N2, . . . , Nκ ) = V¯i(T , p, X1, X2, . . . , Xκ−1)Ni.
i=1

(5.102)

The differential of V is

κ
dV = V α dT − V κT dp + V¯i dNi,
i=1

(5.103)

but from V =

i V¯iNi it can also be written

κ

κ

dV = V¯i dNi + Ni dV¯i.

i=1

i=1

(5.104)

Comparison of Eqs. (5.103) and (5.104) shows that

κ
Ni dV¯i = V α dT − V κT dp,
i=1

(5.105)

which is an equation of Gibbs-Duhem type. We can divide Eq. (5.101) by N to obtain an equation for the molar volume

v := V = N

κ

V¯ i Xi .

i=1

(5.106)

For a single component material there is only one partial molar volume, V¯1=(∂V /∂N )T,p and it depends only on T and p. In that case, Eq. (5.106) takes the form

v=V = N

∂V

∂N

,
T ,p

single component.

(5.107)

Chapter 5 • Open Systems 73

In this simple case, the derivative with respect to N becomes just the ratio V /N . Equation (5.105) becomes dv = v α dT − v κT dp which can be rewritten

d ln v = α dT − κT dp, single component.

(5.108)

Thus

α=

∂ ln v

∂T

;
p

κT = −

∂ ln v

∂p

,
T

single component.

(5.109)

For a multicomponent material, we see from Eq. (5.106) that Eq. (5.107) must be replaced by

v=V = N

∂V

∂N

,
T ,p,{Xi}

multicomponent.

(5.110)

To obtain Eq. (5.110), we hold the composition constant, in addition to T and p, in Eq. (5.102) and just allow the total number of moles N to vary, so dNi = Xi dN . On the other hand, Eq. (5.108) is insufﬁcient and must be replaced by

dv

=

dV N

−

V N2

dN

= v α dT

− v κT

dp +

κ

V¯i dXi

i=1

κ −1
= v α dT − v κT dp + (V¯i − V¯κ ) dXi,
i=1

(5.111)

where the second form is written in terms of the differentials of κ + 1 independent variables. Instead of Eq. (5.109), we now have

α=

∂ ln v ;
∂T p,{Xi}

κT = −

∂ ln v ∂p

.
T ,{Xi}

(5.112)

5.6.1 Method of Intercepts
The method of intercepts provides a useful graphical representation of partial molar quantities. We illustrate it for partial molar volumes, but it applies to any partial molar quantities. We ﬁrst illustrate it for a binary system and then derive the general formulae for a multicomponent system.

Binary system: For a binary system, there are only two chemical components, so we choose an independent variable set p, T, X2. Since X1 is not a member of this set, X2 is allowed to vary freely, so we can take partial derivatives with respect to T, p, or X2 while holding the other pair constant. For a binary system, Eq. (5.106) becomes

v = V¯1X1 + V¯2X2 = V¯1(1 − X2) + V¯2X2

(5.113)

and from Eq. (5.111), with dX1 = −dX2, we obtain

∂v ∂ X2

= V¯2 − V¯1.
T ,p

(5.114)

74 THERMAL PHYSICS

V¯2 v

V¯1 T,p

X2∗

X2

FIGURE 5–2 Illustration of the method of intercepts to calculate partial molar volumes for a system of two
components. We plot a graph of v versus X2 at ﬁxed p and T . Then the partial molar volumes for some composition X2∗ are given by the intercepts of the tangent to v at X2∗. V¯ 1(T , p, X2∗) is the intercept at X2 = 0 which corresponds to pure component 1. V¯ 2(T , p, X2∗) is the intercept at X2 = 1 which corresponds to pure component 2.

We solve Eqs. (5.113) and (5.114) simultaneously for V¯1 and V¯2 to obtain

V¯1 = v − X2

∂v ∂ X2

;
T ,p

(5.115)

V¯2 = v + (1 − X2)

∂v ∂ X2

.
T ,p

(5.116)

Equations (5.115) and (5.116) are illustrated in Figure 5–2. On a graph of v versus X2 (at ﬁxed T and p) we see that the partial molar volumes for some composition X2∗ are given by the intercepts, at X2 = 0 and X2 = 1, of the tangent to v at X2∗. This graphic construction allows one to see immediately how V¯1 and V¯2 vary with composition X2∗.
For example, if V is a linear function of X2, its tangent is coincident with V itself and V¯1 and V¯2 are independent of X2. In that case, one can imagine that each component of
the solution has a ﬁxed physical volume. Moreover, if the curve V versus X2 is convex,
instead of concave as in Figure 5–2, a partial molar volume could be negative! In that case,
it makes no sense to think of a partial molar volume as a physical volume; instead, it is
only a manifestation of the slope of the V versus X2 curve, even though Eq. (5.113) still
holds.

Multicomponent system: For multicomponent systems, we use the second form of Eq. (5.111) which depends on the set of independent variables p, T, X1, X2, . . . , Xκ−1. Within this reduced variable set, we can take the partial derivative with respect to Xi to obtain

∂v ∂ Xi

= (V¯i − V¯κ );
T ,p,{Xi }

i = 1, 2, . . . , κ − 1.

(5.117)

Chapter 5 • Open Systems 75

We multiply Eq. (5.117) by Xi and sum to get

κ −1
Xi
i=1

∂v ∂ Xi

κ −1

κ −1

= XiV¯i − V¯κ Xi

T ,p,{Xi } i=1

i=1

κ −1
= XiV¯i + Xκ V¯κ − V¯κ .

i=1

(5.118)

Then by using Eq. (5.106), Eq. (5.118) becomes

κ −1
V¯κ = v − Xi
i=1

∂v

∂ Xi

.
T ,p,{Xi }

(5.119)

Equation (5.119) can be interpreted geometrically by imagining v to be plotted as a hypersurface in the coordinates X1, X2, . . . , Xκ−1. The quantity on its right-hand side is then seen to be the intercept on the v axis, at the origin of the Xi, of a hyperplane that is tangent to v at composition X1, X2, . . . , Xκ−1. Unlike the case of two components, this is not particularly easy to visualize.

Example Problem 5.6. A solution of A and B atoms at constant temperature and pressure has
a molar volume v = 3 + 2XB − XB2 cm3/mol, where XB is the mole fraction of B atoms.
(a) Use the method of intercepts to calculate the partial molar volumes V¯A and V¯B. (b) Show explicitly from your results that v = XAV¯A + XBV¯B, where XA = 1 − XB is the mole
fraction of A atoms. Why is such a relation true? (c) Show explicitly from your results that 0 = XA(dV¯A/dXB) + XB(dV¯B/dXB). Why is such a
relation true?

Solution 5.6.

(a)

We calculate V¯A XB2 − 2XB + 5.

= v (XB) − XBdv /dXB

= XB3 − 3 and V¯B

= v (XB) + (1 − XB)dv /dXB

=

(b) We can easily check that v = XAV¯A + XBV¯B, where XA = 1 − XB. This is just a special case of

Eq. (5.106).

(c) We readily compute ∂V¯A/∂XB = 2XB and ∂V¯B/∂XB = 2XB − 2 = −2XA so XA∂V¯A/∂XB + XB∂V¯B/∂XB = 0. This result follows from Eq. (5.105) for constant T and p after division by N.

5.7 Entropy of Chemical Reaction
Before leaving this chapter, we show how the formalism developed for open systems can be used to treat chemically closed systems in which the mole numbers can vary by means of chemical reactions. Then we proceed to calculate the entropy due to a chemical reaction. See Chapter 12 for a more complete treatment of chemical reactions that includes heats of reaction and detailed conditions for equilibrium.

76 THERMAL PHYSICS

We begin with Eq. (5.10) and write

dNi = dintNi + dextNi,

(5.120)

where dextNi denotes changes in Ni due to exchanges of chemical species with the external environment and dintNi denotes changes due to chemical reactions internal to the system.
For simplicity, we treat only one chemical reaction, which we write in the symbolic form

νiAi = 0,
i

(5.121)

where Ai is the symbol (such as C, CO, CO2, H, H2, etc.) of the chemical species i and νi is its stoichiometric coefﬁcient in the reaction. We regard νi to be negative for reactants and positive for products. For example, reaction of carbon and oxygen to form carbon
monoxide, namely

C + (1/2)O2 → CO

(5.122)

could be written in the form of Eq. (5.121) with A1 = C, A2 = O2, A3 = CO and ν1 = −1, ν2 = −1/2, ν3 = 1. We can therefore write

dintNi = νi dN˜ ,

(5.123)

where N˜ is a progress variable that represents the extent to which the reaction has taken place. Equation (5.10) therefore becomes

κ

κ

dU = T dS − p dV + μiνi dN˜ + μi dextNi.

i=1

i=1

(5.124)

A special case of Eq. (5.124) is a chemically closed system for which dextNi = 0, in which case it becomes

κ
dU = T dS − p dV + μiνi dN˜ .
i=1

(5.125)

Equation (5.125) replaces Eq. (3.47) when there is a chemical reaction. Combining Eq. (5.125) with the ﬁrst law dU = δQ − δW and eliminating dU, we obtain

δQ + p dV − δW − κ μiνi dN˜ = dS.

T

T

T

i=1

(5.126)

Subtracting δQ/Ts from both sides of Eq. (5.126) and applying the second law in the form of Eq. (3.4), we obtain

δQ 1 − 1 + p dV − δW − κ μiνi dN˜ = dS − δQ ≥ 0,

T Ts

T

T

i=1

Ts

(5.127)

where the inequality holds for natural irreversible processes and the equal sign holds for an idealized reversible process. Comparison with Eq. (3.52) reveals an additional term that can represent irreversible entropy production due to chemical reaction.

Chapter 5 • Open Systems 77

If only quasistatic work is done so that δW = p dV , and T = Ts so there is no entropy production due to irreversible heat transfer, Eq. (5.127) becomes

dS = δQ − κ μiνi dN˜ ≥ 0.

T

T

i=1

(5.128)

For a reversible process, the equal sign holds in Eq. (5.128) and Eq. (3.6) also holds, so

dS = δQ/T, which would require the second term on the right-hand side of Eq. (5.128)

to vanish. For dN˜ = 0, this would require

κ i

μiνi

=

0, which turns out to be the

condition that the reaction is in equilibrium. For an irreversible process, the inequality

sign in Eq. (5.128) holds, so

dS − δQ = − κ μiνi dN˜ > 0,

T

T

i=1

(5.129)

which results in entropy production due to an irreversible chemical reaction. In that case,
Eq. (3.6) would no longer hold. Such a reaction will continue until equilibrium is reached
or until at least one of the reactants in the system is used up, which will occur when dN˜ = 0.
In their book Modern Thermodynamics, Kondepudi and Prigogine [16] break the entropy change dS into external and internal parts by writing15 dS = dextS + dintS, where dextS = δQ/T and dintS ≥ 0. The inequality applies to a natural irreversible process and
the equality applies to an idealized reversible process. This leads to

κ
dintS = −

μiνi dN˜ ≥ 0.

T

i=1

(5.130)

This interpretation is consistent with our more general Eqs. (5.127) and (5.128) in the special case of Ts = T (no irreversible heat ﬂow) and no irreversible work.
For a cyclic process,

0 = dS = dextS + dintS,

(5.131)

which requires

− dextS = − δQ = dintS ≥ 0. T

(5.132)

Equation (5.132) is in agreement with Eq. (3.15) for a cyclic process during which T = Tr. When Eq. (5.130) holds, we also have

dintS = −

κ μiνi dN˜ ≥ 0. T
i=1

(5.133)

15As shown below, dextS and dintS are not exact differentials because their integrals around a closed path are not necessarily equal to zero.

78 THERMAL PHYSICS
Since S depends on U, V , and N˜ for this system, these quantities must return to their original values for a cyclic process. This means that any chemical reaction that takes place during part of a cycle must be reversed during another part of the cycle. If the inequality holds in Eq. (5.133), the chemical reaction is irreversible and entropy is produced; this requires heat to be exchanged with the system in such a way that Eq. (5.132) holds, so an equal amount of entropy is extracted from the system.

6
Equilibrium and Thermodynamic Potentials

In Chapter 3 we introduced the criterion for thermodynamic equilibrium for an isolated system in terms of the entropy. We now develop alternative criteria for equilibrium in terms of the internal energy and other thermodynamic potentials, the latter being related to the internal energy by Legendre transformations. Each of these potentials depends on a speciﬁc set of natural variables. The various resulting equilibrium criteria are useful for a situation in which a particular variable set is subject to control in an experiment. For example, many experiments on gases are conducted in a ﬁxed volume V at constant temperature T. In this case, heat must be exchanged with the environment to keep the temperature constant. Experiments on liquids or solids are often conducted at ﬁxed T and ﬁxed pressure p, in which case both heat and work must be exchanged with the environment to insure that these quantities remain constant. Therefore, our alternative equilibrium criteria will generally pertain to systems that are not isolated.

6.1 Entropy Criterion

We ﬁrst review the criterion for equilibrium in terms of the entropy, S. This criterion is based on the second law for an isolated system, according to which

S ≥ 0, isolated system, allowed changes.

(6.1)

For an isolated system, we have chemical closure, δQ = 0 and δW = 0, so dU = 0. The inequality in Eq. (6.1) pertains to a natural irreversible process and the equality corresponds to a hypothetical idealized process that is reversible. Thus for natural irreversible processes, we have

S > 0, isolated system, natural irreversible changes.

(6.2)

Equilibrium pertains to a situation in which all natural irreversible processes are forbidden.
Suppose that a composite system, which consists of a number of parts, is initially in equilibrium by virtue of some internal constraints, such as rigid, insulating, and impenetrable walls that separate its parts. When some of these constraints are removed, transformations to which Eq. (6.2) applies can occur, and the entropy can continue to increase as much as allowed by any remaining constraints until S achieves a maximum value. When this maximum value is reached, the system will no longer be able to undergo irreversible changes, and it will be in a new equilibrium state. We need not worry about

Thermal Physics. http://dx.doi.org/10.1016/B978-0-12-803304-3.00006-5

79

Copyright © 2015 Elsevier Inc. All rights reserved.

