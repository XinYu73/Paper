This page intentionally left blank

Mathematical Methods for Physics and Engineering
The third edition of this highly acclaimed undergraduate textbook is suitable for teaching all the mathematics ever likely to be needed for an undergraduate course in any of the physical sciences. As well as lucid descriptions of all the topics covered and many worked examples, it contains more than 800 exercises. A number of additional topics have been included and the text has undergone signiﬁcant reorganisation in some areas. New stand-alone chapters:
• give a systematic account of the ‘special functions’ of physical science • cover an extended range of practical applications of complex variables including
WKB methods and saddle-point integration techniques • provide an introduction to quantum operators.
Further tabulations, of relevance in statistics and numerical integration, have been added. In this edition, all 400 odd-numbered exercises are provided with complete worked solutions in a separate manual, available to both students and their teachers; these are in addition to the hints and outline answers given in the main text. The even-numbered exercises have no hints, answers or worked solutions and can be used for unaided homework; full solutions to them are available to instructors on a password-protected website.
K e n R i l e y read mathematics at the University of Cambridge and proceeded to a Ph.D. there in theoretical and experimental nuclear physics. He became a research associate in elementary particle physics at Brookhaven, and then, having taken up a lectureship at the Cavendish Laboratory, Cambridge, continued this research at the Rutherford Laboratory and Stanford; in particular he was involved in the experimental discovery of a number of the early baryonic resonances. As well as having been Senior Tutor at Clare College, where he has taught physics and mathematics for over 40 years, he has served on many committees concerned with the teaching and examining of these subjects at all levels of tertiary and undergraduate education. He is also one of the authors of 200 Puzzling Physics Problems.
M i c h a e l H o b s o n read natural sciences at the University of Cambridge, specialising in theoretical physics, and remained at the Cavendish Laboratory to complete a Ph.D. in the physics of star-formation. As a research fellow at Trinity Hall, Cambridge and subsequently an advanced fellow of the Particle Physics and Astronomy Research Council, he developed an interest in cosmology, and in particular in the study of ﬂuctuations in the cosmic microwave background. He was involved in the ﬁrst detection of these ﬂuctuations using a ground-based interferometer. He is currently a University Reader at the Cavendish Laboratory, his research interests include both theoretical and observational aspects of cosmology, and he is the principal author of General Relativity: An Introduction for

Physicists. He is also a Director of Studies in Natural Sciences at Trinity Hall and enjoys an active role in the teaching of undergraduate physics and mathematics. S t e p h e n B e n c e obtained both his undergraduate degree in Natural Sciences and his Ph.D. in Astrophysics from the University of Cambridge. He then became a Research Associate with a special interest in star-formation processes and the structure of star-forming regions. In particular, his research concentrated on the physics of jets and outﬂows from young stars. He has had considerable experience of teaching mathematics and physics to undergraduate and pre-universtiy students.
ii

Mathematical Methods for Physics and Engineering
Third Edition
K. F. RILEY, M. P. HOBSON and S. J. BENCE

cambridge university press Cambridge, New York, Melbourne, Madrid, Cape Town, Singapore, São Paulo
Cambridge University Press The Edinburgh Building, Cambridge cb2 2ru, UK Published in the United States of America by Cambridge University Press, New York www.cambridge.org Information on this title: www.cambridge.org/9780521861533
© K. F. Riley, M. P. Hobson and S. J. Bence 2006
This publication is in copyright. Subject to statutory exception and to the provision of relevant collective licensing agreements, no reproduction of any part may take place without the written permission of Cambridge University Press.
First published in print format 2006
isbn-13 978-0-511-16842-0 eBook (EBL) isbn-10 0-511-16842-x eBook (EBL)
isbn-13 978-0-521-86153-3 hardback isbn-10 0-521-86153-5 hardback
isbn-13 978-0-521-67971-8 paperback isbn-10 0-521-67971-0 paperback
Cambridge University Press has no responsibility for the persistence or accuracy of urls for external or third-party internet websites referred to in this publication, and does not guarantee that any content on such websites is, or will remain, accurate or appropriate.

Contents

Preface to the third edition Preface to the second edition Preface to the ﬁrst edition

page xx xxiii xxv

1 Preliminary algebra

1

1.1 Simple functions and equations

1

Polynomial equations; factorisation; properties of roots

1.2 Trigonometric identities

10

Single angle; compound angles; double- and half-angle identities

1.3 Coordinate geometry

15

1.4 Partial fractions

18

Complications and special cases

1.5 Binomial expansion

25

1.6 Properties of binomial coeﬃcients

27

1.7 Some particular methods of proof

30

Proof by induction; proof by contradiction; necessary and suﬃcient conditions

1.8 Exercises

36

1.9 Hints and answers

39

2 Preliminary calculus

41

2.1 Diﬀerentiation

41

Diﬀerentiation from ﬁrst principles; products; the chain rule; quotients; implicit diﬀerentiation; logarithmic diﬀerentiation; Leibnitz’ theorem; special points of a function; curvature; theorems of diﬀerentiation

v

CONTENTS

2.2 Integration

59

Integration from ﬁrst principles; the inverse of diﬀerentiation; by inspec-

tion; sinusoidal functions; logarithmic integration; using partial fractions; substitution method; integration by parts; reduction formulae; inﬁnite and

improper integrals; plane polar coordinates; integral inequalities; applications

of integration

2.3 Exercises

76

2.4 Hints and answers

81

3 Complex numbers and hyperbolic functions

83

3.1 The need for complex numbers

83

3.2 Manipulation of complex numbers

85

Addition and subtraction; modulus and argument; multiplication; complex

conjugate; division

3.3 Polar representation of complex numbers

92

Multiplication and division in polar form

3.4 de Moivre’s theorem

95

trigonometric identities; ﬁnding the nth roots of unity; solving polynomial equations

3.5 Complex logarithms and complex powers

99

3.6 Applications to diﬀerentiation and integration

101

3.7 Hyperbolic functions

102

Deﬁnitions; hyperbolic–trigonometric analogies; identities of hyperbolic

functions; solving hyperbolic equations; inverses of hyperbolic functions;

calculus of hyperbolic functions

3.8 Exercises

109

3.9 Hints and answers

113

4 Series and limits

115

4.1 Series

115

4.2 Summation of series

116

Arithmetic series; geometric series; arithmetico-geometric series; the diﬀerence method; series involving natural numbers; transformation of series

4.3 Convergence of inﬁnite series

124

Absolute and conditional convergence; series containing only real positive

terms; alternating series test

4.4 Operations with series

131

4.5 Power series

131

Convergence of power series; operations with power series

4.6 Taylor series

136

Taylor’s theorem; approximation errors; standard Maclaurin series

4.7 Evaluation of limits

141

4.8 Exercises

144

4.9 Hints and answers

149

vi

CONTENTS

5 Partial diﬀerentiation

151

5.1 Deﬁnition of the partial derivative

151

5.2 The total diﬀerential and total derivative

153

5.3 Exact and inexact diﬀerentials

155

5.4 Useful theorems of partial diﬀerentiation

157

5.5 The chain rule

157

5.6 Change of variables

158

5.7 Taylor’s theorem for many-variable functions

160

5.8 Stationary values of many-variable functions

162

5.9 Stationary values under constraints

167

5.10 Envelopes

173

5.11 Thermodynamic relations

176

5.12 Diﬀerentiation of integrals

178

5.13 Exercises

179

5.14 Hints and answers

185

6 Multiple integrals

187

6.1 Double integrals

187

6.2 Triple integrals

190

6.3 Applications of multiple integrals

191

Areas and volumes; masses, centres of mass and centroids; Pappus’ theorems; moments of inertia; mean values of functions

6.4 Change of variables in multiple integrals

199

Change of variables in double integrals; evaluation of the integral I =

∞ −∞

e−x2

dx;

change

of

variables

in

triple

integrals;

general

properties

of

Jacobians

6.5 Exercises

207

6.6 Hints and answers

211

7 Vector algebra

212

7.1 Scalars and vectors

212

7.2 Addition and subtraction of vectors

213

7.3 Multiplication by a scalar

214

7.4 Basis vectors and components

217

7.5 Magnitude of a vector

218

7.6 Multiplication of vectors

219

Scalar product; vector product; scalar triple product; vector triple product

vii

CONTENTS

7.7 Equations of lines, planes and spheres

226

7.8 Using vectors to ﬁnd distances

229

Point to line; point to plane; line to line; line to plane

7.9 Reciprocal vectors

233

7.10 Exercises

234

7.11 Hints and answers

240

8 Matrices and vector spaces

241

8.1 Vector spaces

242

Basis vectors; inner product; some useful inequalities

8.2 Linear operators

247

8.3 Matrices

249

8.4 Basic matrix algebra

250

Matrix addition; multiplication by a scalar; matrix multiplication

8.5 Functions of matrices

255

8.6 The transpose of a matrix

255

8.7 The complex and Hermitian conjugates of a matrix

256

8.8 The trace of a matrix

258

8.9 The determinant of a matrix

259

Properties of determinants

8.10 The inverse of a matrix

263

8.11 The rank of a matrix

267

8.12 Special types of square matrix

268

Diagonal; triangular; symmetric and antisymmetric; orthogonal; Hermitian

and anti-Hermitian; unitary; normal

8.13 Eigenvectors and eigenvalues

272

Of a normal matrix; of Hermitian and anti-Hermitian matrices; of a unitary

matrix; of a general square matrix

8.14 Determination of eigenvalues and eigenvectors

280

Degenerate eigenvalues

8.15 Change of basis and similarity transformations

282

8.16 Diagonalisation of matrices

285

8.17 Quadratic and Hermitian forms

288

Stationary properties of the eigenvectors; quadratic surfaces

8.18 Simultaneous linear equations

292

Range; null space; N simultaneous linear equations in N unknowns; singular value decomposition

8.19 Exercises

307

8.20 Hints and answers

314

9 Normal modes

316

9.1 Typical oscillatory systems

317

9.2 Symmetry and normal modes

322

viii

CONTENTS

9.3 Rayleigh–Ritz method

327

9.4 Exercises

329

9.5 Hints and answers

332

10 Vector calculus

334

10.1 Diﬀerentiation of vectors

334

Composite vector expressions; diﬀerential of a vector

10.2 Integration of vectors

339

10.3 Space curves

340

10.4 Vector functions of several arguments

344

10.5 Surfaces

345

10.6 Scalar and vector ﬁelds

347

10.7 Vector operators

347

Gradient of a scalar ﬁeld; divergence of a vector ﬁeld; curl of a vector ﬁeld

10.8 Vector operator formulae

354

Vector operators acting on sums and products; combinations of grad, div and

curl

10.9 Cylindrical and spherical polar coordinates

357

10.10 General curvilinear coordinates

364

10.11 Exercises

369

10.12 Hints and answers

375

11 Line, surface and volume integrals

377

11.1 Line integrals

377

Evaluating line integrals; physical examples; line integrals with respect to a

scalar

11.2 Connectivity of regions

383

11.3 Green’s theorem in a plane

384

11.4 Conservative ﬁelds and potentials

387

11.5 Surface integrals

389

Evaluating surface integrals; vector areas of surfaces; physical examples

11.6 Volume integrals

396

Volumes of three-dimensional regions

11.7 Integral forms for grad, div and curl

398

11.8 Divergence theorem and related theorems

401

Green’s theorems; other related integral theorems; physical applications

11.9 Stokes’ theorem and related theorems

406

Related integral theorems; physical applications

11.10 Exercises

409

11.11 Hints and answers

414

12 Fourier series

415

12.1 The Dirichlet conditions

415

ix

CONTENTS

12.2 The Fourier coeﬃcients

417

12.3 Symmetry considerations

419

12.4 Discontinuous functions

420

12.5 Non-periodic functions

422

12.6 Integration and diﬀerentiation

424

12.7 Complex Fourier series

424

12.8 Parseval’s theorem

426

12.9 Exercises

427

12.10 Hints and answers

431

13 Integral transforms

433

13.1 Fourier transforms

433

The uncertainty principle; Fraunhofer diﬀraction; the Dirac δ-function;

relation of the δ-function to Fourier transforms; properties of Fourier transforms; odd and even functions; convolution and deconvolution; correlation functions and energy spectra; Parseval’s theorem; Fourier transforms in higher

dimensions

13.2 Laplace transforms

453

Laplace transforms of derivatives and integrals; other properties of Laplace

transforms

13.3 Concluding remarks

459

13.4 Exercises

460

13.5 Hints and answers

466

14 First-order ordinary diﬀerential equations

468

14.1 General form of solution

469

14.2 First-degree ﬁrst-order equations

470

Separable-variable equations; exact equations; inexact equations, integrating factors; linear equations; homogeneous equations; isobaric equations;

Bernoulli’s equation; miscellaneous equations

14.3 Higher-degree ﬁrst-order equations

480

Equations soluble for p; for x; for y; Clairaut’s equation

14.4 Exercises

484

14.5 Hints and answers

488

15 Higher-order ordinary diﬀerential equations

490

15.1 Linear equations with constant coeﬃcients

492

Finding the complementary function yc(x); ﬁnding the particular integral yp(x); constructing the general solution yc(x) + yp(x); linear recurrence relations; Laplace transform method

15.2 Linear equations with variable coeﬃcients

503

The Legendre and Euler linear equations; exact equations; partially known

complementary function; variation of parameters; Green’s functions; canonical

form for second-order equations

x

CONTENTS

15.3 General ordinary diﬀerential equations

518

Dependent variable absent; independent variable absent; non-linear exact

equations; isobaric or homogeneous equations; equations homogeneous in x or y alone; equations having y = Aex as a solution

15.4 Exercises

523

15.5 Hints and answers

529

16 Series solutions of ordinary diﬀerential equations

531

16.1 Second-order linear ordinary diﬀerential equations

531

Ordinary and singular points

16.2 Series solutions about an ordinary point

535

16.3 Series solutions about a regular singular point

538

Distinct roots not diﬀering by an integer; repeated root of the indicial

equation; distinct roots diﬀering by an integer

16.4 Obtaining a second solution

544

The Wronskian method; the derivative method; series form of the second

solution

16.5 Polynomial solutions

548

16.6 Exercises

550

16.7 Hints and answers

553

17 Eigenfunction methods for diﬀerential equations

554

17.1 Sets of functions

556

Some useful inequalities

17.2 Adjoint, self-adjoint and Hermitian operators

559

17.3 Properties of Hermitian operators

561

Reality of the eigenvalues; orthogonality of the eigenfunctions; construction

of real eigenfunctions

17.4 Sturm–Liouville equations

564

Valid boundary conditions; putting an equation into Sturm–Liouville form

17.5 Superposition of eigenfunctions: Green’s functions

569

17.6 A useful generalisation

572

17.7 Exercises

573

17.8 Hints and answers

576

18 Special functions

577

18.1 Legendre functions

577

General solution for integer ; properties of Legendre polynomials

18.2 Associated Legendre functions

587

18.3 Spherical harmonics

593

18.4 Chebyshev functions

595

18.5 Bessel functions

602

General solution for non-integer ν; general solution for integer ν; properties

of Bessel functions

xi

CONTENTS

18.6 Spherical Bessel functions

614

18.7 Laguerre functions

616

18.8 Associated Laguerre functions

621

18.9 Hermite functions

624

18.10 Hypergeometric functions

628

18.11 Conﬂuent hypergeometric functions

633

18.12 The gamma function and related functions

635

18.13 Exercises

640

18.14 Hints and answers

646

19 Quantum operators

648

19.1 Operator formalism

648

Commutators

19.2 Physical examples of operators

656

Uncertainty principle; angular momentum; creation and annihilation operators

19.3 Exercises

671

19.4 Hints and answers

674

20 Partial diﬀerential equations: general and particular solutions

675

20.1 Important partial diﬀerential equations

676

The wave equation; the diﬀusion equation; Laplace’s equation; Poisson’s equation; Schro¨dinger’s equation

20.2 General form of solution

680

20.3 General and particular solutions

681

First-order equations; inhomogeneous equations and problems; second-order

equations

20.4 The wave equation

693

20.5 The diﬀusion equation

695

20.6 Characteristics and the existence of solutions

699

First-order equations; second-order equations

20.7 Uniqueness of solutions

705

20.8 Exercises

707

20.9 Hints and answers

711

21 Partial diﬀerential equations: separation of variables

and other methods

713

21.1 Separation of variables: the general method

713

21.2 Superposition of separated solutions

717

21.3 Separation of variables in polar coordinates

725

Laplace’s equation in polar coordinates; spherical harmonics; other equations in polar coordinates; solution by expansion; separation of variables for

inhomogeneous equations

21.4 Integral transform methods

747

xii

CONTENTS

21.5 Inhomogeneous problems – Green’s functions

751

Similarities to Green’s functions for ordinary diﬀerential equations; general

boundary-value problems; Dirichlet problems; Neumann problems

21.6 Exercises

767

21.7 Hints and answers

773

22 Calculus of variations

775

22.1 The Euler–Lagrange equation

776

22.2 Special cases

777

F does not contain y explicitly; F does not contain x explicitly

22.3 Some extensions

781

Several dependent variables; several independent variables; higher-order

derivatives; variable end-points

22.4 Constrained variation

785

22.5 Physical variational principles

787

Fermat’s principle in optics; Hamilton’s principle in mechanics

22.6 General eigenvalue problems

790

22.7 Estimation of eigenvalues and eigenfunctions

792

22.8 Adjustment of parameters

795

22.9 Exercises

797

22.10 Hints and answers

801

23 Integral equations

803

23.1 Obtaining an integral equation from a diﬀerential equation

803

23.2 Types of integral equation

804

23.3 Operator notation and the existence of solutions

805

23.4 Closed-form solutions

806

Separable kernels; integral transform methods; diﬀerentiation

23.5 Neumann series

813

23.6 Fredholm theory

815

23.7 Schmidt–Hilbert theory

816

23.8 Exercises

819

23.9 Hints and answers

823

24 Complex variables

824

24.1 Functions of a complex variable

825

24.2 The Cauchy–Riemann relations

827

24.3 Power series in a complex variable

830

24.4 Some elementary functions

832

24.5 Multivalued functions and branch cuts

835

24.6 Singularities and zeros of complex functions

837

24.7 Conformal transformations

839

24.8 Complex integrals

845

xiii

CONTENTS

24.9 Cauchy’s theorem

849

24.10 Cauchy’s integral formula

851

24.11 Taylor and Laurent series

853

24.12 Residue theorem

858

24.13 Deﬁnite integrals using contour integration

861

24.14 Exercises

867

24.15 Hints and answers

870

25 Applications of complex variables

871

25.1 Complex potentials

871

25.2 Applications of conformal transformations

876

25.3 Location of zeros

879

25.4 Summation of series

882

25.5 Inverse Laplace transform

884

25.6 Stokes’ equation and Airy integrals

888

25.7 WKB methods

895

25.8 Approximations to integrals

905

Level lines and saddle points; steepest descents; stationary phase

25.9 Exercises

920

25.10 Hints and answers

925

26 Tensors

927

26.1 Some notation

928

26.2 Change of basis

929

26.3 Cartesian tensors

930

26.4 First- and zero-order Cartesian tensors

932

26.5 Second- and higher-order Cartesian tensors

935

26.6 The algebra of tensors

938

26.7 The quotient law

939

26.8 The tensors δij and ijk

941

26.9 Isotropic tensors

944

26.10 Improper rotations and pseudotensors

946

26.11 Dual tensors

949

26.12 Physical applications of tensors

950

26.13 Integral theorems for tensors

954

26.14 Non-Cartesian coordinates

955

26.15 The metric tensor

957

26.16 General coordinate transformations and tensors

960

26.17 Relative tensors

963

26.18 Derivatives of basis vectors and Christoﬀel symbols

965

26.19 Covariant diﬀerentiation

968

26.20 Vector operators in tensor form

971

xiv

CONTENTS

26.21 Absolute derivatives along curves

975

26.22 Geodesics

976

26.23 Exercises

977

26.24 Hints and answers

982

27 Numerical methods 27.1 Algebraic and transcendental equations
Rearrangement of the equation; linear interpolation; binary chopping; Newton–Raphson method 27.2 Convergence of iteration schemes 27.3 Simultaneous linear equations Gaussian elimination; Gauss–Seidel iteration; tridiagonal matrices 27.4 Numerical integration Trapezium rule; Simpson’s rule; Gaussian integration; Monte Carlo methods 27.5 Finite diﬀerences 27.6 Diﬀerential equations Diﬀerence equations; Taylor series solutions; prediction and correction; Runge–Kutta methods; isoclines 27.7 Higher-order equations 27.8 Partial diﬀerential equations 27.9 Exercises 27.10 Hints and answers

984 985
992 994
1000
1019 1020
1028 1030 1033 1039

28 Group theory 28.1 Groups
Deﬁnition of a group; examples of groups 28.2 Finite groups 28.3 Non-Abelian groups 28.4 Permutation groups 28.5 Mappings between groups 28.6 Subgroups 28.7 Subdividing a group
Equivalence relations and classes; congruence and cosets; conjugates and classes 28.8 Exercises 28.9 Hints and answers

1041 1041
1049 1052 1056 1059 1061 1063
1070 1074

29 Representation theory 29.1 Dipole moments of molecules 29.2 Choosing an appropriate formalism 29.3 Equivalent representations 29.4 Reducibility of a representation 29.5 The orthogonality theorem for irreducible representations

1076 1077 1078 1084 1086 1090

xv

CONTENTS

29.6 Characters

1092

Orthogonality property of characters

29.7 Counting irreps using characters

1095

Summation rules for irreps

29.8 Construction of a character table

1100

29.9 Group nomenclature

1102

29.10 Product representations

1103

29.11 Physical applications of group theory

1105

Bonding in molecules; matrix elements in quantum mechanics; degeneracy of

normal modes; breaking of degeneracies

29.12 Exercises

1113

29.13 Hints and answers

1117

30 Probability

1119

30.1 Venn diagrams

1119

30.2 Probability

1124

Axioms and theorems; conditional probability; Bayes’ theorem

30.3 Permutations and combinations

1133

30.4 Random variables and distributions

1139

Discrete random variables; continuous random variables

30.5 Properties of distributions

1143

Mean; mode and median; variance and standard deviation; moments; central moments

30.6 Functions of random variables

1150

30.7 Generating functions

1157

Probability generating functions; moment generating functions; characteristic functions; cumulant generating functions

30.8 Important discrete distributions

1168

Binomial; geometric; negative binomial; hypergeometric; Poisson

30.9 Important continuous distributions

1179

Gaussian; log-normal; exponential; gamma; chi-squared; Cauchy; Breit–

Wigner; uniform

30.10 The central limit theorem

1195

30.11 Joint distributions

1196

Discrete bivariate; continuous bivariate; marginal and conditional distributions

30.12 Properties of joint distributions

1199

Means; variances; covariance and correlation

30.13 Generating functions for joint distributions

1205

30.14 Transformation of variables in joint distributions

1206

30.15 Important joint distributions

1207

Multinominal; multivariate Gaussian

30.16 Exercises

1211

30.17 Hints and answers

1219

xvi

CONTENTS

31 Statistics

1221

31.1 Experiments, samples and populations

1221

31.2 Sample statistics

1222

Averages; variance and standard deviation; moments; covariance and correla-

tion

31.3 Estimators and sampling distributions

1229

Consistency, bias and eﬃciency; Fisher’s inequality; standard errors; conﬁ-

dence limits

31.4 Some basic estimators

1243

Mean; variance; standard deviation; moments; covariance and correlation

31.5 Maximum-likelihood method

1255

ML estimator; transformation invariance and bias; eﬃciency; errors and

conﬁdence limits; Bayesian interpretation; large-N behaviour; extended

ML method

31.6 The method of least squares

1271

Linear least squares; non-linear least squares

31.7 Hypothesis testing

1277

Simple and composite hypotheses; statistical tests; Neyman–Pearson; gener-

alised likelihood-ratio; Student’s t; Fisher’s F; goodness of ﬁt

31.8 Exercises

1298

31.9 Hints and answers

1303

Index

1305

xvii

CONTENTS
I am the very Model for a Student Mathematical
I am the very model for a student mathematical; I’ve information rational, and logical and practical. I know the laws of algebra, and ﬁnd them quite symmetrical, And even know the meaning of ‘a variate antithetical’.
I’m extremely well acquainted, with all things mathematical. I understand equations, both the simple and quadratical. About binomial theorems I’m teeming with a lot o’news, With many cheerful facts about the square of the hypotenuse.
I’m very good at integral and diﬀerential calculus, And solving paradoxes that so often seem to rankle us. In short in matters rational, and logical and practical, I am the very model for a student mathematical.
I know the singularities of equations diﬀerential, And some of these are regular, but the rest are quite essential. I quote the results of giants; with Euler, Newton, Gauss, Laplace, And can calculate an orbit, given a centre, force and mass.
I can reconstruct equations, both canonical and formal, And write all kinds of matrices, orthogonal, real and normal. I show how to tackle problems that one has never met before, By analogy or example, or with some clever metaphor.
I seldom use equivalence to help decide upon a class, But often ﬁnd an integral, using a contour o’er a pass. In short in matters rational, and logical and practical, I am the very model for a student mathematical.
When you have learnt just what is meant by ‘Jacobian’ and ‘Abelian’; When you at sight can estimate, for the modal, mean and median; When describing normal subgroups is much more than recitation; When you understand precisely what is ‘quantum excitation’;
When you know enough statistics that you can recognise RV; When you have learnt all advances that have been made in SVD; And when you can spot the transform that solves some tricky PDE, You will feel no better student has ever sat for a degree.
Your accumulated knowledge, whilst extensive and exemplary, Will have only been brought down to the beginning of last century, But still in matters rational, and logical and practical, You’ll be the very model of a student mathematical.
KFR, with apologies to W.S. Gilbert
xix

Preface to the third edition
As is natural, in the four years since the publication of the second edition of this book we have somewhat modiﬁed our views on what should be included and how it should be presented. In this new edition, although the range of topics covered has been extended, there has been no signiﬁcant shift in the general level of diﬃculty or in the degree of mathematical sophistication required. Further, we have aimed to preserve the same style of presentation as seems to have been well received in the ﬁrst two editions. However, a signiﬁcant change has been made to the format of the chapters, speciﬁcally to the way that the exercises, together with their hints and answers, have been treated; the details of the change are explained below.
The two major chapters that are new in this third edition are those dealing with ‘special functions’ and the applications of complex variables. The former presents a systematic account of those functions that appear to have arisen in a more or less haphazard way as a result of studying particular physical situations, and are deemed ‘special’ for that reason. The treatment presented here shows that, in fact, they are nearly all particular cases of the hypergeometric or conﬂuent hypergeometric functions, and are special only in the sense that the parameters of the relevant function take simple or related values.
The second new chapter describes how the properties of complex variables can be used to tackle problems arising from the description of physical situations or from other seemingly unrelated areas of mathematics. To topics treated in earlier editions, such as the solution of Laplace’s equation in two dimensions, the summation of series, the location of zeros of polynomials and the calculation of inverse Laplace transforms, has been added new material covering Airy integrals, saddle-point methods for contour integral evaluation, and the WKB approach to asymptotic forms.
Other new material includes a stand-alone chapter on the use of coordinate-free operators to establish valuable results in the ﬁeld of quantum mechanics; amongst
xx

PREFACE TO THE THIRD EDITION
the physical topics covered are angular momentum and uncertainty principles. There are also signiﬁcant additions to the treatment of numerical integration. In particular, Gaussian quadrature based on Legendre, Laguerre, Hermite and Chebyshev polynomials is discussed, and appropriate tables of points and weights are provided.
We now turn to the most obvious change to the format of the book, namely the way that the exercises, hints and answers are treated. The second edition of Mathematical Methods for Physics and Engineering carried more than twice as many exercises, based on its various chapters, as did the ﬁrst. In its preface we discussed the general question of how such exercises should be treated but, in the end, decided to provide hints and outline answers to all problems, as in the ﬁrst edition. This decision was an uneasy one as, on the one hand, it did not allow the exercises to be set as totally unaided homework that could be used for assessment purposes but, on the other, it did not give a full explanation of how to tackle a problem when a student needed explicit guidance or a model answer.
In order to allow both of these educationally desirable goals to be achieved, we have, in this third edition, completely changed the way in which this matter is handled. A large number of exercises have been included in the penultimate subsections of the appropriate, sometimes reorganised, chapters. Hints and outline answers are given, as previously, in the ﬁnal subsections, but only for the oddnumbered exercises. This leaves all even-numbered exercises free to be set as unaided homework, as described below.
For the four hundred plus odd-numbered exercises, complete solutions are available, to both students and their teachers, in the form of a separate manual, Student Solutions Manual for Mathematical Methods for Physics and Engineering (Cambridge: Cambridge University Press, 2006); the hints and outline answers given in this main text are brief summaries of the model answers given in the manual. There, each original exercise is reproduced and followed by a fully worked solution. For those original exercises that make internal reference to this text or to other (even-numbered) exercises not included in the solutions manual, the questions have been reworded, usually by including additional information, so that the questions can stand alone.
In many cases, the solution given in the manual is even fuller than one that might be expected of a good student that has understood the material. This is because we have aimed to make the solutions instructional as well as utilitarian. To this end, we have included comments that are intended to show how the plan for the solution is fomulated and have given the justiﬁcations for particular intermediate steps (something not always done, even by the best of students). We have also tried to write each individual substituted formula in the form that best indicates how it was obtained, before simplifying it at the next or a subsequent stage. Where several lines of algebraic manipulation or calculus are needed to obtain a ﬁnal result, they are normally included in full; this should enable the
xxi

PREFACE TO THE THIRD EDITION student to determine whether an incorrect answer is due to a misunderstanding of principles or to a technical error.
The remaining four hundred or so even-numbered exercises have no hints or answers, outlined or detailed, available for general access. They can therefore be used by instructors as a basis for setting unaided homework. Full solutions to these exercises, in the same general format as those appearing in the manual (though they may contain references to the main text or to other exercises), are available without charge to accredited teachers as downloadable pdf ﬁles on the password-protected website http://www.cambridge.org/9780521679718. Teachers wishing to have access to the website should contact solutions@cambridge.org for registration details.
In all new publications, errors and typographical mistakes are virtually unavoidable, and we would be grateful to any reader who brings instances to our attention. Retrospectively, we would like to record our thanks to Reinhard Gerndt, Paul Renteln and Joe Tenn for making us aware of some errors in the second edition. Finally, we are extremely grateful to Dave Green for his considerable and continuing advice concerning LATEX.
Ken Riley, Michael Hobson, Cambridge, 2006
xxii

Preface to the second edition
Since the publication of the ﬁrst edition of this book, both through teaching the material it covers and as a result of receiving helpful comments from colleagues, we have become aware of the desirability of changes in a number of areas. The most important of these is that the mathematical preparation of current senior college and university entrants is now less thorough than it used to be. To match this, we decided to include a preliminary chapter covering areas such as polynomial equations, trigonometric identities, coordinate geometry, partial fractions, binomial expansions, necessary and suﬃcient condition and proof by induction and contradiction.
Whilst the general level of what is included in this second edition has not been raised, some areas have been expanded to take in topics we now feel were not adequately covered in the ﬁrst. In particular, increased attention has been given to non-square sets of simultaneous linear equations and their associated matrices. We hope that this more extended treatment, together with the inclusion of singular value matrix decomposition, will make the material of more practical use to engineering students. In the same spirit, an elementary treatment of linear recurrence relations has been included. The topic of normal modes has been given a small chapter of its own, though the links to matrices on the one hand, and to representation theory on the other, have not been lost.
Elsewhere, the presentation of probability and statistics has been reorganised to give the two aspects more nearly equal weights. The early part of the probability chapter has been rewritten in order to present a more coherent development based on Boolean algebra, the fundamental axioms of probability theory and the properties of intersections and unions. Whilst this is somewhat more formal than previously, we think that it has not reduced the accessibility of these topics and hope that it has increased it. The scope of the chapter has been somewhat extended to include all physically important distributions and an introduction to cumulants.
xxiii

PREFACE TO THE SECOND EDITION
Statistics now occupies a substantial chapter of its own, one that includes systematic discussions of estimators and their eﬃciency, sample distributions and tand F-tests for comparing means and variances. Other new topics are applications of the chi-squared distribution, maximum-likelihood parameter estimation and least-squares ﬁtting. In other chapters we have added material on the following topics: curvature, envelopes, curve-sketching, more reﬁned numerical methods for diﬀerential equations and the elements of integration using Monte Carlo techniques.
Over the last four years we have received somewhat mixed feedback about the number of exercises at the ends of the various chapters. After consideration, we decided to increase the number substantially, partly to correspond to the additional topics covered in the text but mainly to give both students and their teachers a wider choice. There are now nearly 800 such exercises, many with several parts. An even more vexed question has been whether to provide hints and answers to all the exercises or just to ‘the odd-numbered’ ones, as is the normal practice for textbooks in the United States, thus making the remainder more suitable for setting as homework. In the end, we decided that hints and outline solutions should be provided for all the exercises, in order to facilitate independent study while leaving the details of the calculation as a task for the student.
In conclusion, we hope that this edition will be thought by its users to be ‘heading in the right direction’ and would like to place on record our thanks to all who have helped to bring about the changes and adjustments. Naturally, those colleagues who have noted errors or ambiguities in the ﬁrst edition and brought them to our attention ﬁgure high on the list, as do the staﬀ at The Cambridge University Press. In particular, we are grateful to Dave Green for continued LATEX advice, Susan Parkinson for copy-editing the second edition with her usual keen eye for detail and ﬂair for crafting coherent prose and Alison Woollatt for once again turning our basic LATEX into a beautifully typeset book. Our thanks go to all of them, though of course we accept full responsibility for any remaining errors or ambiguities, of which, as with any new publication, there are bound to be some.
On a more personal note, KFR again wishes to thank his wife Penny for her unwavering support, not only in his academic and tutorial work, but also in their joint eﬀorts to convert time at the bridge table into ‘green points’ on their record. MPH is once more indebted to his wife, Becky, and his mother, Pat, for their tireless support and encouragement above and beyond the call of duty. MPH dedicates his contribution to this book to the memory of his father, Ronald Leonard Hobson, whose gentle kindness, patient understanding and unbreakable spirit made all things seem possible.
Ken Riley, Michael Hobson Cambridge, 2002
xxiv

Preface to the ﬁrst edition
A knowledge of mathematical methods is important for an increasing number of university and college courses, particularly in physics, engineering and chemistry, but also in more general science. Students embarking on such courses come from diverse mathematical backgrounds, and their core knowledge varies considerably. We have therefore decided to write a textbook that assumes knowledge only of material that can be expected to be familiar to all the current generation of students starting physical science courses at university. In the United Kingdom this corresponds to the standard of Mathematics A-level, whereas in the United States the material assumed is that which would normally be covered at junior college.
Starting from this level, the ﬁrst six chapters cover a collection of topics with which the reader may already be familiar, but which are here extended and applied to typical problems encountered by ﬁrst-year university students. They are aimed at providing a common base of general techniques used in the development of the remaining chapters. Students who have had additional preparation, such as Further Mathematics at A-level, will ﬁnd much of this material straightforward.
Following these opening chapters, the remainder of the book is intended to cover at least that mathematical material which an undergraduate in the physical sciences might encounter up to the end of his or her course. The book is also appropriate for those beginning graduate study with a mathematical content, and naturally much of the material forms parts of courses for mathematics students. Furthermore, the text should provide a useful reference for research workers.
The general aim of the book is to present a topic in three stages. The ﬁrst stage is a qualitative introduction, wherever possible from a physical point of view. The second is a more formal presentation, although we have deliberately avoided strictly mathematical questions such as the existence of limits, uniform convergence, the interchanging of integration and summation orders, etc. on the
xxv

PREFACE TO THE FIRST EDITION
grounds that ‘this is the real world; it must behave reasonably’. Finally a worked example is presented, often drawn from familiar situations in physical science and engineering. These examples have generally been fully worked, since, in the authors’ experience, partially worked examples are unpopular with students. Only in a few cases, where trivial algebraic manipulation is involved, or where repetition of the main text would result, has an example been left as an exercise for the reader. Nevertheless, a number of exercises also appear at the end of each chapter, and these should give the reader ample opportunity to test his or her understanding. Hints and answers to these exercises are also provided.
With regard to the presentation of the mathematics, it has to be accepted that many equations (especially partial diﬀerential equations) can be written more compactly by using subscripts, e.g. uxy for a second partial derivative, instead of the more familiar ∂2u/∂x∂y, and that this certainly saves typographical space. However, for many students, the labour of mentally unpacking such equations is suﬃciently great that it is not possible to think of an equation’s physical interpretation at the same time. Consequently, wherever possible we have decided to write out such expressions in their more obvious but longer form.
During the writing of this book we have received much help and encouragement from various colleagues at the Cavendish Laboratory, Clare College, Trinity Hall and Peterhouse. In particular, we would like to thank Peter Scheuer, whose comments and general enthusiasm proved invaluable in the early stages. For reading sections of the manuscript, for pointing out misprints and for numerous useful comments, we thank many of our students and colleagues at the University of Cambridge. We are especially grateful to Chris Doran, John Huber, Garth Leder, Tom Ko¨rner and, not least, Mike Stobbs, who, sadly, died before the book was completed. We also extend our thanks to the University of Cambridge and the Cavendish teaching staﬀ, whose examination questions and lecture hand-outs have collectively provided the basis for some of the examples included. Of course, any errors and ambiguities remaining are entirely the responsibility of the authors, and we would be most grateful to have them brought to our attention.
We are indebted to Dave Green for a great deal of advice concerning typesetting in LATEX and to Andrew Lovatt for various other computing tips. Our thanks also go to Anja Visser and Grac¸a Rocha for enduring many hours of (sometimes heated) debate. At Cambridge University Press, we are very grateful to our editor Adam Black for his help and patience and to Alison Woollatt for her expert typesetting of such a complicated text. We also thank our copy-editor Susan Parkinson for many useful suggestions that have undoubtedly improved the style of the book.
Finally, on a personal note, KFR wishes to thank his wife Penny, not only for a long and happy marriage, but also for her support and understanding during his recent illness – and when things have not gone too well at the bridge table! MPH is indebted both to Rebecca Morris and to his parents for their tireless
xxvi

PREFACE TO THE FIRST EDITION support and patience, and for their unending supplies of tea. SJB is grateful to Anthony Gritten for numerous relaxing discussions about J. S. Bach, to Susannah Ticciati for her patience and understanding, and to Kate Isaak for her calming late-night e-mails from the USA.
Ken Riley, Michael Hobson and Stephen Bence Cambridge, 1997
xxvii

1
Preliminary algebra
This opening chapter reviews the basic algebra of which a working knowledge is presumed in the rest of the book. Many students will be familiar with much, if not all, of it, but recent changes in what is studied during secondary education mean that it cannot be taken for granted that they will already have a mastery of all the topics presented here. The reader may assess which areas need further study or revision by attempting the exercises at the end of the chapter. The main areas covered are polynomial equations and the related topic of partial fractions, curve sketching, coordinate geometry, trigonometric identities and the notions of proof by induction or contradiction.
1.1 Simple functions and equations It is normal practice when starting the mathematical investigation of a physical problem to assign an algebraic symbol to the quantity whose value is sought, either numerically or as an explicit algebraic expression. For the sake of deﬁniteness, in this chapter we will use x to denote this quantity most of the time. Subsequent steps in the analysis involve applying a combination of known laws, consistency conditions and (possibly) given constraints to derive one or more equations satisﬁed by x. These equations may take many forms, ranging from a simple polynomial equation to, say, a partial diﬀerential equation with several boundary conditions. Some of the more complicated possibilities are treated in the later chapters of this book, but for the present we will be concerned with techniques for the solution of relatively straightforward algebraic equations.
1.1.1 Polynomials and polynomial equations Firstly we consider the simplest type of equation, a polynomial equation, in which a polynomial expression in x, denoted by f(x), is set equal to zero and thereby
1

PRELIMINARY ALGEBRA

forms an equation which is satisﬁed by particular values of x, called the roots of the equation:

f(x) = anxn + an−1xn−1 + · · · + a1x + a0 = 0.

(1.1)

Here n is an integer > 0, called the degree of both the polynomial and the equation, and the known coeﬃcients a0, a1, . . . , an are real quantities with an = 0.
Equations such as (1.1) arise frequently in physical problems, the coeﬃcients ai being determined by the physical properties of the system under study. What is needed is to ﬁnd some or all of the roots of (1.1), i.e. the x-values, αk, that satisfy f(αk) = 0; here k is an index that, as we shall see later, can take up to n diﬀerent values, i.e. k = 1, 2, . . . , n. The roots of the polynomial equation can equally well be described as the zeros of the polynomial. When they are real, they correspond to the points at which a graph of f(x) crosses the x-axis. Roots that are complex (see chapter 3) do not have such a graphical interpretation.
For polynomial equations containing powers of x greater than x4 general methods do not exist for obtaining explicit expressions for the roots αk. Even for n = 3 and n = 4 the prescriptions for obtaining the roots are suﬃciently complicated that it is usually preferable to obtain exact or approximate values by other methods. Only for n = 1 and n = 2 can closed-form solutions be given. These results will be well known to the reader, but they are given here for the sake of completeness. For n = 1, (1.1) reduces to the linear equation

a1x + a0 = 0;

(1.2)

the solution (root) is α1 = −a0/a1. For n = 2, (1.1) reduces to the quadratic equation

a2x2 + a1x + a0 = 0;

(1.3)

the two roots α1 and α2 are given by

−a1 ± a21 − 4a2a0

α1,2 =

. 2a2

(1.4)

When discussing speciﬁcally quadratic equations, as opposed to more general

polynomial equations, it is usual to write the equation in one of the two notations

ax2 + bx + c = 0,

ax2 + 2bx + c = 0,

(1.5)

with respective explicit pairs of solutions

√

√

−b ± b2 − 4ac

α1,2 =

, 2a

−b ± b2 − ac

α1,2 =

. a

(1.6)

Of course, these two notations are entirely equivalent and the only important

point is to associate each form of answer with the corresponding form of equation;

most people keep to one form, to avoid any possible confusion.

2

1.1 SIMPLE FUNCTIONS AND EQUATIONS

If the value of the quantity appearing under the square root sign is positive then both roots are real; if it is negative then the roots form a complex conjugate pair, i.e. they are of the form p ± iq with p and q real (see chapter 3); if it has zero value then the two roots are equal and special considerations usually arise.
Thus linear and quadratic equations can be dealt with in a cut-and-dried way. We now turn to methods for obtaining partial information about the roots of higher-degree polynomial equations. In some circumstances the knowledge that an equation has a root lying in a certain range, or that it has no real roots at all, is all that is actually required. For example, in the design of electronic circuits it is necessary to know whether the current in a proposed circuit will break into spontaneous oscillation. To test this, it is suﬃcient to establish whether a certain polynomial equation, whose coeﬃcients are determined by the physical parameters of the circuit, has a root with a positive real part (see chapter 3); complete determination of all the roots is not needed for this purpose. If the complete set of roots of a polynomial equation is required, it can usually be obtained to any desired accuracy by numerical methods such as those described in chapter 27.
There is no explicit step-by-step approach to ﬁnding the roots of a general polynomial equation such as (1.1). In most cases analytic methods yield only information about the roots, rather than their exact values. To explain the relevant techniques we will consider a particular example, ‘thinking aloud’ on paper and expanding on special points about methods and lines of reasoning. In more routine situations such comment would be absent and the whole process briefer and more tightly focussed.

Example: the cubic case Let us investigate the roots of the equation

g(x) = 4x3 + 3x2 − 6x − 1 = 0

(1.7)

or, in an alternative phrasing, investigate the zeros of g(x). We note ﬁrst of all that this is a cubic equation. It can be seen that for x large and positive g(x) will be large and positive and, equally, that for x large and negative g(x) will be large and negative. Therefore, intuitively (or, more formally, by continuity) g(x) must cross the x-axis at least once and so g(x) = 0 must have at least one real root. Furthermore, it can be shown that if f(x) is an nth-degree polynomial then the graph of f(x) must cross the x-axis an even or odd number of times as x varies between −∞ and +∞, according to whether n itself is even or odd. Thus a polynomial of odd degree always has at least one real root, but one of even degree may have no real root. A small complication, discussed later in this section, occurs when repeated roots arise.
Having established that g(x) = 0 has at least one real root, we may ask how

3

PRELIMINARY ALGEBRA

many real roots it could have. To answer this we need one of the fundamental theorems of algebra, mentioned above:

An nth-degree polynomial equation has exactly n roots.

It should be noted that this does not imply that there are n real roots (only that there are not more than n); some of the roots may be of the form p + iq.
To make the above theorem plausible and to see what is meant by repeated roots, let us suppose that the nth-degree polynomial equation f(x) = 0, (1.1), has r roots α1, α2, . . . , αr, considered distinct for the moment. That is, we suppose that f(αk) = 0 for k = 1, 2, . . . , r, so that f(x) vanishes only when x is equal to one of the r values αk. But the same can be said for the function

F(x) = A(x − α1)(x − α2) · · · (x − αr),

(1.8)

in which A is a non-zero constant; F(x) can clearly be multiplied out to form a polynomial expression.
We now call upon a second fundamental result in algebra: that if two polynomial functions f(x) and F(x) have equal values for all values of x, then their coeﬃcients are equal on a term-by-term basis. In other words, we can equate the coeﬃcients of each and every power of x in the two expressions (1.8) and (1.1); in particular we can equate the coeﬃcients of the highest power of x. From this we have Axr ≡ anxn and thus that r = n and A = an. As r is both equal to n and to the number of roots of f(x) = 0, we conclude that the nth-degree polynomial f(x) = 0 has n roots. (Although this line of reasoning may make the theorem plausible, it does not constitute a proof since we have not shown that it is permissible to write f(x) in the form of equation (1.8).)
We next note that the condition f(αk) = 0 for k = 1, 2, . . . , r, could also be met if (1.8) were replaced by

F(x) = A(x − α1)m1 (x − α2)m2 · · · (x − αr)mr ,

(1.9)

with A = an. In (1.9) the mk are integers ≥ 1 and are known as the multiplicities of the roots, mk being the multiplicity of αk. Expanding the right-hand side (RHS) leads to a polynomial of degree m1 + m2 + · · · + mr. This sum must be equal to n. Thus, if any of the mk is greater than unity then the number of distinct roots, r, is less than n; the total number of roots remains at n, but one or more of the αk counts more than once. For example, the equation

F(x) = A(x − α1)2(x − α2)3(x − α3)(x − α4) = 0

has exactly seven roots, α1 being a double root and α2 a triple root, whilst α3 and α4 are unrepeated (simple) roots.
We can now say that our particular equation (1.7) has either one or three real roots but in the latter case it may be that not all the roots are distinct. To decide how many real roots the equation has, we need to anticipate two ideas from the

4

φ1(x)

1.1 SIMPLE FUNCTIONS AND EQUATIONS φ2(x)

x β1 β2

β2
x β1

Figure 1.1 Two curves φ1(x) and φ2(x), both with zero derivatives at the same values of x, but with diﬀerent numbers of real solutions to φi(x) = 0.
next chapter. The ﬁrst of these is the notion of the derivative of a function, and the second is a result known as Rolle’s theorem.
The derivative f (x) of a function f(x) measures the slope of the tangent to the graph of f(x) at that value of x (see ﬁgure 2.1 in the next chapter). For the moment, the reader with no prior knowledge of calculus is asked to accept that the derivative of axn is naxn−1, so that the derivative g (x) of the curve g(x) = 4x3 + 3x2 − 6x − 1 is given by g (x) = 12x2 + 6x − 6. Similar expressions for the derivatives of other polynomials are used later in this chapter.
Rolle’s theorem states that if f(x) has equal values at two diﬀerent values of x then at some point between these two x-values its derivative is equal to zero; i.e. the tangent to its graph is parallel to the x-axis at that point (see ﬁgure 2.2).
Having brieﬂy mentioned the derivative of a function and Rolle’s theorem, we now use them to establish whether g(x) has one or three real zeros. If g(x) = 0 does have three real roots αk, i.e. g(αk) = 0 for k = 1, 2, 3, then it follows from Rolle’s theorem that between any consecutive pair of them (say α1 and α2) there must be some real value of x at which g (x) = 0. Similarly, there must be a further zero of g (x) lying between α2 and α3. Thus a necessary condition for three real roots of g(x) = 0 is that g (x) = 0 itself has two real roots.
However, this condition on the number of roots of g (x) = 0, whilst necessary, is not suﬃcient to guarantee three real roots of g(x) = 0. This can be seen by inspecting the cubic curves in ﬁgure 1.1. For each of the two functions φ1(x) and φ2(x), the derivative is equal to zero at both x = β1 and x = β2. Clearly, though, φ2(x) = 0 has three real roots whilst φ1(x) = 0 has only one. It is easy to see that the crucial diﬀerence is that φ1(β1) and φ1(β2) have the same sign, whilst φ2(β1) and φ2(β2) have opposite signs.
It will be apparent that for some equations, φ(x) = 0 say, φ (x) equals zero
5

PRELIMINARY ALGEBRA

at a value of x for which φ(x) is also zero. Then the graph of φ(x) just touches the x-axis. When this happens the value of x so found is, in fact, a double real root of the polynomial equation (corresponding to one of the mk in (1.9) having the value 2) and must be counted twice when determining the number of real roots.
Finally, then, we are in a position to decide the number of real roots of the equation
g(x) = 4x3 + 3x2 − 6x − 1 = 0.

The equation g (x) = 0, with g (x) = 12x2 + 6x − 6, is a quadratic equation with

explicit solutions§

√

−3 ± 9 + 72

β1,2 =

, 12

so

that

β1

=

−1

and

β2

=

1 2

.

The

corresponding

values

of

g(x)

are

g(β1)

=

4

and

g(β2)

=

−

11 4

,

which

are

of

opposite

sign.

This

indicates

that

4x3

+

3x2

−

6x

−

1

=

0

has

three

real

roots,

one

lying

in

the

range

−1

<

x<

1 2

and

the

others

one

on

each side of that range.

The techniques we have developed above have been used to tackle a cubic

equation, but they can be applied to polynomial equations f(x) = 0 of degree

greater than 3. However, much of the analysis centres around the equation

f (x) = 0 and this itself, being then a polynomial equation of degree 3 or more,

either has no closed-form general solution or one that is complicated to evaluate.

Thus the amount of information that can be obtained about the roots of f(x) = 0

is correspondingly reduced.

A more general case To illustrate what can (and cannot) be done in the more general case we now investigate as far as possible the real roots of
f(x) = x7 + 5x6 + x4 − x3 + x2 − 2 = 0.
The following points can be made.
(i) This is a seventh-degree polynomial equation; therefore the number of real roots is 1, 3, 5 or 7.
(ii) f(0) is negative whilst f(∞) = +∞, so there must be at least one positive root.

§ The two roots β1, β2 are written as β1,2. By convention β1 refers to the upper symbol in ±, β2 to the lower symbol.
6

1.1 SIMPLE FUNCTIONS AND EQUATIONS

(iii) The equation f (x) = 0 can be written as x(7x5 + 30x4 + 4x2 − 3x + 2) = 0 and thus x = 0 is a root. The derivative of f (x), denoted by f (x), equals 42x5 + 150x4 + 12x2 − 6x + 2. That f (x) is zero whilst f (x) is positive at x = 0 indicates (subsection 2.1.8) that f(x) has a minimum there. This, together with the facts that f(0) is negative and f(∞) = ∞, implies that the total number of real roots to the right of x = 0 must be odd. Since the total number of real roots must be odd, the number to the left must be even (0, 2, 4 or 6).
This is about all that can be deduced by simple analytic methods in this case, although some further progress can be made in the ways indicated in exercise 1.3.
There are, in fact, more sophisticated tests that examine the relative signs of successive terms in an equation such as (1.1), and in quantities derived from them, to place limits on the numbers and positions of roots. But they are not prerequisites for the remainder of this book and will not be pursued further here.
We conclude this section with a worked example which demonstrates that the practical application of the ideas developed so far can be both short and decisive.
For what values of k, if any, does f(x) = x3 − 3x2 + 6x + k = 0
have three real roots?
Firstly we study the equation f (x) = 0, i.e. 3x2 − 6x + 6 = 0. This is a quadratic equation but, using (1.6), because 62 < 4 × 3 × 6, it can have no real roots. Therefore, it follows immediately that f(x) has no maximum or minimum; consequently f(x) = 0 cannot have more than one real root, whatever the value of k.

1.1.2 Factorising polynomials

In the previous subsection we saw how a polynomial with r given distinct zeros αk could be constructed as the product of factors containing those zeros:

f(x) = an(x − α1)m1 (x − α2)m2 · · · (x − αr)mr = anxn + an−1xn−1 + · · · + a1x + a0,

(1.10)

with m1 + m2 + · · · + mr = n, the degree of the polynomial. It will cause no loss of generality in what follows to suppose that all the zeros are simple, i.e. all mk = 1 and r = n, and this we will do.
Sometimes it is desirable to be able to reverse this process, in particular when one exact zero has been found by some method and the remaining zeros are to be investigated. Suppose that we have located one zero, α; it is then possible to write (1.10) as

f(x) = (x − α)f1(x),

(1.11)

7

PRELIMINARY ALGEBRA
where f1(x) is a polynomial of degree n−1. How can we ﬁnd f1(x)? The procedure is much more complicated to describe in a general form than to carry out for an equation with given numerical coeﬃcients ai. If such manipulations are too complicated to be carried out mentally, they could be laid out along the lines of an algebraic ‘long division’ sum. However, a more compact form of calculation is as follows. Write f1(x) as
f1(x) = bn−1xn−1 + bn−2xn−2 + bn−3xn−3 + · · · + b1x + b0.
Substitution of this form into (1.11) and subsequent comparison of the coeﬃcients of xp for p = n, n − 1, . . . , 1, 0 with those in the second line of (1.10) generates the series of equations
bn−1 = an, bn−2 − αbn−1 = an−1, bn−3 − αbn−2 = an−2,
... b0 − αb1 = a1,
−αb0 = a0.
These can be solved successively for the bj, starting either from the top or from the bottom of the series. In either case the ﬁnal equation used serves as a check; if it is not satisﬁed, at least one mistake has been made in the computation – or α is not a zero of f(x) = 0. We now illustrate this procedure with a worked example.
Determine by inspection the simple roots of the equation f(x) = 3x4 − x3 − 10x2 − 2x + 4 = 0
and hence, by factorisation, ﬁnd the rest of its roots.
From the pattern of coeﬃcients it can be seen that x = −1 is a solution to the equation. We therefore write
f(x) = (x + 1)(b3x3 + b2x2 + b1x + b0), where
b3 = 3, b2 + b3 = −1, b1 + b2 = −10, b0 + b1 = −2,
b0 = 4. These equations give b3 = 3, b2 = −4, b1 = −6, b0 = 4 (check) and so
f(x) = (x + 1)f1(x) = (x + 1)(3x3 − 4x2 − 6x + 4).
8

1.1 SIMPLE FUNCTIONS AND EQUATIONS

We now note that f1(x) = 0 if x is set equal to 2. Thus x − 2 is a factor of f1(x), which therefore can be written as
f1(x) = (x − 2)f2(x) = (x − 2)(c2x2 + c1x + c0)
with

c2 = 3,

c1 − 2c2 = −4,

c0 − 2c1 = −6,

−2c0 = 4.

These equations determine f2(x) as 3x2 + 2x − 2. Since f2(x) = 0 is a quadratic equation,

its solutions can be written explicitly as

√

−1 ± 1 + 6

x=

.

3√

√

Thus

the

four

roots

of

f(x)

=

0

are

−1, 2,

1 3

(−1

+

7)

and

1 3

(−1

−

7).

1.1.3 Properties of roots

From the fact that a polynomial equation can be written in any of the alternative forms
f(x) = anxn + an−1xn−1 + · · · + a1x + a0 = 0, f(x) = an(x − α1)m1 (x − α2)m2 · · · (x − αr)mr = 0, f(x) = an(x − α1)(x − α2) · · · (x − αn) = 0,
it follows that it must be possible to express the coeﬃcients ai in terms of the roots αk. To take the most obvious example, comparison of the constant terms (formally the coeﬃcient of x0) in the ﬁrst and third expressions shows that

an(−α1)(−α2) · · · (−αn) = a0,

or, using the product notation,

n
αk
k=1

=

(−1)n a0 . an

(1.12)

Only slightly less obvious is a result obtained by comparing the coeﬃcients of xn−1 in the same two expressions of the polynomial:

n k=1

αk

=

− an−1 . an

(1.13)

Comparing the coeﬃcients of other powers of x yields further results, though they are of less general use than the two just given. One such, which the reader

may wish to derive, is

n j=1

n k>j

αj αk

=

an−2 . an

(1.14)

9

PRELIMINARY ALGEBRA

In the case of a quadratic equation these root properties are used suﬃciently

often that they are worth stating explicitly, as follows. If the roots of the quadratic equation ax2 + bx + c = 0 are α1 and α2 then

α1

+

α2

=

−b, a

c

α1α2

=

. a

If the alternative standard form for the quadratic is used, b is replaced by 2b in both the equation and the ﬁrst of these results.

Find a cubic equation whose roots are −4, 3 and 5.

From results (1.12) – (1.14) we can compute that, arbitrarily setting a3 = 1,

3
−a2 = αk = 4,
k=1

33

a1 =

αjαk = −17,

j=1 k>j

3
a0 = (−1)3 αk = 60.
k=1

Thus a possible cubic equation is x3 + (−4)x2 + (−17)x + (60) = 0. Of course, any multiple of x3 − 4x2 − 17x + 60 = 0 will do just as well.

1.2 Trigonometric identities
So many of the applications of mathematics to physics and engineering are concerned with periodic, and in particular sinusoidal, behaviour that a sure and ready handling of the corresponding mathematical functions is an essential skill. Even situations with no obvious periodicity are often expressed in terms of periodic functions for the purposes of analysis. Later in this book whole chapters are devoted to developing the techniques involved, but as a necessary prerequisite we here establish (or remind the reader of) some standard identities with which he or she should be fully familiar, so that the manipulation of expressions containing sinusoids becomes automatic and reliable. So as to emphasise the angular nature of the argument of a sinusoid we will denote it in this section by θ rather than x.

1.2.1 Single-angle identities

We give without proof the basic identity satisﬁed by the sinusoidal functions sin θ and cos θ, namely

cos2 θ + sin2 θ = 1.

(1.15)

If sin θ and cos θ have been deﬁned geometrically in terms of the coordinates of a point on a circle, a reference to the name of Pythagoras will suﬃce to establish this result. If they have been deﬁned by means of series (with θ expressed in radians) then the reader should refer to Euler’s equation (3.23) on page 93, and note that eiθ has unit modulus if θ is real.

10

1.2 TRIGONOMETRIC IDENTITIES

y y

R

P

M T
O

N B
A

x x

Figure 1.2 Illustration of the compound-angle identities. Refer to the main text for details.

Other standard single-angle formulae derived from (1.15) by dividing through by various powers of sin θ and cos θ are

1 + tan2 θ = sec2 θ, cot2 θ + 1 = cosec 2θ.

(1.16) (1.17)

1.2.2 Compound-angle identities
The basis for building expressions for the sinusoidal functions of compound angles are those for the sum and diﬀerence of just two angles, since all other cases can be built up from these, in principle. Later we will see that a study of complex numbers can provide a more eﬃcient approach in some cases.
To prove the basic formulae for the sine and cosine of a compound angle A + B in terms of the sines and cosines of A and B, we consider the construction shown in ﬁgure 1.2. It shows two sets of axes, Oxy and Ox y , with a common origin but rotated with respect to each other through an angle A. The point P lies on the unit circle centred on the common origin O and has coordinates cos(A + B), sin(A + B) with respect to the axes Oxy and coordinates cos B, sin B with respect to the axes Ox y .
Parallels to the axes Oxy (dotted lines) and Ox y (broken lines) have been drawn through P . Further parallels (MR and RN) to the Ox y axes have been
11

PRELIMINARY ALGEBRA

drawn through R, the point (0, sin(A + B)) in the Oxy system. That all the angles marked with the symbol • are equal to A follows from the simple geometry of right-angled triangles and crossing lines.
We now determine the coordinates of P in terms of lengths in the ﬁgure, expressing those lengths in terms of both sets of coordinates:

(i) cos B = x = T N + NP = MR + NP = OR sin A + RP cos A = sin(A + B) sin A + cos(A + B) cos A;
(ii) sin B = y = OM − T M = OM − NR = OR cos A − RP sin A = sin(A + B) cos A − cos(A + B) sin A.

Now, if equation (i) is multiplied by sin A and added to equation (ii) multiplied by cos A, the result is
sin A cos B + cos A sin B = sin(A + B)(sin2 A + cos2 A) = sin(A + B).

Similarly, if equation (ii) is multiplied by sin A and subtracted from equation (i) multiplied by cos A, the result is
cos A cos B − sin A sin B = cos(A + B)(cos2 A + sin2 A) = cos(A + B).

Corresponding graphically based results can be derived for the sines and cosines of the diﬀerence of two angles; however, they are more easily obtained by setting B to −B in the previous results and remembering that sin B becomes − sin B whilst cos B is unchanged. The four results may be summarised by

sin(A ± B) = sin A cos B ± cos A sin B cos(A ± B) = cos A cos B ∓ sin A sin B.

(1.18) (1.19)

Standard results can be deduced from these by setting one of the two angles equal to π or to π/2:

sin(π − θ) = sin θ,

sin

1 2

π

−

θ

= cos θ,

cos(π − θ) = − cos θ,

cos

1 2

π

−

θ

= sin θ,

(1.20) (1.21)

From these basic results many more can be derived. An immediate deduction, obtained by taking the ratio of the two equations (1.18) and (1.19) and then dividing both the numerator and denominator of this ratio by cos A cos B, is

tan(A

±

B)

=

tan A ± tan B 1 ∓ tan A tan B

.

(1.22)

One application of this result is a test for whether two lines on a graph are orthogonal (perpendicular); more generally, it determines the angle between them. The standard notation for a straight-line graph is y = mx + c, in which m is the slope of the graph and c is its intercept on the y-axis. It should be noted that the slope m is also the tangent of the angle the line makes with the x-axis.

12

1.2 TRIGONOMETRIC IDENTITIES

Consequently the angle θ12 between two such straight-line graphs is equal to the diﬀerence in the angles they individually make with the x-axis, and the tangent of that angle is given by (1.22):

tan θ12

=

tan θ1 − tan θ2 1 + tan θ1 tan θ2

=

m1 − m2 . 1 + m1m2

(1.23)

For the lines to be orthogonal we must have θ12 = π/2, i.e. the ﬁnal fraction on the RHS of the above equation must equal ∞, and so

m1m2 = −1.

(1.24)

A kind of inversion of equations (1.18) and (1.19) enables the sum or diﬀerence of two sines or cosines to be expressed as the product of two sinusoids; the procedure is typiﬁed by the following. Adding together the expressions given by (1.18) for sin(A + B) and sin(A − B) yields

sin(A + B) + sin(A − B) = 2 sin A cos B.

If we now write A + B = C and A − B = D, this becomes

sin C + sin D = 2 sin C + D cos C − D .

2

2

(1.25)

In a similar way each of the following equations can be derived:

sin C − sin D = 2 cos

C +D 2

sin

C −D 2

,

C +D

C−D

cos C + cos D = 2 cos 2 cos 2 ,

cos C − cos D = −2 sin

C +D 2

sin

C −D 2

.

(1.26) (1.27) (1.28)

The minus sign on the right of the last of these equations should be noted; it may help to avoid overlooking this ‘oddity’ to recall that if C > D then cos C < cos D.

1.2.3 Double- and half-angle identities Double-angle and half-angle identities are needed so often in practical calculations that they should be committed to memory by any physical scientist. They can be obtained by setting B equal to A in results (1.18) and (1.19). When this is done,
13

PRELIMINARY ALGEBRA

and use made of equation (1.15), the following results are obtained:

sin 2θ = 2 sin θ cos θ,

(1.29)

cos 2θ = cos2 θ − sin2 θ

= 2 cos2 θ − 1

= 1 − 2 sin2 θ,

(1.30)

2 tan θ tan 2θ = 1 − tan2 θ .

(1.31)

A further set of identities enables sinusoidal functions of θ to be expressed in

terms of polynomial functions of a variable t = tan(θ/2). They are not used in

their primary role until the next chapter, but we give a derivation of them here

for reference. If t = tan(θ/2), then it follows from (1.16) that 1+t2 = sec2(θ/2) and cos(θ/2) =
(1 + t2)−1/2, whilst sin(θ/2) = t(1 + t2)−1/2. Now, using (1.29) and (1.30), we may

write:

θ θ 2t sin θ = 2 sin 2 cos 2 = 1 + t2 ,

cos θ

=

cos2

θ 2

−

sin2

θ 2

=

1 1

− +

t2 t2 ,

2t tan θ = 1 − t2 .

(1.32) (1.33) (1.34)

It can be further shown that the derivative of θ with respect to t takes the algebraic form 2/(1 + t2). This completes a package of results that enables

expressions involving sinusoids, particularly when they appear as integrands, to

be cast in more convenient algebraic forms. The proof of the derivative property

and examples of use of the above results are given in subsection (2.2.7).

We conclude this section with a worked example which is of such a commonly

occurring form that it might be considered a standard procedure.

Solve for θ the equation

a sin θ + b cos θ = k,

where a, b and k are given real quantities.

To solve this equation we make use of result (1.18) by setting a = K cos φ and b = K sin φ for suitable values of K and φ. We then have

k = K cos φ sin θ + K sin φ cos θ = K sin(θ + φ),

with

K2 = a2 + b2

and

φ

=

tan−1

b .

a

Whether φ lies in 0 ≤ φ ≤ π or in −π < φ < 0 has to be determined by the individual

signs of a and b. The solution is thus

θ = sin−1 k − φ, K

14

1.3 COORDINATE GEOMETRY
with K and φ as given above. Notice that the inverse sine yields two values in the range 0 to 2π and that there is no real solution to the original equation if |k| > |K| = (a2 + b2)1/2.

1.3 Coordinate geometry We have already mentioned the standard form for a straight-line graph, namely

y = mx + c,

(1.35)

representing a linear relationship between the independent variable x and the dependent variable y. The slope m is equal to the tangent of the angle the line makes with the x-axis whilst c is the intercept on the y-axis.
An alternative form for the equation of a straight line is

ax + by + k = 0,

(1.36)

to which (1.35) is clearly connected by

m

=

−

a b

and

c

=

−

k b

.

This form treats x and y on a more symmetrical basis, the intercepts on the two axes being −k/a and −k/b respectively.
A power relationship between two variables, i.e. one of the form y = Axn, can also be cast into straight-line form by taking the logarithms of both sides. Whilst it is normal in mathematical work to use natural logarithms (to base e, written ln x), for practical investigations logarithms to base 10 are often employed. In either case the form is the same, but it needs to be remembered which has been used when recovering the value of A from ﬁtted data. In the mathematical (base e) form, the power relationship becomes

ln y = n ln x + ln A.

(1.37)

Now the slope gives the power n, whilst the intercept on the ln y axis is ln A, which yields A, either by exponentiation or by taking antilogarithms.
The other standard coordinate forms of two-dimensional curves that students should know and recognise are those concerned with the conic sections – so called because they can all be obtained by taking suitable sections across a (double) cone. Because the conic sections can take many diﬀerent orientations and scalings their general form is complex,

Ax2 + By2 + Cxy + Dx + Ey + F = 0,

(1.38)

but each can be represented by one of four generic forms, an ellipse, a parabola, a hyperbola or, the degenerate form, a pair of straight lines. If they are reduced to their standard representations, in which axes of symmetry are made to coincide

15

PRELIMINARY ALGEBRA

with the coordinate axes, the ﬁrst three take the forms

(x − α)2 (y − β)2 a2 + b2 = 1 (y − β)2 = 4a(x − α)

(x − α)2 a2

−

(y − β)2 b2

=

1

(ellipse), (parabola), (hyperbola).

(1.39) (1.40) (1.41)

Here, (α, β) gives the position of the ‘centre’ of the curve, usually taken as the origin (0, 0) when this does not conﬂict with any imposed conditions. The parabola equation given is that for a curve symmetric about a line parallel to the x-axis. For one symmetrical about a parallel to the y-axis the equation would read (x − α)2 = 4a(y − β).
Of course, the circle is the special case of an ellipse in which b = a and the equation takes the form

(x − α)2 + (y − β)2 = a2.

(1.42)

The distinguishing characteristic of this equation is that when it is expressed in the form (1.38) the coeﬃcients of x2 and y2 are equal and that of xy is zero; this property is not changed by any reorientation or scaling and so acts to identify a general conic as a circle.
Deﬁnitions of the conic sections in terms of geometrical properties are also available; for example, a parabola can be deﬁned as the locus of a point that is always at the same distance from a given straight line (the directrix) as it is from a given point (the focus). When these properties are expressed in Cartesian coordinates the above equations are obtained. For a circle, the deﬁning property is that all points on the curve are a distance a from (α, β); (1.42) expresses this requirement very directly. In the following worked example we derive the equation for a parabola.

Find the equation of a parabola that has the line x = −a as its directrix and the point (a, 0) as its focus.
Figure 1.3 shows the situation in Cartesian coordinates. Expressing the deﬁning requirement that P N and P F are equal in length gives
(x + a) = [(x − a)2 + y2]1/2 ⇒ (x + a)2 = (x − a)2 + y2 which, on expansion of the squared terms, immediately gives y2 = 4ax. This is (1.40) with α and β both set equal to zero.
Although the algebra is more complicated, the same method can be used to derive the equations for the ellipse and the hyperbola. In these cases the distance from the ﬁxed point is a deﬁnite fraction, e, known as the eccentricity, of the distance from the ﬁxed line. For an ellipse 0 < e < 1, for a circle e = 0, and for a hyperbola e > 1. The parabola corresponds to the case e = 1.

16

1.3 COORDINATE GEOMETRY y

P

N

(x, y)

F

x

O

(a, 0)

x = −a
Figure 1.3 Construction of a parabola using the point (a, 0) as the focus and the line x = −a as the directrix.

The values of a and b (with a ≥ b) in equation (1.39) for an ellipse are related to e through

e2

=

a2

− a2

b2

and give the lengths of the semi-axes of the ellipse. If the ellipse is centred on the origin, i.e. α = β = 0, then the focus is (−ae, 0) and the directrix is the line x = −a/e.
For each conic section curve, although we have two variables, x and y, they are not independent, since if one is given then the other can be determined. However, determining y when x is given, say, involves solving a quadratic equation on each occasion, and so it is convenient to have parametric representations of the curves. A parametric representation allows each point on a curve to be associated with a unique value of a single parameter t. The simplest parametric representations for the conic sections are as given below, though that for the hyperbola uses hyperbolic functions, not formally introduced until chapter 3. That they do give valid parameterizations can be veriﬁed by substituting them into the standard forms (1.39)–(1.41); in each case the standard form is reduced to an algebraic or trigonometric identity.

x = α + a cos φ, y = β + b sin φ (ellipse),

x = α + at2,

y = β + 2at

(parabola),

x = α + a cosh φ, y = β + b sinh φ (hyperbola).

As a ﬁnal example illustrating several topics from this section we now prove

17

PRELIMINARY ALGEBRA

the well-known result that the angle subtended by a diameter at any point on a circle is a right angle.

Taking the diameter to be the line joining Q = (−a, 0) and R = (a, 0) and the point P to be any point on the circle x2 + y2 = a2, prove that angle QP R is a right angle.

If P is the point (x, y), the slope of the line QP is

y−0

y

m1

=

x

−

(−a)

=

. x+a

That of RP is

y−0

y

m2 = x − (a) = x − a .

Thus

y2 m1m2 = x2 − a2 .

But, since P is on the circle, y2 = a2 − x2 and consequently m1m2 = −1. From result (1.24) this implies that QP and RP are orthogonal and that QP R is therefore a right angle. Note that this is true for any point P on the circle.

1.4 Partial fractions
In subsequent chapters, and in particular when we come to study integration in chapter 2, we will need to express a function f(x) that is the ratio of two polynomials in a more manageable form. To remove some potential complexity from our discussion we will assume that all the coeﬃcients in the polynomials are real, although this is not an essential simpliﬁcation.
The behaviour of f(x) is crucially determined by the location of the zeros of its denominator, i.e. if f(x) is written as f(x) = g(x)/h(x) where both g(x) and h(x) are polynomials,§ then f(x) changes extremely rapidly when x is close to those values αi that are the roots of h(x) = 0. To make such behaviour explicit, we write f(x) as a sum of terms such as A/(x − α)n, in which A is a constant, α is one of the αi that satisfy h(αi) = 0 and n is a positive integer. Writing a function in this way is known as expressing it in partial fractions.
Suppose, for the sake of deﬁniteness, that we wish to express the function
4x + 2 f(x) = x2 + 3x + 2
§ It is assumed that the ratio has been reduced so that g(x) and h(x) do not contain any common factors, i.e. there is no value of x that makes both vanish at the same time. We may also assume without any loss of generality that the coeﬃcient of the highest power of x in h(x) has been made equal to unity, if necessary, by dividing both numerator and denominator by the coeﬃcient of this highest power.
18

1.4 PARTIAL FRACTIONS

in partial fractions, i.e. to write it as

f(x)

=

g(x) h(x)

=

4x + 2 x2 + 3x + 2

=

A1 (x − α1)n1

+

A2 (x − α2)n2

+···

.

(1.43)

The ﬁrst question that arises is that of how many terms there should be on the right-hand side (RHS). Although some complications occur when h(x) has repeated roots (these are considered below) it is clear that f(x) only becomes inﬁnite at the two values of x, α1 and α2, that make h(x) = 0. Consequently the RHS can only become inﬁnite at the same two values of x and therefore contains only two partial fractions – these are the ones shown explicitly. This argument can be trivially extended (again temporarily ignoring the possibility of repeated roots of h(x)) to show that if h(x) is a polynomial of degree n then there should be n terms on the RHS, each containing a diﬀerent root αi of the equation h(αi) = 0.
A second general question concerns the appropriate values of the ni. This is answered by putting the RHS over a common denominator, which will clearly have to be the product (x − α1)n1 (x − α2)n2 · · · . Comparison of the highest power of x in this new RHS with the same power in h(x) shows that n1 + n2 + · · · = n. This result holds whether or not h(x) = 0 has repeated roots and, although we do not give a rigorous proof, strongly suggests the following correct conclusions.

• The number of terms on the RHS is equal to the number of distinct roots of h(x) = 0, each term having a diﬀerent root αi in its denominator (x − αi)ni .
• If αi is a multiple root of h(x) = 0 then the value to be assigned to ni in (1.43) is that of mi when h(x) is written in the product form (1.9). Further, as discussed on p. 23, Ai has to be replaced by a polynomial of degree mi − 1. This is also formally true for non-repeated roots, since then both mi and ni are equal to unity.

Returning to our speciﬁc example we note that the denominator h(x) has zeros at x = α1 = −1 and x = α2 = −2; these x-values are the simple (non-repeated) roots of h(x) = 0. Thus the partial fraction expansion will be of the form

4x + 2 x2 + 3x + 2

=

A1 x+1

+

A2 . x+2

(1.44)

We now list several methods available for determining the coeﬃcients A1 and A2. We also remind the reader that, as with all the explicit examples and techniques described, these methods are to be considered as models for the handling of any ratio of polynomials, with or without characteristics that make it a special case.

(i) The RHS can be put over a common denominator, in this case (x+1)(x+2), and then the coeﬃcients of the various powers of x can be equated in the

19

PRELIMINARY ALGEBRA
numerators on both sides of the equation. This leads to
4x + 2 = A1(x + 2) + A2(x + 1), 4 = A1 + A2 2 = 2A1 + A2.
Solving the simultaneous equations for A1 and A2 gives A1 = −2 and A2 = 6. (ii) A second method is to substitute two (or more generally n) diﬀerent values of x into each side of (1.44) and so obtain two (or n) simultaneous equations for the two (or n) constants Ai. To justify this practical way of proceeding it is necessary, strictly speaking, to appeal to method (i) above, which establishes that there are unique values for A1 and A2 valid for all values of x. It is normally very convenient to take zero as one of the values of x, but of course any set will do. Suppose in the present case that we use the values x = 0 and x = 1 and substitute in (1.44). The resulting equations are
2 = A1 + A2 , 21 2 6 = A1 + A2 , 62 3 which on solution give A1 = −2 and A2 = 6, as before. The reader can easily verify that any other pair of values for x (except for a pair that includes α1 or α2) gives the same values for A1 and A2. (iii) The very reason why method (ii) fails if x is chosen as one of the roots αi of h(x) = 0 can be made the basis for determining the values of the Ai corresponding to non-multiple roots without having to solve simultaneous equations. The method is conceptually more diﬃcult than the other methods presented here, and needs results from the theory of complex variables (chapter 24) to justify it. However, we give a practical ‘cookbook’ recipe for determining the coeﬃcients.
(a) To determine the coeﬃcient Ak, imagine the denominator h(x) written as the product (x − α1)(x − α2) · · · (x − αn), with any m-fold repeated root giving rise to m factors in parentheses.
(b) Now set x equal to αk and evaluate the expression obtained after omitting the factor that reads αk − αk.
(c) Divide the value so obtained into g(αk); the result is the required coeﬃcient Ak.
For our speciﬁc example we ﬁnd that in step (a) that h(x) = (x + 1)(x + 2) and that in evaluating A1 step (b) yields −1 + 2, i.e. 1. Since g(−1) = 4(−1) + 2 = −2, step (c) gives A1 as (−2)/(1), i.e in agreement with our other evaluations. In a similar way A2 is evaluated as (−6)/(−1) = 6.
20

1.4 PARTIAL FRACTIONS

Thus any one of the methods listed above shows that

4x + 2

−2

6

x2

+ 3x + 2

=

x

+1

+

x

. +2

The best method to use in any particular circumstance will depend on the complexity, in terms of the degrees of the polynomials and the multiplicities of the roots of the denominator, of the function being considered and, to some extent, on the individual inclinations of the student; some prefer lengthy but straightforward solution of simultaneous equations, whilst others feel more at home carrying through shorter but more abstract calculations in their heads.

1.4.1 Complications and special cases
Having established the basic method for partial fractions, we now show, through further worked examples, how some complications are dealt with by extensions to the procedure. These extensions are introduced one at a time, but of course in any practical application more than one may be involved.

The degree of the numerator is greater than or equal to that of the denominator

Although we have not speciﬁcally mentioned the fact, it will be apparent from trying to apply method (i) of the previous subsection to such a case, that if the degree of the numerator (m) is not less than that of the denominator (n) then the ratio of two polynomials cannot be expressed in partial fractions.
To get round this diﬃculty it is necessary to start by dividing the denominator h(x) into the numerator g(x) to obtain a further polynomial, which we will denote by s(x), together with a function t(x) that is a ratio of two polynomials for which the degree of the numerator is less than that of the denominator. The function t(x) can therefore be expanded in partial fractions. As a formula,

f(x) = g(x) = s(x) + t(x) ≡ s(x) + r(x) .

h(x)

h(x)

(1.45)

It is apparent that the polynomial r(x) is the remainder obtained when g(x) is divided by h(x), and, in general, will be a polynomial of degree n − 1. It is also clear that the polynomial s(x) will be of degree m − n. Again, the actual division process can be set out as an algebraic long division sum but is probably more easily handled by writing (1.45) in the form

g(x) = s(x)h(x) + r(x)

(1.46)

or, more explicitly, as
g(x) = (sm−nxm−n + sm−n−1xm−n−1 + · · · + s0)h(x) + (rn−1xn−1 + rn−2xn−2 + · · · + r0) (1.47)

and then equating coeﬃcients.

21

PRELIMINARY ALGEBRA

We illustrate this procedure with the following worked example.

Find the partial fraction decomposition of the function x3 + 3x2 + 2x + 1
f(x) = x2 − x − 6 .

Since the degree of the numerator is 3 and that of the denominator is 2, a preliminary long division is necessary. The polynomial s(x) resulting from the division will have degree 3 − 2 = 1 and the remainder r(x) will be of degree 2 − 1 = 1 (or less). Thus we write
x3 + 3x2 + 2x + 1 = (s1x + s0)(x2 − x − 6) + (r1x + r0).
From equating the coeﬃcients of the various powers of x on the two sides of the equation, starting with the highest, we now obtain the simultaneous equations

1 = s1, 3 = s0 − s1, 2 = −s0 − 6s1 + r1, 1 = −6s0 + r0.
These are readily solved, in the given order, to yield s1 = 1, s0 = 4, r1 = 12 and r0 = 25. Thus f(x) can be written as

12x + 25

f(x)

=

x

+

4

+

x2

−

x

−

. 6

The last term can now be decomposed into partial fractions as previously. The zeros of

the denominator are at x = 3 and x = −2 and the application of any method from the

previous

subsection

yields

the

respective

constants

as

A1

=

12

1 5

and

A2

=

−

1 5

.

Thus

the

ﬁnal partial fraction decomposition of f(x) is

x

+

4

+

61 5(x −

3)

−

1 5(x +

. 2)

Factors of the form a2 + x2 in the denominator
We have so far assumed that the roots of h(x) = 0, needed for the factorisation of the denominator of f(x), can always be found. In principle they always can but in some cases they are not real. Consider, for example, attempting to express in partial fractions a polynomial ratio whose denominator is h(x) = x3 − x2 + 2x − 2. Clearly x = 1 is a zero of h(x), and so a ﬁrst factorisation is (x − 1)(x2 + 2). However we cannot make any further progress because the factor x2 + 2 cannot be expressed as (x − α)(x − β) for any real α and β.
Complex numbers are introduced later in this book (chapter 3) and, when the reader has studied them, he or she may wish to justify the procedure set out below. It can be shown to be equivalent to that already given, but the zeros of h(x) are now allowed to be complex and terms that are complex conjugates of each other are combined to leave only real terms.
Since quadratic factors of the form a2+x2 that appear in h(x) cannot be reduced to the product of two linear factors, partial fraction expansions including them need to have numerators in the corresponding terms that are not simply constants
22

1.4 PARTIAL FRACTIONS

Ai but linear functions of x, i.e. of the form Bix + Ci. Thus, in the expansion, linear terms (ﬁrst-degree polynomials) in the denominator have constants (zerodegree polynomials) in their numerators, whilst quadratic terms (second-degree polynomials) in the denominator have linear terms (ﬁrst-degree polynomials) in their numerators. As a symbolic formula, the partial fraction expansion of

g(x) (x − α1)(x − α2) · · · (x − αp)(x2 + a21)(x2 + a22) · · · (x2 + a2q)

should take the form

A1 x − α1

+

x

A2 − α2

+···+

Ap x − αp

+

B1x + C1 x2 + a21

+

B2x + C2 x2 + a22

+

···+

Bqx + Cq x2 + a2q

.

Of course, the degree of g(x) must be less than p + 2q; if it is not, an initial division must be carried out as demonstrated earlier.

Repeated factors in the denominator

Consider trying (incorrectly) to expand

x−4 f(x) = (x + 1)(x − 2)2

in partial fraction form as follows:

x−4 (x + 1)(x − 2)2

=

A1 x+1

+

(x

A2 − 2)2

.

Multiplying both sides of this supposed equality by (x + 1)(x − 2)2 produces an equation whose LHS is linear in x, whilst its RHS is quadratic. This is clearly wrong and so an expansion in the above form cannot be valid. The correction we must make is very similar to that needed in the previous subsection, namely that since (x − 2)2 is a quadratic polynomial the numerator of the term containing it must be a ﬁrst-degree polynomial, and not simply a constant.
The correct form for the part of the expansion containing the doubly repeated root is therefore (Bx + C)/(x − 2)2. Using this form and either of methods (i) and (ii) for determining the constants gives the full partial fraction expansion as

x−4 (x + 1)(x − 2)2

=

−5 9(x + 1)

+

5x − 16 9(x − 2)2 ,

as the reader may verify. Since any term of the form (Bx + C)/(x − α)2 can be written as

B(x − α) + C + Bα B C + Bα

(x − α)2

= x − α + (x − α)2 ,

and similarly for multiply repeated roots, an alternative form for the part of the partial fraction expansion containing a repeated root α is

D1 x−α

+

(x

D2 − α)2

+

···

+

(x

Dp − α)p

.

(1.48)

23

PRELIMINARY ALGEBRA

In this form, all x-dependence has disappeared from the numerators but at the expense of p − 1 additional terms; the total number of constants to be determined remains unchanged, as it must.
When describing possible methods of determining the constants in a partial fraction expansion, we noted that method (iii), p. 20, which avoids the need to solve simultaneous equations, is restricted to terms involving non-repeated roots. In fact, it can be applied in repeated-root situations, when the expansion is put in the form (1.48), but only to ﬁnd the constant in the term involving the largest inverse power of x − α, i.e. Dp in (1.48).
We conclude this section with a more protracted worked example that contains all three of the complications discussed.

Resolve the following expression F(x) into partial fractions:

x5 − 2x4 − x3 + 5x2 − 46x + 100

F(x) =

(x2 + 6)(x − 2)2

.

We note that the degree of the denominator (4) is not greater than that of the numerator (5), and so we must start by dividing the latter by the former. It follows, from the diﬀerence in degrees and the coeﬃcients of the highest powers in each, that the result will be a linear expression s1x + s0 with the coeﬃcient s1 equal to 1. Thus the numerator of F(x) must be expressible as

(x + s0)(x4 − 4x3 + 10x2 − 24x + 24) + (r3x3 + r2x2 + r1x + r0),

where the second factor in parentheses is the denominator of F(x) written as a polynomial. Equating the coeﬃcients of x4 gives −2 = −4+s0 and ﬁxes s0 as 2. Equating the coeﬃcients
of powers less than 4 gives equations involving the coeﬃcients ri as follows:

−1 = −8 + 10 + r3, 5 = −24 + 20 + r2,
−46 = 24 − 48 + r1, 100 = 48 + r0.

Thus the remainder polynomial r(x) can be constructed and F(x) written as

F (x)

=

x+

2+

−3x3 + 9x2 − 22x + (x2 + 6)(x − 2)2

52

≡

x+2

+ f(x).

The polynomial ratio f(x) can now be expressed in partial fraction form, noting that its denominator contains both a term of the form x2 + a2 and a repeated root. Thus

f(x)

=

Bx + C x2 + 6

+

D1 x−2

+

(x

D2 − 2)2

.

We could now put the RHS of this equation over the common denominator (x2 + 6)(x − 2)2
and ﬁnd B, C, D1 and D2 by equating coeﬃcients of powers of x. It is quicker, however, to use methods (iii) and (ii). Method (iii) gives D2 as (−24 + 36 − 44 + 52)/(4 + 6) = 2. We choose to evaluate the other coeﬃcients by method (ii), and setting x = 0, x = 1 and

24

1.5 BINOMIAL EXPANSION

x = −1 gives respectively

These equations reduce to

52

=

C

−

D1

+

2 ,

24 6 2 4

36 7

=

B

+C 7

− D1

+ 2,

86

=

C

−B

−

D1

+

2 .

63

7

39

4C − 12D1 = 40, B + C − 7D1 = 22, −9B + 9C − 21D1 = 72,

with solution B = 0, C = 1, D1 = −3. Thus, ﬁnally, we may rewrite the original expression F(x) in partial fractions as

F (x)

=

x

+

2

+

x2

1 +

6

−

x

3 −

2

+

(x

2 −

2)2 .

1.5 Binomial expansion
Earlier in this chapter we were led to consider functions containing powers of the sum or diﬀerence of two terms, e.g. (x − α)m. Later in this book we will ﬁnd numerous occasions on which we wish to write such a product of repeated factors as a polynomial in x or, more generally, as a sum of terms each of which contains powers of x and α separately, as opposed to a power of their sum or diﬀerence.
To make the discussion general and the result applicable to a wide variety of situations, we will consider the general expansion of f(x) = (x + y)n, where x and y may stand for constants, variables or functions and, for the time being, n is a positive integer. It may not be obvious what form the general expansion takes but some idea can be obtained by carrying out the multiplication explicitly for small values of n. Thus we obtain successively
(x + y)1 = x + y, (x + y)2 = (x + y)(x + y) = x2 + 2xy + y2, (x + y)3 = (x + y)(x2 + 2xy + y2) = x3 + 3x2y + 3xy2 + y3, (x + y)4 = (x + y)(x3 + 3x2y + 3xy2 + y3) = x4 + 4x3y + 6x2y2 + 4xy3 + y4.
This does not establish a general formula, but the regularity of the terms in the expansions and the suggestion of a pattern in the coeﬃcients indicate that a general formula for power n will have n + 1 terms, that the powers of x and y in every term will add up to n and that the coeﬃcients of the ﬁrst and last terms will be unity whilst those of the second and penultimate terms will be n.
25

PRELIMINARY ALGEBRA

In fact, the general expression, the binomial expansion for power n, is given by

k=n
(x + y)n = nCkxn−kyk,
k=0

(1.49)

where nCk is called the binomial coeﬃcient and is expressed in terms of factorial functions by n!/[k!(n − k)!]. Clearly, simply to make such a statement does not

constitute proof of its validity, but, as we will see in subsection 1.5.2, (1.49) can

be proved using a method called induction. Before turning to that proof, we

investigate some of the elementary properties of the binomial coeﬃcients.

1.5.1 Binomial coefﬁcients

As stated above, the binomial coeﬃcients are deﬁned by

nCk

≡

n! k!(n − k)!

≡

n k

for 0 ≤ k ≤ n,

(1.50)

where in the second identity we give a common alternative notation for nCk. Obvious properties include

(i) nC0 = nCn = 1, (ii) nC1 = nCn−1 = n, (iii) nCk = nCn−k.

We note that, for any given n, the largest coeﬃcient in the binomial expansion is

the

middle

one

(k

=

n/2)

if

n

is

even;

the

middle

two

coeﬃcients

(k

=

1 2

(n

±

1))

are equal largest if n is odd. Somewhat less obvious is the result

nCk

+

nCk−1

=

n! k!(n − k)!

+

(k

−

n! 1)!(n − k

+ 1)!

n![(n + 1 − k) + k] = k!(n + 1 − k)!

=

(n + 1)! k!(n + 1 − k)!

=

n+1 Ck .

(1.51)

An equivalent statement, in which k has been redeﬁned as k + 1, is

nCk + nCk+1 = n+1Ck+1.

(1.52)

1.5.2 Proof of the binomial expansion
We are now in a position to prove the binomial expansion (1.49). In doing so, we introduce the reader to a procedure applicable to certain types of problems and known as the method of induction. The method is discussed much more fully in subsection 1.7.1.
26

1.6 PROPERTIES OF BINOMIAL COEFFICIENTS

We start by assuming that (1.49) is true for some positive integer n = N. We now proceed to show that this implies that it must also be true for n = N+1, as follows:

N
(x + y)N+1 = (x + y) N CkxN−kyk

k=0

N

N

=

N CkxN+1−kyk +

N CkxN−kyk+1

k=0

k=0

N

N+1

=

N CkxN+1−kyk +

N Cj−1x(N+1)−j yj ,

k=0

j=1

where in the ﬁrst line we have used the assumption and in the third line have
moved the second summation index by unity, by writing k + 1 = j. We now separate oﬀ the ﬁrst term of the ﬁrst sum, NC0xN+1, and write it as N+1C0xN+1; we can do this since, as noted in (i) following (1.50), nC0 = 1 for every n. Similarly, the last term of the second summation can be replaced by N+1CN+1yN+1.
The remaining terms of each of the two summations are now written together,
with the summation index denoted by k in both terms. Thus

N

(x + y)N+1 = N+1C0xN+1 +

N Ck + N Ck−1 x(N+1)−kyk + N+1CN+1yN+1

k=1

N

= N+1C0xN+1 +

N+1Ckx(N+1)−kyk + N+1CN+1yN+1

k=1

N+1

=

N +1 Ck x(N +1)−k y k .

k=0

In going from the ﬁrst to the second line we have used result (1.51). Now we observe that the ﬁnal overall equation is just the original assumed result (1.49) but with n = N + 1. Thus it has been shown that if the binomial expansion is assumed to be true for n = N, then it can be proved to be true for n = N + 1. But it holds trivially for n = 1, and therefore for n = 2 also. By the same token it is valid for n = 3, 4, . . . , and hence is established for all positive integers n.

1.6 Properties of binomial coeﬃcients
1.6.1 Identities involving binomial coefﬁcients
There are many identities involving the binomial coeﬃcients that can be derived directly from their deﬁnition, and yet more that follow from their appearance in the binomial expansion. Only the most elementary ones, given earlier, are worth committing to memory but, as illustrations, we now derive two results involving sums of binomial coeﬃcients.
27

PRELIMINARY ALGEBRA

The ﬁrst is a further application of the method of induction. Consider the proposal that, for any n ≥ 1 and k ≥ 0,

n−1
k+sCk = n+kCk+1.
s=0

(1.53)

Notice that here n, the number of terms in the sum, is the parameter that varies, k is a ﬁxed parameter, whilst s is a summation index and does not appear on the RHS of the equation.

Now we suppose that the statement (1.53) about the value of the sum of the binomial coeﬃcients kCk, k+1Ck, . . . , k+n−1Ck is true for n = N. We next write down a series with an extra term and determine the implications of the supposition for
the new series:

N+1−1

N−1

k+sCk =

k+sCk + k+N Ck

s=0

s=0

= N+kCk+1 + N+kCk

= N+k+1Ck+1.

But this is just proposal (1.53) with n now set equal to N + 1. To obtain the last line, we have used (1.52), with n set equal to N + k.
It only remains to consider the case n = 1, when the summation only contains one term and (1.53) reduces to

kCk = 1+kCk+1.

This is trivially valid for any k since both sides are equal to unity, thus completing the proof of (1.53) for all positive integers n.
The second result, which gives a formula for combining terms from two sets of binomial coeﬃcients in a particular way (a kind of ‘convolution’, for readers who are already familiar with this term), is derived by applying the binomial expansion directly to the identity

(x + y)p(x + y)q ≡ (x + y)p+q.

Written in terms of binomial expansions, this reads

p

q

p+q

pCsxp−sys

qCtxq−tyt =

p+q Cr xp+q−r yr .

s=0

t=0

r=0

We now equate coeﬃcients of xp+q−ryr on the two sides of the equation, noting

that on the LHS all combinations of s and t such that s + t = r contribute. This

gives as an identity that

r

r

pCr−tqCt = p+qCr =

p Ct q Cr−t .

t=0

t=0

(1.54)

28

1.6 PROPERTIES OF BINOMIAL COEFFICIENTS

We have speciﬁcally included the second equality to emphasise the symmetrical nature of the relationship with respect to p and q.
Further identities involving the coeﬃcients can be obtained by giving x and y special values in the deﬁning equation (1.49) for the expansion. If both are set equal to unity then we obtain (using the alternative notation so as to produce familiarity with it)

n + n + n + · · · + n = 2n,

0

1

2

n

(1.55)

whilst setting x = 1 and y = −1 yields

n − n + n − · · · + (−1)n n = 0.

0

1

2

n

(1.56)

1.6.2 Negative and non-integral values of n

Up till now we have restricted n in the binomial expansion to be a positive integer. Negative values can be accommodated, but only at the cost of an inﬁnite series of terms rather than the ﬁnite one represented by (1.49). For reasons that are intuitively sensible and will be discussed in more detail in chapter 4, very often we require an expansion in which, at least ultimately, successive terms in the inﬁnite series decrease in magnitude. For this reason, if x > y we consider (x + y)−m, where m itself is a positive integer, in the form

(x + y)n = (x + y)−m = x−m

1+ y

−m
.

x

Since the ratio y/x is less than unity, terms containing higher powers of it will be small in magnitude, whilst raising the unit term to any power will not aﬀect its magnitude. If y > x the roles of the two must be interchanged.
We can now state, but will not explicitly prove, the form of the binomial expansion appropriate to negative values of n (n equal to −m):

∞
(x + y)n = (x + y)−m = x−m −mCk

yk ,
x

k=0

(1.57)

where the hitherto undeﬁned quantity −mCk, which appears to involve factorials of negative numbers, is given by

−mCk

=

(−1)k m(m

+ 1) · · · (m k!

+k

− 1)

=

(−1)k

(m + k − 1)! (m − 1)!k!

=

(−1)k

m+k−1 Ck . (1.58)

The binomial coeﬃcient on the extreme right of this equation has its normal meaning and is well deﬁned since m + k − 1 ≥ k.
Thus we have a deﬁnition of binomial coeﬃcients for negative integer values of n in terms of those for positive n. The connection between the two may not

29

PRELIMINARY ALGEBRA

be obvious, but they are both formed in the same way in terms of recurrence
relations. Whatever the sign of n, the series of coeﬃcients nCk can be generated by starting with nC0 = 1 and using the recurrence relation

nCk+1

=

n k

− +

k 1

n Ck .

(1.59)

The diﬀerence is that for positive integer n the series terminates when k = n, whereas for negative n there is no such termination – in line with the inﬁnite series of terms in the corresponding expansion.
Finally we note that, in fact, equation (1.59) generates the appropriate coefﬁcients for all values of n, positive or negative, integer or non-integer, with the obvious exception of the case in which x = −y and n is negative. For non-integer n the expansion does not terminate, even if n is positive.

1.7 Some particular methods of proof
Much of the mathematics used by physicists and engineers is concerned with obtaining a particular value, formula or function from a given set of data and stated conditions. However, just as it is essential in physics to formulate the basic laws and so be able to set boundaries on what can or cannot happen, so it is important in mathematics to be able to state general propositions about the outcomes that are or are not possible. To this end one attempts to establish theorems that state in as general a way as possible mathematical results that apply to particular types of situation. We conclude this introductory chapter by describing two methods that can sometimes be used to prove particular classes of theorems.
The two general methods of proof are known as proof by induction (which has already been met in this chapter) and proof by contradiction. They share the common characteristic that at an early stage in the proof an assumption is made that a particular (unproven) statement is true; the consequences of that assumption are then explored. In an inductive proof the conclusion is reached that the assumption is self-consistent and has other equally consistent but broader implications, which are then applied to establish the general validity of the assumption. A proof by contradiction, however, establishes an internal inconsistency and thus shows that the assumption is unsustainable; the natural consequence of this is that the negative of the assumption is established as true.
Later in this book use will be made of these methods of proof to explore new territory, e.g. to examine the properties of vector spaces, matrices and groups. However, at this stage we will draw our illustrative and test examples from earlier sections of this chapter and other topics in elementary algebra and number theory.
30

1.7 SOME PARTICULAR METHODS OF PROOF

1.7.1 Proof by induction
The proof of the binomial expansion given in subsection 1.5.2 and the identity established in subsection 1.6.1 have already shown the way in which an inductive proof is carried through. They also indicated the main limitation of the method, namely that only an initially supposed result can be proved. Thus the method of induction is of no use for deducing a previously unknown result; a putative equation or result has to be arrived at by some other means, usually by noticing patterns or by trial and error using simple values of the variables involved. It will also be clear that propositions that can be proved by induction are limited to those containing a parameter that takes a range of integer values (usually inﬁnite).
For a proposition involving a parameter n, the ﬁve steps in a proof using induction are as follows.
(i) Formulate the supposed result for general n. (ii) Suppose (i) to be true for n = N (or more generally for all values of
n ≤ N; see below), where N is restricted to lie in the stated range. (iii) Show, using only proven results and supposition (ii), that proposition (i)
is true for n = N + 1. (iv) Demonstrate directly, and without any assumptions, that proposition (i) is
true when n takes the lowest value in its range. (v) It then follows from (iii) and (iv) that the proposition is valid for all values
of n in the stated range.
(It should be noted that, although many proofs at stage (iii) require the validity of the proposition only for n = N, some require it for all n less than or equal to N – hence the form of inequality given in parentheses in the stage (ii) assumption.)
To illustrate further the method of induction, we now apply it to two worked examples; the ﬁrst concerns the sum of the squares of the ﬁrst n natural numbers.

Prove that the sum of the squares of the ﬁrst n natural numbers is given by

n

r2

=

1 6

n(n

+

1)(2n + 1).

r=1

(1.60)

As previously we start by assuming the result is true for n = N. Then it follows that

N+1

N

r2 = r2 + (N + 1)2

r=1

r=1

=

1 6

N

(N

+ 1)(2N

+ 1) + (N

+ 1)2

=

1 6

(N

+ 1)[N(2N

+

1) + 6N

+ 6]

=

1 6

(N

+ 1)[(2N

+ 3)(N

+ 2)]

=

1 6

(N

+ 1)[(N

+ 1)

+ 1][2(N

+ 1) + 1].

31

PRELIMINARY ALGEBRA
This is precisely the original assumption, but with N replaced by N + 1. To complete the proof we only have to verify (1.60) for n = 1. This is trivially done and establishes the result for all positive n. The same and related results are obtained by a diﬀerent method in subsection 4.2.5.
Our second example is somewhat more complex and involves two nested proofs by induction: whilst trying to establish the main result by induction, we ﬁnd that we are faced with a second proposition which itself requires an inductive proof.
Show that Q(n) = n4 + 2n3 + 2n2 + n is divisible by 6 (without remainder) for all positive integer values of n.
Again we start by assuming the result is true for some particular value N of n, whilst noting that it is trivially true for n = 0. We next examine Q(N + 1), writing each of its terms as a binomial expansion:
Q(N + 1) = (N + 1)4 + 2(N + 1)3 + 2(N + 1)2 + (N + 1) = (N4 + 4N3 + 6N2 + 4N + 1) + 2(N3 + 3N2 + 3N + 1) + 2(N2 + 2N + 1) + (N + 1) = (N4 + 2N3 + 2N2 + N) + (4N3 + 12N2 + 14N + 6).
Now, by our assumption, the group of terms within the ﬁrst parentheses in the last line is divisible by 6 and clearly so are the terms 12N2 and 6 within the second parentheses. Thus it comes down to deciding whether 4N3 + 14N is divisible by 6 – or equivalently, whether R(N) = 2N3 + 7N is divisible by 3.
To settle this latter question we try using a second inductive proof and assume that R(N) is divisible by 3 for N = M, whilst again noting that the proposition is trivially true for N = M = 0. This time we examine R(M + 1):
R(M + 1) = 2(M + 1)3 + 7(M + 1) = 2(M3 + 3M2 + 3M + 1) + 7(M + 1) = (2M3 + 7M) + 3(2M2 + 2M + 3)
By assumption, the ﬁrst group of terms in the last line is divisible by 3 and the second group is patently so. We thus conclude that R(N) is divisible by 3 for all N ≥ M, and taking M = 0 shows that it is divisible by 3 for all N.
We can now return to the main proposition and conclude that since R(N) = 2N3 + 7N is divisible by 3, 4N3 + 12N2 + 14N + 6 is divisible by 6. This in turn establishes that the divisibility of Q(N + 1) by 6 follows from the assumption that Q(N) divides by 6. Since Q(0) clearly divides by 6, the proposition in the question is established for all values of n.
1.7.2 Proof by contradiction
The second general line of proof, but again one that is normally only useful when the result is already suspected, is proof by contradiction. The questions it can attempt to answer are only those that can be expressed in a proposition that is either true or false. Clearly, it could be argued that any mathematical result can be so expressed but, if the proposition is no more than a guess, the chances of success are negligible. Valid propositions containing even modest formulae are either the result of true inspiration or, much more normally, yet another reworking of an old chestnut!
32

1.7 SOME PARTICULAR METHODS OF PROOF

The essence of the method is to exploit the fact that mathematics is required to be self-consistent, so that, for example, two calculations of the same quantity, starting from the same given data but proceeding by diﬀerent methods, must give the same answer. Equally, it must not be possible to follow a line of reasoning and draw a conclusion that contradicts either the input data or any other conclusion based upon the same data.
It is this requirement on which the method of proof by contradiction is based. The crux of the method is to assume that the proposition to be proved is not true, and then use this incorrect assumption and ‘watertight’ reasoning to draw a conclusion that contradicts the assumption. The only way out of the self-contradiction is then to conclude that the assumption was indeed false and therefore that the proposition is true.
It must be emphasised that once a (false) contrary assumption has been made, every subsequent conclusion in the argument must follow of necessity. Proof by contradiction fails if at any stage we have to admit ‘this may or may not be the case’. That is, each step in the argument must be a necessary consequence of results that precede it (taken together with the assumption), rather than simply a possible consequence.
It should also be added that if no contradiction can be found using sound reasoning based on the assumption then no conclusion can be drawn about either the proposition or its negative and some other approach must be tried.
We illustrate the general method with an example in which the mathematical reasoning is straightforward, so that attention can be focussed on the structure of the proof.

A rational number r is a fraction r = p/q in which p and q are integers with q positive. Further, r is expressed in its lowest terms, any integer common factor of p and q having been divided out.
Prove that the square root of an integer m cannot be a rational number, unless the square root itself is an integer.

We begin by supposing that the stated result is not true and that we can write an equation

√ m

=

r

=

p

for integers m, p, q with

q = 1.

q

It then follows that p2 = mq2. But, since r is expressed in its lowest terms, p and q, and hence p2 and q2, have no factors in common. However, m is an integer; this is only possible if q = 1 and p2 = m. This conclusion contradicts the√requirement that q = 1 and so leads to the conclusion that it was wrong to suppose that m can be expressed as a non-integer
rational number. This completes the proof of the statement in the question.

Our second worked example, also taken from elementary number theory, involves slightly more complicated mathematical reasoning but again exhibits the structure associated with this type of proof.

33

PRELIMINARY ALGEBRA

The prime integers pi are labelled in ascending order, thus p1 = 1, p2 = 2, p5 = 7, etc. Show that there is no largest prime number.
Assume, on the contrary, that there is a largest prime and let it be pN. Consider now the number q formed by multiplying together all the primes from p1 to pN and then adding one to the product, i.e.
q = p1p2 · · · pN + 1.
By our assumption pN is the largest prime, and so no number can have a prime factor greater than this. However, for every prime pi, i = 1, 2, . . . , N, the quotient q/pi has the form Mi + (1/pi) with Mi an integer and 1/pi non-integer. This means that q/pi cannot be an integer and so pi cannot be a divisor of q.
Since q is not divisible by any of the (assumed) ﬁnite set of primes, it must be itself a prime. As q is also clearly greater than pN, we have a contradiction. This shows that our assumption that there is a largest prime integer must be false, and so it follows that there is no largest prime integer.
It should be noted that the given construction for q does not generate all the primes that actually exist (e.g. for N = 3, q = 7 rather than the next actual prime value of 5, is found), but this does not matter for the purposes of our proof by contradiction.

1.7.3 Necessary and sufﬁcient conditions

As the ﬁnal topic in this introductory chapter, we consider brieﬂy the notion of, and distinction between, necessary and suﬃcient conditions in the context of proving a mathematical proposition. In ordinary English the distinction is well deﬁned, and that distinction is maintained in mathematics. However, in the authors’ experience students tend to overlook it and assume (wrongly) that, having proved that the validity of proposition A implies the truth of proposition B, it follows by ‘reversing the argument’ that the validity of B automatically implies that of A.
As an example, let proposition A be that an integer N is divisible without remainder by 6, and proposition B be that N is divisible without remainder by 2. Clearly, if A is true then it follows that B is true, i.e. A is a suﬃcient condition for B; it is not however a necessary condition, as is trivially shown by taking N as 8. Conversely, the same value of N shows that whilst the validity of B is a necessary condition for A to hold, it is not suﬃcient.
An alternative terminology to ‘necessary’ and ‘suﬃcient’ often employed by mathematicians is that of ‘if’ and ‘only if’, particularly in the combination ‘if and only if’ which is usually written as IFF or denoted by a double-headed arrow ⇐⇒ . The equivalent statements can be summarised by

A if B

A is true if B is true or B is a suﬃcient condition for A

B =⇒ A, B =⇒ A,

A only if B A is true only if B is true or

A =⇒ B,

B is a necessary consequence of A A =⇒ B,

34

1.7 SOME PARTICULAR METHODS OF PROOF

A IFF B A is true if and only if B is true or B ⇐⇒ A, A and B necessarily imply each other B ⇐⇒ A.
Although at this stage in the book we are able to employ for illustrative purposes only simple and fairly obvious results, the following example is given as a model of how necessary and suﬃcient conditions should be proved. The essential point is that for the second part of the proof (whether it be the ‘necessary’ part or the ‘suﬃcient’ part) one needs to start again from scratch; more often than not, the lines of the second part of the proof will not be simply those of the ﬁrst written in reverse order.

Prove that (A) a function f(x) is a quadratic polynomial with zeros at x = 2 and x = 3 if and only if (B) the function f(x) has the form λ(x2 − 5x + 6) with λ a non-zero constant.

(1) Assume A, i.e. that f(x) is a quadratic polynomial with zeros at x = 2 and x = 3. Let its form be ax2 + bx + c with a = 0. Then we have
4a + 2b + c = 0, 9a + 3b + c = 0,
and subtraction shows that 5a + b = 0 and b = −5a. Substitution of this into the ﬁrst of the above equations gives c = −4a − 2b = −4a + 10a = 6a. Thus, it follows that
f(x) = a(x2 − 5x + 6) with a = 0,
and establishes the ‘A only if B’ part of the stated result.

(2) Now assume that f(x) has the form λ(x2 − 5x + 6) with λ a non-zero constant. Firstly we note that f(x) is a quadratic polynomial, and so it only remains to prove that its zeros occur at x = 2 and x = 3. Consider f(x) = 0, which, after dividing through by the non-zero constant λ, gives
x2 − 5x + 6 = 0.

We proceed by using a technique known as completing the square, for the purposes of illustration, although the factorisation of the above equation should be clear to the reader. Thus we write

x2

−

5x

+

(

5 2

)2

−

(

5 2

)2

+

6

=

0,

(x −

5 2

)2

=

1 4

,

x−

5 2

=

±

1 2

.

The two roots of f(x) = 0 are therefore x = 2 and x = 3; these x-values give the zeros

of f(x). This establishes the second (‘A if B’) part of the result. Thus we have shown that the assumption of either condition implies the validity of the other and the proof is

complete.

It should be noted that the propositions have to be carefully and precisely formulated. If, for example, the word ‘quadratic’ were omitted from A, statement B would still be a suﬃcient condition for A but not a necessary one, since f(x) could then be x3 − 4x2 + x + 6 and A would not require B. Omitting the constant λ from the stated form of f(x) in B has the same eﬀect. Conversely, if A were to state that f(x) = 3(x − 2)(x − 3) then B would be a necessary condition for A but not a suﬃcient one.

35

PRELIMINARY ALGEBRA

1.8 Exercises

Polynomial equations

1.1

Continue the investigation of equation (1.7), namely

g(x) = 4x3 + 3x2 − 6x − 1,

as follows.

(a) Make a table of values of g(x) for integer values of x between −2 and 2. Use

it and the information derived in the text to draw a graph and so determine

the roots of g(x) = 0 as accurately as possible.

(b) Find one accurate root of g(x) = 0 by inspection and hence determine precise

values for the other two roots.

(c) Show that f(x) = 4x3 + 3x2 − 6x − k = 0 has only one real root unless

−5

≤

k

≤

7 4

.

1.2

Determine how the number of real roots of the equation

g(x) = 4x3 − 17x2 + 10x + k = 0

depends upon k. Are there any cases for which the equation has exactly two

distinct real roots?

1.3

Continue the analysis of the polynomial equation

f(x) = x7 + 5x6 + x4 − x3 + x2 − 2 = 0,

investigated in subsection 1.1.1, as follows.

(a) By writing the ﬁfth-degree polynomial appearing in the expression for f (x) in the form 7x5 + 30x4 + a(x − b)2 + c, show that there is in fact only one positive root of f(x) = 0.
(b) By evaluating f(1), f(0) and f(−1), and by inspecting the form of f(x) for negative values of x, determine what you can about the positions of the real roots of f(x) = 0.

1.4

Given that x = 2 is one root of

g(x) = 2x4 + 4x3 − 9x2 − 11x − 6 = 0,

use factorisation to determine how many real roots it has.

1.5

Construct the quadratic equations that have the following pairs of roots:

(a) −6, −3; (b) 0, 4; (c) 2, 2; (d) 3 + 2i, 3 − 2i, where i2 = −1.

1.6

Use the results of (i) equation (1.13), (ii) equation (1.12) and (iii) equation (1.14)

to prove that if the roots of 3x3 − x2 − 10x + 8 = 0 are α1, α2 and α3 then

(a) α−1 1 + α−2 1 + α−3 1 = 5/4, (b) α21 + α22 + α23 = 61/9, (c) α31 + α32 + α33 = −125/27. (d) Convince yourself that eliminating (say) α2 and α3 from (i), (ii) and (iii) does
not give a simple explicit way of ﬁnding α1.

1.7

Prove that

by considering

Trigonometric identities

√

π cos =

3√+ 1

12 2 2

36

1.8 EXERCISES

(a) the sum of the sines of π/3 and π/6, (b) the sine of the sum of π/3 and π/4.

1.8

The following exercises are based on the half-angle formulae.

√ (a) Use the fact that sin(π/6) = 1/2 to prove that tan(π/12) = 2 − 3.

(b) Use the √result of (a) to show further that tan(π/24) = q(2 − q) where q2 = 2 + 3.

1.9

Find the real solutions of

(a) 3 sin θ − 4 cos θ = 2, (b) 4 sin θ + 3 cos θ = 6, (c) 12 sin θ − 5 cos θ = −6.

1.10 If s = sin(π/8), prove that
8s4 − 8s2 + 1 = 0, √ and hence show that s = [(2 − 2)/4]1/2. 1.11 Find all the solutions of

sin θ + sin 4θ = sin 2θ + sin 3θ

that lie in the range −π < θ ≤ π. What is the multiplicity of the solution θ = 0?

Coordinate geometry
1.12 Obtain in the form (1.38) the equations that describe the following:
(a) a circle of radius 5 with its centre at (1, −1); (b) the line 2x + 3y + 4 = 0 and the line orthogonal to it which passes through
(1, 1); (c) an ellipse of eccentricity 0.6 with centre (1, 1) and its major axis of length 10
parallel to the y-axis.
1.13 Determine the forms of the conic sections described by the following equations:
(a) x2 + y2 + 6x + 8y = 0; (b) 9x2 − 4y2 − 54x − 16y + 29 = 0; (c) 2x2 + 2y2 + 5xy − 4x + y − 6 = 0; (d) x2 + y2 + 2xy − 8x + 8y = 0.
1.14 For the ellipse x2 y2 + =1 a2 b2
with eccentricity e, the two points (−ae, 0) and (ae, 0) are known as its foci. Show that the sum of the distances from any point on the ellipse to the foci is 2a. (The constancy of the sum of the distances from two ﬁxed points can be used as an alternative deﬁning property of an ellipse.)

Partial fractions

1.15 Resolve the following into partial fractions using the three methods given in section 1.4, verifying that the same decomposition is obtained by each method:

2x + 1 (a) x2 + 3x − 10 ,

4 (b) x2 − 3x .

37

PRELIMINARY ALGEBRA

1.16 Express the following in partial fraction form:

2x3 − 5x + 1 (a) x2 − 2x − 8 ,

x2 + x − 1 (b) x2 + x − 2 .

1.17 Rearrange the following functions in partial fraction form:

x−6 (a) x3 − x2 + 4x − 4 ,

x3 + 3x2 + x + 19 (b) x4 + 10x2 + 9 .

1.18 Resolve the following into partial fractions in such a way that x does not appear in any numerator:

2x2 + x + 1 (a) (x − 1)2(x + 3) ,

x2 − 2 (b) x3 + 8x2 + 16x ,

x3 − x − 1 (c) (x + 3)3(x + 1) .

Binomial expansion

1.19 Evaluate those of the following that are deﬁned: (a) 5C3, (b) 3C5, (c) −5C3, (d)

−3C5.

√

1.20 Use a binomial expansion to evaluate 1/ 4.2 to ﬁve places of decimals, and

compare it with the accurate answer obtained using a calculator.

Proof by induction and contradiction

1.21 Prove by induction that

n

r

=

1 2

n(n

+

1)

and

r=1

n

r3

=

1 4

n2(n

+

1)2.

r=1

1.22 Prove by induction that

1 + r + r2

+ · · · + rk

+ · · · + rn

=

1 − rn+1 1−r .

1.23 Prove that 32n + 7, where n is a non-negative integer, is divisible by 8.
1.24 If a sequence of terms, un, satisﬁes the recurrence relation un+1 = (1 − x)un + nx, with u1 = 0, show, by induction, that, for n ≥ 1,

un

=

1 [nx − 1 + (1 − x)n]. x

1.25 Prove by induction that

n1

θ

2r tan 2r

1 = 2n cot

θ 2n

− cot θ.

r=1

1.26 The quantities ai in this exercise are all positive real numbers.

(a) Show that

a1a2 ≤

a1 + a2

2
.

2

(b) Hence prove, by induction on m, that

a1a2 · · · ap ≤

a1 + a2 + · · · + ap

p
,

p

where p = 2m with m a positive integer. Note that each increase of m by unity doubles the number of factors in the product.

38

1.9 HINTS AND ANSWERS

1.27 Establish the values of k for which the binomial coeﬃcient pCk is divisible by p when p is a prime number. Use your result and the method of induction to prove that np − n is divisible by p for all integers n and all prime numbers p. Deduce that n5 − n is divisible by 30 for any integer n.
1.28 An arithmetic progression of integers an is one in which an = a0 + nd, where a0 and d are integers and n takes successive values 0, 1, 2, . . . .
(a) Show that if any one term of the progression is the cube of an integer then so are inﬁnitely many others.
(b) Show that no cube of an integer can be expressed as 7n + 5 for some positive integer n.
1.29 Prove, by the method of contradiction, that the equation
xn + an−1xn−1 + · · · + a1x + a0 = 0,
in which all the coeﬃcients ai are integers, cannot have a rational root, unless that root is an integer. Deduce that any integral root must be a divisor of a0 and hence ﬁnd all rational roots of
(a) x4 + 6x3 + 4x2 + 5x + 4 = 0, (b) x4 + 5x3 + 2x2 − 10x + 6 = 0.
Necessary and suﬃcient conditions 1.30 Prove that the equation ax2 + bx + c = 0, in which a, b and c are real and a > 0,
has two real distinct solutions IFF b2 > 4ac. 1.31 For the real variable x, show that a suﬃcient, but not necessary, condition for
f(x) = x(x + 1)(2x + 1) to be divisible by 6 is that x is an integer. 1.32 Given that at least one of a and b, and at least one of c and d, are non-zero,
show that ad = bc is both a necessary and suﬃcient condition for the equations
ax + by = 0,
cx + dy = 0,
to have a solution in which at least one of x and y is non-zero. 1.33 The coeﬃcients ai in the polynomial Q(x) = a4x4 + a3x3 + a2x2 + a1x are all
integers. Show that Q(n) is divisible by 24 for all integers n ≥ 0 if and only if all of the following conditions are satisﬁed: (i) 2a4 + a3 is divisible by 4; (ii) a4 + a2 is divisible by 12; (iii) a4 + a3 + a2 + a1 is divisible by 24.

1.9 Hints and answers

√

√

1.1

(b)

The

roots

are

1,

1 8

(−7

+

33)

=

−0.1569,

1 8

(−7

−

33) = −1.593. (c) −5 and

7 4

are

the

values

of

k

that

make

f(−1)

and

f(

1 2

)

equal

to

zero.

1.3

(a)

a

= 4,

b=

3 8

and

c

=

23 16

are

all

positive.

Therefore

f (x) > 0

for

all

x > 0.

(b) f(1) = 5, f(0) = −2 and f(−1) = 5, and so there is at least one root in each

of the ranges 0 < x < 1 and −1 <√x < 0. (x7 + 5x6) + (x4 − x3) + (x2 − 2) is positive deﬁnite for −5 < x < − 2. There are therefore no roots in this

range, but there must be one to the left of x = −5.

1.5

(a) x2 + 9x + 18 = 0;√(b) x2 − 4x = 0; (c) x2 − 4x + 4 = 0; (d) x2 − 6x + 13 = 0.

1.7

(a) Use sin(π/4) = 1/ 2. (b) Use results (1.20) and (1.21).

1.9

(a) 1.339, −2.626. (b) No solution because 62 > 42 + 32. (c) −0.0849, −2.276.

39

PRELIMINARY ALGEBRA

1.11 Show that the equation is equivalent to sin(5θ/2) sin(θ) sin(θ/2) = 0.

Solutions are −4π/5, −2π/5, 0, 2π/5, 4π/5, π. The solution θ = 0 has multiplicity

3.

1.13 (a) A circle of radius 5 centred on (−3, −4).

(b) A hyperbola with ‘centre’ (3, −2) and ‘semi-axes’ 2 and 3.

(c) The expression factorises into two lines, x + 2y − 3 = 0 and 2x + y + 2 = 0.

(d) Write the expression as (x + y)2 = 8(x − y) to see that it represents a parabola

passing through the origin, with the line x + y = 0 as its axis of symmetry.

1.15

5

9

(a) 7(x − 2) + 7(x + 5) ,

(b)

−4 3x

+

4 3(x −

3)

.

1.17

(a)

x+2 x2 + 4

−

1 x − 1,

x+1

2

(b) x2 + 9 + x2 + 1 .

1.19 (a) 10, (b) not deﬁned, (c) −35, (d) −21.

1.21 Look for factors common to the n = N sum and the additional n = N + 1 term,

so as to reduce the sum for n = N + 1 to a single term.

1.23 Write 32n as 8m − 7.

1.25 Use the half-angle formulae of equations (1.32) to (1.34) to relate functions of

θ/2k to those of θ/2k+1.

1.27

Divisible for k = 1, 2, . . . , p − 1. Expand (n + 1)p as np +

p−1 1

p

Ck

nk

+

1.

Apply

the stated result for p = 5. Note that n5 − n = n(n − 1)(n + 1)(n2 + 1); the product

of any three consecutive integers must divide by both 2 and 3.

1.29 By assuming x = p/q with q = 1, show that a fraction −pn/q is equal to an integer an−1pn−1 + · · · + a1pqn−2 + a0qn−1. This is a contradiction, and is only resolved if q = 1 and the root is an integer.

(a) The only possible candidates are ±1, ±2, ±4. None is a root.

(b) The only possible candidates are ±1, ±2, ±3, ±6. Only −3 is a root.

1.31 f(x) can be written as x(x + 1)(x + 2) + x(x + 1)(x − 1). Each term consists of

the product of three consecutive integers, of which one must therefore divide by

2 and (a diﬀerent) one by 3. Thus each term separately divides by 6, and so

therefore does f(x). Note that if x is the root of 2x3 + 3x2 + x − 24 = 0 that lies

near the non-integer value x = 1.826, then x(x + 1)(2x + 1) = 24 and therefore

divides by 6.

1.33 Note that, e.g., the condition for 6a4 + a3 to be divisible by 4 is the same as the

condition for 2a4 + a3 to be divisible by 4.

For the necessary (only if) part of the proof set n = 1, 2, 3 and take integer

combinations of the resulting equations.

For the suﬃcient (if) part of the proof use the stated conditions to prove the

proposition by induction. Note that n3 − n is divisible by 6 and that n2 + n is

even.

40

2
Preliminary calculus
This chapter is concerned with the formalism of probably the most widely used mathematical technique in the physical sciences, namely the calculus. The chapter divides into two sections. The ﬁrst deals with the process of diﬀerentiation and the second with its inverse process, integration. The material covered is essential for the remainder of the book and serves as a reference. Readers who have previously studied these topics should ensure familiarity by looking at the worked examples in the main text and by attempting the exercises at the end of the chapter.
2.1 Diﬀerentiation Diﬀerentiation is the process of determining how quickly or slowly a function varies, as the quantity on which it depends, its argument, is changed. More speciﬁcally it is the procedure for obtaining an expression (numerical or algebraic) for the rate of change of the function with respect to its argument. Familiar examples of rates of change include acceleration (the rate of change of velocity) and chemical reaction rate (the rate of change of chemical composition). Both acceleration and reaction rate give a measure of the change of a quantity with respect to time. However, diﬀerentiation may also be applied to changes with respect to other quantities, for example the change in pressure with respect to a change in temperature.
Although it will not be apparent from what we have said so far, diﬀerentiation is in fact a limiting process, that is, it deals only with the inﬁnitesimal change in one quantity resulting from an inﬁnitesimal change in another.
2.1.1 Differentiation from ﬁrst principles Let us consider a function f(x) that depends on only one variable x, together with numerical constants, for example, f(x) = 3x2 or f(x) = sin x or f(x) = 2 + 3/x.
41

PRELIMINARY CALCULUS

f(x + ∆x)

A ∆f

P

f(x)

∆x θ
x x + ∆x
Figure 2.1 The graph of a function f(x) showing that the gradient or slope of the function at P , given by tan θ, is approximately equal to ∆f/∆x.

Figure 2.1 shows an example of such a function. Near any particular point, P , the value of the function changes by an amount ∆f, say, as x changes by a small amount ∆x. The slope of the tangent to the graph of f(x) at P is then approximately ∆f/∆x, and the change in the value of the function is ∆f = f(x + ∆x) − f(x). In order to calculate the true value of the gradient, or ﬁrst derivative, of the function at P , we must let ∆x become inﬁnitesimally small. We therefore deﬁne the ﬁrst derivative of f(x) as

f (x) ≡

df(x)

≡

lim

f(x + ∆x) − f(x) ,

(2.1)

dx

∆x→0

∆x

provided that the limit exists. The limit will depend in almost all cases on the value of x. If the limit does exist at a point x = a then the function is said to be diﬀerentiable at a; otherwise it is said to be non-diﬀerentiable at a. The formal concept of a limit and its existence or non-existence is discussed in chapter 4; for present purposes we will adopt an intuitive approach.
In the deﬁnition (2.1), we allow ∆x to tend to zero from either positive or negative values and require the same limit to be obtained in both cases. A function that is diﬀerentiable at a is necessarily continuous at a (there must be no jump in the value of the function at a), though the converse is not necessarily true. This latter assertion is illustrated in ﬁgure 2.1: the function is continuous at the ‘kink’ A but the two limits of the gradient as ∆x tends to zero from positive or negative values are diﬀerent and so the function is not diﬀerentiable at A.
It should be clear from the above discussion that near the point P we may

42

2.1 DIFFERENTIATION

approximate the change in the value of the function, ∆f, that results from a small change ∆x in x by

∆f ≈ df(x) ∆x.

(2.2)

dx

As one would expect, the approximation improves as the value of ∆x is reduced. In the limit in which the change ∆x becomes inﬁnitesimally small, we denote it by the diﬀerential dx, and (2.2) reads

df = df(x) dx.

(2.3)

dx

This equality relates the inﬁnitesimal change in the function, df, to the inﬁnitesimal change dx that causes it.
So far we have discussed only the ﬁrst derivative of a function. However, we can also deﬁne the second derivative as the gradient of the gradient of a function. Again we use the deﬁnition (2.1) but now with f(x) replaced by f (x). Hence the second derivative is deﬁned by

f

(x) ≡

lim

f (x + ∆x) − f (x) ,

(2.4)

∆x→0

∆x

provided that the limit exists. A physical example of a second derivative is the second derivative of the distance travelled by a particle with respect to time. Since the ﬁrst derivative of distance travelled gives the particle’s velocity, the second derivative gives its acceleration.
We can continue in this manner, the nth derivative of the function f(x) being deﬁned by

f(n)(x) ≡

lim

f(n−1)(x + ∆x) − f(n−1)(x) .

∆x→0

∆x

(2.5)

It should be noted that with this notation f (x) ≡ f(1)(x), f (x) ≡ f(2)(x), etc., and that formally f(0)(x) ≡ f(x).
All this should be familiar to the reader, though perhaps not with such formal deﬁnitions. The following example shows the diﬀerentiation of f(x) = x2 from ﬁrst principles. In practice, however, it is desirable simply to remember the derivatives of standard functions; the techniques given in the remainder of this section can be applied to ﬁnd more complicated derivatives.
43

PRELIMINARY CALCULUS

Find from ﬁrst principles the derivative with respect to x of f(x) = x2.

Using the deﬁnition (2.1),

f(x + ∆x) − f(x)

f (x) = lim

∆x→0

∆x

(x + ∆x)2 − x2

= lim

∆x→0

∆x

2x∆x + (∆x)2

= lim

∆x→0

∆x

= lim (2x + ∆x). ∆x→0

As ∆x tends to zero, 2x + ∆x tends towards 2x, hence

f (x) = 2x.

Derivatives of other functions can be obtained in the same way. The derivatives of some simple functions are listed below (note that a is a constant):

d (xn) = nxn−1, dx

d (eax) = aeax, dx

d

(ln ax) =

1 ,

dx

x

d dx (sin ax) = a cos ax,

d dx

(cos

ax)

=

−a

sin

ax,

d dx (sec ax) = a sec ax tan ax,

d (tan ax) = a sec2 ax, dx

d (cosec ax) = −a cosec ax cot ax, dx

d (cot ax) = −a cosec2 ax, dx

d sin−1 x = √ 1 ,

dx

a

a2 − x2

d cos−1 x = √ −1 ,

dx

a

a2 − x2

d dx

tan−1 x a

a = a2 + x2 .

Diﬀerentiation from ﬁrst principles emphasises the deﬁnition of a derivative as the gradient of a function. However, for most practical purposes, returning to the deﬁnition (2.1) is time consuming and does not aid our understanding. Instead, as mentioned above, we employ a number of techniques, which use the derivatives listed above as ‘building blocks’, to evaluate the derivatives of more complicated functions than hitherto encountered. Subsections 2.1.2–2.1.7 develop the methods required.

2.1.2 Differentiation of products
As a ﬁrst example of the diﬀerentiation of a more complicated function, we consider ﬁnding the derivative of a function f(x) that can be written as the product of two other functions of x, namely f(x) = u(x)v(x). For example, if f(x) = x3 sin x then we might take u(x) = x3 and v(x) = sin x. Clearly the
44

2.1 DIFFERENTIATION

separation is not unique. (In the given example, possible alternative break-ups would be u(x) = x2, v(x) = x sin x, or even u(x) = x4 tan x, v(x) = x−1 cos x.)
The purpose of the separation is to split the function into two (or more) parts, of which we know the derivatives (or at least we can evaluate these derivatives more easily than that of the whole). We would gain little, however, if we did not know the relationship between the derivative of f and those of u and v. Fortunately, they are very simply related, as we shall now show.
Since f(x) is written as the product u(x)v(x), it follows that

f(x + ∆x) − f(x) = u(x + ∆x)v(x + ∆x) − u(x)v(x) = u(x + ∆x)[v(x + ∆x) − v(x)] + [u(x + ∆x) − u(x)]v(x).

From the deﬁnition of a derivative (2.1),

df

f(x + ∆x) − f(x)

= lim

dx ∆x→0

∆x

v(x + ∆x) − v(x) u(x + ∆x) − u(x)

= lim u(x + ∆x)

+

v(x) .

∆x→0

∆x

∆x

In the limit ∆x → 0, the factors in square brackets become dv/dx and du/dx (by the deﬁnitions of these quantities) and u(x + ∆x) simply becomes u(x). Consequently we obtain

df = d [u(x)v(x)] = u(x) dv(x) + du(x) v(x).

(2.6)

dx dx

dx

dx

In primed notation and without writing the argument x explicitly, (2.6) is stated

concisely as

f = (uv) = uv + u v.

(2.7)

This is a general result obtained without making any assumptions about the speciﬁc forms f, u and v, other than that f(x) = u(x)v(x). In words, the result reads as follows. The derivative of the product of two functions is equal to the ﬁrst function times the derivative of the second plus the second function times the derivative of the ﬁrst.

Find the derivative with respect to x of f(x) = x3 sin x.

Using the product rule, (2.6),

d (x3 sin x) = x3

d (sin x) +

d (x3) sin x

dx

dx

dx

= x3 cos x + 3x2 sin x.

The product rule may readily be extended to the product of three or more functions. Considering the function

f(x) = u(x)v(x)w(x)

(2.8)

45

PRELIMINARY CALCULUS

and using (2.6), we obtain, as before omitting the argument,

df d

du

dx = u dx (vw) + dx vw.

Using (2.6) again to expand the ﬁrst term on the RHS gives the complete result

d (uvw) = uv dw + u dv w + du vw

(2.9)

dx

dx dx dx

or

(uvw) = uvw + uv w + u vw.

(2.10)

It is readily apparent that this can be extended to products containing any number n of factors; the expression for the derivative will then consist of n terms with the prime appearing in successive terms on each of the n factors in turn. This is probably the easiest way to recall the product rule.

2.1.3 The chain rule

Products are just one type of complicated function that we may encounter in diﬀerentiation. Another is the function of a function, e.g. f(x) = (3 + x2)3 = u(x)3, where u(x) = 3 + x2. If ∆f, ∆u and ∆x are small ﬁnite quantities, it follows that

∆f ∆f ∆u

=

;

∆x ∆u ∆x

As the quantities become inﬁnitesimally small we obtain

df df du

=

.

dx du dx

(2.11)

This is the chain rule, which we must apply when diﬀerentiating a function of a function.

Find the derivative with respect to x of f(x) = (3 + x2)3.

Rewriting the function as f(x) = u3, where u(x) = 3 + x2, and applying (2.11) we ﬁnd

df = 3u2 du = 3u2 d (3 + x2) = 3u2 × 2x = 6x(3 + x2)2.

dx

dx

dx

Similarly, the derivative with respect to x of f(x) = 1/v(x) may be obtained by rewriting the function as f(x) = v−1 and applying (2.11):

df dx

=

−v−2 dv dx

=

−

1 v2

dv . dx

(2.12)

The chain rule is also useful for calculating the derivative of a function f with respect to x when both x and f are written in terms of a variable (or parameter), say t.

46

2.1 DIFFERENTIATION

Find the derivative with respect to x of f(t) = 2at, where x = at2.

We could of course substitute for t and then diﬀerentiate f as a function of x, but in this case it is quicker to use

df = df dt = 2a 1

1 =,

dx dt dx

2at t

where we have used the fact that

dt

dx −1

=

.

dx dt

2.1.4 Differentiation of quotients

Applying (2.6) for the derivative of a product to a function f(x) = u(x)[1/v(x)], we may obtain the derivative of the quotient of two factors. Thus

f= u v

1 =u
v

+u

1 v

=u

−

v v2

+u, v

where (2.12) has been used to evaluate (1/v) . This can now be rearranged into the more convenient and memorisable form

u vu − uv

f=

=

v

v2 .

(2.13)

This can be expressed in words as the derivative of a quotient is equal to the bottom times the derivative of the top minus the top times the derivative of the bottom, all over the bottom squared.

Find the derivative with respect to x of f(x) = sin x/x.

Using (2.13) with u(x) = sin x, v(x) = x and hence u (x) = cos x, v (x) = 1, we ﬁnd

f

(x)

=

x cos x − sin x x2

=

cos x x

−

sin x x2 .

2.1.5 Implicit differentiation
So far we have only diﬀerentiated functions written in the form y = f(x). However, we may not always be presented with a relationship in this simple form. As an example consider the relation x3 − 3xy + y3 = 2. In this case it is not possible to rearrange the equation to give y as a function of x. Nevertheless, by diﬀerentiating term by term with respect to x (implicit diﬀerentiation), we can ﬁnd the derivative of y.
47

PRELIMINARY CALCULUS

Find dy/dx if x3 − 3xy + y3 = 2.

Diﬀerentiating each term in the equation with respect to x we obtain

d (x3) −

d (3xy) +

d (y3) =

d (2),

dx

dx

dx

dx

⇒ 3x2 − 3x dy + 3y + 3y2 dy = 0,

dx

dx

where the derivative of 3xy has been found using the product rule. Hence, rearranging for dy/dx,
dy y − x2 dx = y2 − x .

Note that dy/dx is a function of both x and y and cannot be expressed as a function of x only.

2.1.6 Logarithmic differentiation
In circumstances in which the variable with respect to which we are diﬀerentiating is an exponent, taking logarithms and then diﬀerentiating implicitly is the simplest way to ﬁnd the derivative.
Find the derivative with respect to x of y = ax.
To ﬁnd the required derivative we ﬁrst take logarithms and then diﬀerentiate implicitly: ln y = ln ax = x ln a ⇒ 1 dy = ln a. y dx
Now, rearranging and substituting for y, we ﬁnd dy = y ln a = ax ln a. dx

2.1.7 Leibnitz’ theorem
We have discussed already how to ﬁnd the derivative of a product of two or more functions. We now consider Leibnitz’ theorem, which gives the corresponding results for the higher derivatives of products.
Consider again the function f(x) = u(x)v(x). We know from the product rule that f = uv + u v. Using the rule once more for each of the products, we obtain
f = (uv + u v ) + (u v + u v) = uv + 2u v + u v.
Similarly, diﬀerentiating twice more gives
f = uv + 3u v + 3u v + u v, f(4) = uv(4) + 4u v + 6u v + 4u v + u(4)v.
48

2.1 DIFFERENTIATION

The pattern emerging is clear and strongly suggests that the results generalise to

f(n) =

n

n! r!(n −

u(r)v(n−r) r)!

=

n

n Cr u(r) v(n−r) ,

r=0

r=0

(2.14)

where the fraction n!/[r!(n − r)!] is identiﬁed with the binomial coeﬃcient nCr (see chapter 1). To prove that this is so, we use the method of induction as follows.
Assume that (2.14) is valid for n equal to some integer N. Then

f(N+1) =

N

N

Cr

d dx

u(r)v(N−r)

r=0

N

=

N Cr[u(r)v(N−r+1) + u(r+1)v(N−r)]

r=0

N

N+1

=

N Csu(s)v(N+1−s) +

N Cs−1u(s)v(N+1−s),

s=0

s=1

where we have substituted summation index s for r in the ﬁrst summation, and for r + 1 in the second. Now, from our earlier discussion of binomial coeﬃcients, equation (1.51), we have

N Cs + N Cs−1 = N+1Cs

and so, after separating out the ﬁrst term of the ﬁrst summation and the last term of the second, obtain

N

f(N+1) = N C0u(0)v(N+1) +

N+1Csu(s)v(N+1−s) + N CN u(N+1)v(0).

s=1

But N C0 = 1 = N+1C0 and N CN = 1 = N+1CN+1, and so we may write

N

f(N+1) = N+1C0u(0)v(N+1) +

N+1Csu(s)v(N+1−s) + N+1CN+1u(N+1)v(0)

s=1

N+1

=

N+1Csu(s)v(N+1−s).

s=0

This is just (2.14) with n set equal to N + 1. Thus, assuming the validity of (2.14) for n = N implies its validity for n = N + 1. However, when n = 1 equation (2.14) is simply the product rule, and this we have already proved directly. These results taken together establish the validity of (2.14) for all n and prove Leibnitz’ theorem.

49

PRELIMINARY CALCULUS
f(x) Q

A

C

S

B

x
Figure 2.2 A graph of a function, f(x), showing how diﬀerentiation corresponds to ﬁnding the gradient of the function at a particular point. Points B, Q and S are stationary points (see text).
Find the third derivative of the function f(x) = x3 sin x.
Using (2.14) we immediately ﬁnd f (x) = 6 sin x + 3(6x) cos x + 3(3x2)(− sin x) + x3(− cos x) = 3(2 − 3x2) sin x + x(18 − x2) cos x.
2.1.8 Special points of a function
We have interpreted the derivative of a function as the gradient of the function at the relevant point (ﬁgure 2.1). If the gradient is zero for some particular value of x then the function is said to have a stationary point there. Clearly, in graphical terms, this corresponds to a horizontal tangent to the graph.
Stationary points may be divided into three categories and an example of each is shown in ﬁgure 2.2. Point B is said to be a minimum since the function increases in value in both directions away from it. Point Q is said to be a maximum since the function decreases in both directions away from it. Note that B is not the overall minimum value of the function and Q is not the overall maximum; rather, they are a local minimum and a local maximum. Maxima and minima are known collectively as turning points.
The third type of stationary point is the stationary point of inﬂection, S. In this case the function falls in the positive x-direction and rises in the negative x-direction so that S is neither a maximum nor a minimum. Nevertheless, the gradient of the function is zero at S, i.e. the graph of the function is ﬂat there, and this justiﬁes our calling it a stationary point. Of course, a point at which the
50

2.1 DIFFERENTIATION

gradient of the function is zero but the function rises in the positive x-direction and falls in the negative x-direction is also a stationary point of inﬂection.
The above distinction between the three types of stationary point has been made rather descriptively. However, it is possible to deﬁne and distinguish stationary points mathematically. From their deﬁnition as points of zero gradient, all stationary points must be characterised by df/dx = 0. In the case of the minimum, B, the slope, i.e. df/dx, changes from negative at A to positive at C through zero at B. Thus df/dx is increasing and so the second derivative d2f/dx2 must be positive. Conversely, at the maximum, Q, we must have that d2f/dx2 is negative.
It is less obvious, but intuitively reasonable, that at S, d2f/dx2 is zero. This may be inferred from the following observations. To the left of S the curve is concave upwards so that df/dx is increasing with x and hence d2f/dx2 > 0. To the right of S, however, the curve is concave downwards so that df/dx is decreasing with x and hence d2f/dx2 < 0.
In summary, at a stationary point df/dx = 0 and
(i) for a minimum, d2f/dx2 > 0,
(ii) for a maximum, d2f/dx2 < 0,
(iii) for a stationary point of inﬂection, d2f/dx2 = 0 and d2f/dx2 changes sign through the point.
In case (iii), a stationary point of inﬂection, in order that d2f/dx2 changes sign through the point we normally require d3f/dx3 = 0 at that point. This simple rule can fail for some functions, however, and in general if the ﬁrst non-vanishing derivative of f(x) at the stationary point is f(n) then if n is even the point is a maximum or minimum and if n is odd the point is a stationary point of inﬂection. This may be seen from the Taylor expansion (see equation (4.17)) of the function about the stationary point, but it is not proved here.
Find the positions and natures of the stationary points of the function f(x) = 2x3 − 3x2 − 36x + 2.

The ﬁrst criterion for a stationary point is that df/dx = 0, and hence we set

from which we obtain

df = 6x2 − 6x − 36 = 0, dx
(x − 3)(x + 2) = 0.

Hence the stationary points are at x = 3 and x = −2. To determine the nature of the stationary point we must evaluate d2f/dx2:

d2f dx2

=

12x − 6.

51

PRELIMINARY CALCULUS
f(x)
G
x
Figure 2.3 The graph of a function f(x) that has a general point of inﬂection at the point G.
Now, we examine each stationary point in turn. For x = 3, d2f/dx2 = 30. Since this is positive, we conclude that x = 3 is a minimum. Similarly, for x = −2, d2f/dx2 = −30 and so x = −2 is a maximum.
So far we have concentrated on stationary points, which are deﬁned to have df/dx = 0. We have found that at a stationary point of inﬂection d2f/dx2 is also zero and changes sign. This naturally leads us to consider points at which d2f/dx2 is zero and changes sign but at which df/dx is not, in general, zero. Such points are called general points of inﬂection or simply points of inﬂection. Clearly, a stationary point of inﬂection is a special case for which df/dx is also zero. At a general point of inﬂection the graph of the function changes from being concave upwards to concave downwards (or vice versa), but the tangent to the curve at this point need not be horizontal. A typical example of a general point of inﬂection is shown in ﬁgure 2.3.
The determination of the stationary points of a function, together with the identiﬁcation of its zeros, inﬁnities and possible asymptotes, is usually suﬃcient to enable a graph of the function showing most of its signiﬁcant features to be sketched. Some examples for the reader to try are included in the exercises at the end of this chapter.
2.1.9 Curvature of a function In the previous section we saw that at a point of inﬂection of the function f(x), the second derivative d2f/dx2 changes sign and passes through zero. The corresponding graph of f shows an inversion of its curvature at the point of inﬂection. We now develop a more quantitative measure of the curvature of a function (or its graph), which is applicable at general points and not just in the neighbourhood of a point of inﬂection.
As in ﬁgure 2.1, let θ be the angle made with the x-axis by the tangent at a
52

2.1 DIFFERENTIATION
f(x) C
∆θ ρ
Q P

θ

θ + ∆θ

x

Figure 2.4 Two neighbouring tangents to the curve f(x) whose slopes diﬀer by ∆θ. The angular separation of the corresponding radii of the circle of curvature is also ∆θ.

point P on the curve f = f(x), with tan θ = df/dx evaluated at P . Now consider also the tangent at a neighbouring point Q on the curve, and suppose that it makes an angle θ + ∆θ with the x-axis, as illustrated in ﬁgure 2.4.
It follows that the corresponding normals at P and Q, which are perpendicular to the respective tangents, also intersect at an angle ∆θ. Furthermore, their point of intersection, C in the ﬁgure, will be the position of the centre of a circle that approximates the arc P Q, at least to the extent of having the same tangents at the extremities of the arc. This circle is called the circle of curvature.
For a ﬁnite arc P Q, the lengths of CP and CQ will not, in general, be equal, as they would be if f = f(x) were in fact the equation of a circle. But, as Q is allowed to tend to P , i.e. as ∆θ → 0, they do become equal, their common value being ρ, the radius of the circle, known as the radius of curvature. It follows immediately that the curve and the circle of curvature have a common tangent at P and lie on the same side of it. The reciprocal of the radius of curvature, ρ−1, deﬁnes the curvature of the function f(x) at the point P .
The radius of curvature can be deﬁned more mathematically as follows. The length ∆s of arc P Q is approximately equal to ρ∆θ and, in the limit ∆θ → 0, this relationship deﬁnes ρ as

∆s ds ρ = lim = .
∆θ→0 ∆θ dθ

(2.15)

It should be noted that, as s increases, θ may increase or decrease according to whether the curve is locally concave upwards (i.e. shaped as if it were near a minimum in f(x)) or concave downwards. This is reﬂected in the sign of ρ, which therefore also indicates the position of the curve (and of the circle of curvature)

53

PRELIMINARY CALCULUS

relative to the common tangent, above or below. Thus a negative value of ρ indicates that the curve is locally concave downwards and that the tangent lies above the curve.
We next obtain an expression for ρ, not in terms of s and θ but in terms of x and f(x). The expression, though somewhat cumbersome, follows from the deﬁning equation (2.15), the deﬁning property of θ that tan θ = df/dx ≡ f and the fact that the rate of change of arc length with x is given by

ds

df 2 1/2

= 1+

.

dx

dx

(2.16)

This last result, simply quoted here, is proved more formally in subsection 2.2.13. From the chain rule (2.11) it follows that

ds ds dx

ρ= =

.

dθ dx dθ

Diﬀerentiating both sides of tan θ = df/dx with respect to x gives

(2.17)

sec2 θ dθ dx

=

d2f dx2

≡f

,

from which, using sec2 θ = 1 + tan2 θ = 1 + (f )2, we can obtain dx/dθ as

dx 1 + tan2 θ 1 + (f )2

=

=

.

dθ

f

f

(2.18)

Substituting (2.16) and (2.18) into (2.17) then yields the ﬁnal expression for ρ,

1 + (f )2 3/2

ρ=

.

f

(2.19)

It should be noted that the quantity in brackets is always positive and that its three-halves root is also taken as positive. The sign of ρ is thus solely determined by that of d2f/dx2, in line with our previous discussion relating the sign to whether the curve is concave or convex upwards. If, as happens at a point of inﬂection, d2f/dx2 is zero then ρ is formally inﬁnite and the curvature of f(x) is zero. As d2f/dx2 changes sign on passing through zero, both the local tangent and the circle of curvature change from their initial positions to the opposite side of the curve.
54

2.1 DIFFERENTIATION

Show that the radius of curvature at the point (x, y) on the ellipse
x2 y2 + =1
a2 b2 has magnitude (a4y2 + b4x2)3/2/(a4b4) and the opposite sign to y. Check the special case b = a, for which the ellipse becomes a circle.

Diﬀerentiating the equation of the ellipse with respect to x gives

and so

2x 2y dy a2 + b2 dx = 0

dy dx

=

−

b2 a2

x y

.

A second diﬀerentiation, using (2.13), then yields

d2y dx2

=

−

b2 a2

y − xy y2

=

−

b4 a2y3

y2 x2 b2 + a2

=

−

b4 a2y3

,

where we have used the fact that (x, y) lies on the ellipse. We note that d2y/dx2, and hence ρ, has the opposite sign to y3 and hence to y. Substituting in (2.19) gives for the magnitude
of the radius of curvature

|ρ| =

1 + b4x2/(a4y2) 3/2

(a4y2 + b4x2)3/2

−b4/(a2y3)

=

a4b4

.

For the special case b = a, |ρ| reduces to a−2(y2 + x2)3/2 and, since x2 + y2 = a2, this in turn gives |ρ| = a, as expected.

The discussion in this section has been conﬁned to the behaviour of curves that lie in one plane; examples of the application of curvature to the bending of loaded beams and to particle orbits under the inﬂuence of a central forces can be found in the exercises at the ends of later chapters. A more general treatment of curvature in three dimensions is given in section 10.3, where a vector approach is adopted.

2.1.10 Theorems of differentiation
Rolle’s theorem Rolle’s theorem (ﬁgure 2.5) states that if a function f(x) is continuous in the range a ≤ x ≤ c, is diﬀerentiable in the range a < x < c and satisﬁes f(a) = f(c) then for at least one point x = b, where a < b < c, f (b) = 0. Thus Rolle’s theorem states that for a well-behaved (continuous and diﬀerentiable) function that has the same value at two points either there is at least one stationary point between those points or the function is a constant between them. The validity of the theorem is immediately apparent from ﬁgure 2.5 and a full analytic proof will not be given. The theorem is used in deriving the mean value theorem, which we now discuss.
55

PRELIMINARY CALCULUS f(x)

ab

c

x

Figure 2.5 The graph of a function f(x), showing that if f(a) = f(c) then at one point at least between x = a and x = c the graph has zero gradient.

f(x)

f(c)

C

f(a)

A

ab

c

x

Figure 2.6 The graph of a function f(x); at some point x = b it has the same gradient as the line AC.

Mean value theorem
The mean value theorem (ﬁgure 2.6) states that if a function f(x) is continuous in the range a ≤ x ≤ c and diﬀerentiable in the range a < x < c then

f(c) − f(a) f (b) = c − a ,

(2.20)

for at least one value b where a < b < c. Thus the mean value theorem states that for a well-behaved function the gradient of the line joining two points on the curve is equal to the slope of the tangent to the curve for at least one intervening point.
The proof of the mean value theorem is found by examination of ﬁgure 2.6, as follows. The equation of the line AC is

g(x)

=

f(a)

+

(x

−

a)

f(c) c

− −

f(a) a

,

56

2.1 DIFFERENTIATION

and hence the diﬀerence between the curve and the line is

h(x)

=

f(x)

−

g(x)

=

f(x)

−

f(a)

−

(x

−

a)

f(c) c

− −

f(a) a

.

Since the curve and the line intersect at A and C, h(x) = 0 at both of these points. Hence, by an application of Rolle’s theorem, h (x) = 0 for at least one point b between A and C. Diﬀerentiating our expression for h(x), we ﬁnd

h

(x)

=

f

(x)

−

f(c) c

− −

f(a) , a

and hence at b, where h (x) = 0,

f(c) − f(a) f (b) = c − a .

Applications of Rolle’s theorem and the mean value theorem
Since the validity of Rolle’s theorem is intuitively obvious, given the conditions imposed on f(x), it will not be surprising that the problems that can be solved by applications of the theorem alone are relatively simple ones. Nevertheless we will illustrate it with the following example.
What semi-quantitative results can be deduced by applying Rolle’s theorem to the following functions f(x), with a and c chosen so that f(a) = f(c) = 0? (i) sin x, (ii) cos x, (iii)x2 − 3x + 2, (iv) x2 + 7x + 3, (v) 2x3 − 9x2 − 24x + k.
(i) If the consecutive values of x that make sin x = 0 are α1, α2, . . . (actually x = nπ, for any integer n) then Rolle’s theorem implies that the derivative of sin x, namely cos x, has at least one zero lying between each pair of values αi and αi+1.
(ii) In an exactly similar way, we conclude that the derivative of cos x, namely − sin x, has at least one zero lying between consecutive pairs of zeros of cos x. These two results taken together (but neither separately) imply that sin x and cos x have interleaving zeros.
(iii) For f(x) = x2 − 3x + 2, f(a) = f(c) = 0 if a and c are taken as 1 and 2 respectively. Rolle’s theorem then implies that f (x) = 2x − 3 = 0 has a solution x = b with b in the range 1 < b < 2. This is obviously so, since b = 3/2.
(iv) With f(x) = x2 + 7x + 3, the theorem tells us that if there are two roots of x2 + 7x + 3 = 0 then they have the root of f (x) = 2x + 7 = 0 lying between them. Thus if there are any (real) roots of√x2 + 7x + 3 = 0 then they lie one on either side of x = −7/2. The actual roots are (−7 ± 37)/2.
(v) If f(x) = 2x3 − 9x2 − 24x + k then f (x) = 0 is the equation 6x2 − 18x − 24 = 0, which has solutions x = −1 and x = 4. Consequently, if α1 and α2 are two diﬀerent roots of f(x) = 0 then at least one of −1 and 4 must lie in the open interval α1 to α2. If, as is the case for a certain range of values of k, f(x) = 0 has three roots, α1, α2 and α3, then α1 < −1 < α2 < 4 < α3 .
57

PRELIMINARY CALCULUS

In each case, as might be expected, the application of Rolle’s theorem does no more than focus attention on particular ranges of values; it does not yield precise answers.
Direct veriﬁcation of the mean value theorem is straightforward when it is applied to simple functions. For example, if f(x) = x2, it states that there is a value b in the interval a < b < c such that
c2 − a2 = f(c) − f(a) = (c − a)f (b) = (c − a)2b.
This is clearly so, since b = (a + c)/2 satisﬁes the relevant criteria. As a slightly more complicated example we may consider a cubic equation, say
f(x) = x3 + 2x2 + 4x − 6 = 0, between two speciﬁed values of x, say 1 and 2. In this case we need to verify that there is a value of x lying in the range 1 < x < 2 that satisﬁes
18 − 1 = f(2) − f(1) = (2 − 1)f (x) = 1(3x2 + 4x + 4).
This is easily done, either by evaluating 3x2 +4x+4−17 at x = 1 and at x = 2 and checking that the values have opposite signs or by solving 3x2 + 4x + 4 − 17 = 0 and showing that one of the roots lies in the stated interval.
The following applications of the mean value theorem establish some general inequalities for two common functions.

Determine inequalities satisﬁed by ln x and sin x for suitable ranges of the real variable x.

Since for positive values of its argument the derivative of ln x is x−1, the mean value theorem gives us

ln c − ln a 1

c−a

= b

for some b in 0 < a < b < c. Further, since a < b < c implies that c−1 < b−1 < a−1, we have

1 ln c − ln a 1

< c

c−a

<, a

or, multiplying through by c − a and writing c/a = x where x > 1,

1

−

1 x

<

ln x

<

x − 1.

Applying the mean value theorem to sin x shows that

sin c − sin a c − a = cos b
for some b lying between a and c. If a and c are restricted to lie in the range 0 ≤ a < c ≤ π, in which the cosine function is monotonically decreasing (i.e. there are no turning points), we can deduce that
sin c − sin a cos c < c − a < cos a.

58

2.2 INTEGRATION f(x)

a

b

x

Figure 2.7 An integral as the area under a curve.

2.2 Integration

The notion of an integral as the area under a curve will be familiar to the reader. In ﬁgure 2.7, in which the solid line is a plot of a function f(x), the shaded area represents the quantity denoted by

b
I = f(x) dx.
a

(2.21)

This expression is known as the deﬁnite integral of f(x) between the lower limit x = a and the upper limit x = b, and f(x) is called the integrand.

2.2.1 Integration from ﬁrst principles

The deﬁnition of an integral as the area under a curve is not a formal deﬁnition,
but one that can be readily visualised. The formal deﬁnition of I involves subdividing the ﬁnite interval a ≤ x ≤ b into a large number of subintervals, by deﬁning intermediate points ξi such that a = ξ0 < ξ1 < ξ2 < · · · < ξn = b, and then forming the sum

n
S = f(xi)(ξi − ξi−1),
i=1

(2.22)

where xi is an arbitrary point that lies in the range ξi−1 ≤ xi ≤ ξi (see ﬁgure 2.8). If now n is allowed to tend to inﬁnity in any way whatsoever, subject only to the restriction that the length of every subinterval ξi−1 to ξi tends to zero, then S might, or might not, tend to a unique limit, I. If it does then the deﬁnite integral of f(x) between a and b is deﬁned as having the value I. If no unique limit exists the integral is undeﬁned. For continuous functions and a ﬁnite interval a ≤ x ≤ b the existence of a unique limit is assured and the integral is guaranteed to exist.

59

PRELIMINARY CALCULUS f(x)

a x1 ξ1 x2 ξ2 x3 ξ3

x4 ξ4 x5 b

x

Figure 2.8 The evaluation of a deﬁnite integral by subdividing the interval a ≤ x ≤ b into subintervals.

Evaluate from ﬁrst principles the integral I =

b 0

x2

dx.

We ﬁrst approximate the area under the curve y = x2 between 0 and b by n rectangles of equal width h. If we take the value at the lower end of each subinterval (in the limit of an inﬁnite number of subintervals we could equally well have chosen the value at the upper
end) to give the height of the corresponding rectangle, then the area of the kth rectangle will be (kh)2h = k2h3. The total area is thus

n−1

A=

k2h3

=

(h3)

1 6

n(n

−

1)(2n

−

1),

k=0

where we have used the expression for the sum of the squares of the natural numbers derived in subsection 1.7.1. Now h = b/n and so

A=

b3 n3

n (n − 1)(2n − 1) = b3

6

6

1− 1 n

2− 1 . n

As n → ∞, A → b3/3, which is thus the value I of the integral.

Some straightforward properties of deﬁnite integrals that are almost self-evident

are as follows:

b
0 dx = 0,
a

a
f(x) dx = 0,
a

(2.23)

c

b

c

f(x) dx = f(x) dx + f(x) dx,

a

a

b

(2.24)

b

b

b

[ f(x) + g(x)] dx = f(x) dx + g(x) dx.

a

a

a

(2.25)

60

2.2 INTEGRATION

Combining (2.23) and (2.24) with c set equal to a shows that

b

a

f(x) dx = − f(x) dx.

a

b

(2.26)

2.2.2 Integration as the inverse of differentiation

The deﬁnite integral has been deﬁned as the area under a curve between two ﬁxed limits. Let us now consider the integral

x
F(x) = f(u) du
a

(2.27)

in which the lower limit a remains ﬁxed but the upper limit x is now variable. It

will be noticed that this is essentially a restatement of (2.21), but that the variable

x in the integrand has been replaced by a new variable u. It is conventional to rename the dummy variable in the integrand in this way in order that the same

variable does not appear in both the integrand and the integration limits.

It is apparent from (2.27) that F(x) is a continuous function of x, but at ﬁrst

glance the deﬁnition of an integral as the area under a curve does not connect with

our assertion that integration is the inverse process to diﬀerentiation. However,

by considering the integral (2.27) and using the elementary property (2.24), we

obtain

x+∆x

F(x + ∆x) =

f(u) du

a

x

x+∆x

= f(u) du +

f(u) du

a

x

x+∆x

= F(x) +

f(u) du.

x

Rearranging and dividing through by ∆x yields

F(x + ∆x) − F(x) 1 x+∆x

=

f(u) du.

∆x

∆x x

Letting ∆x → 0 and using (2.1) we ﬁnd that the LHS becomes dF/dx, whereas

the RHS becomes f(x). The latter conclusion follows because when ∆x is small

the value of the integral on the RHS is approximately f(x)∆x, and in the limit ∆x → 0 no approximation is involved. Thus

dF(x) = f(x), dx
or, substituting for F(x) from (2.27),

(2.28)

d

x

f(u) du = f(x).

dx a

61

PRELIMINARY CALCULUS

From the last two equations it is clear that integration can be considered as

the inverse of diﬀerentiation. However, we see from the above analysis that the

lower limit a is arbitrary and so diﬀerentiation does not have a unique inverse. Any function F(x) obeying (2.28) is called an indeﬁnite integral of f(x), though any two such functions can diﬀer by at most an arbitrary additive constant. Since

the lower limit is arbitrary, it is usual to write

x
F(x) = f(u) du

(2.29)

and explicitly include the arbitrary constant only when evaluating F(x). The evaluation is conventionally written in the form

f(x) dx = F(x) + c

(2.30)

where c is called the constant of integration. It will be noticed that, in the absence of any integration limits, we use the same symbol for the arguments of both f and F. This can be confusing, but is suﬃciently common practice that the reader needs to become familiar with it.
We also note that the deﬁnite integral of f(x) between the ﬁxed limits x = a and x = b can be written in terms of F(x). From (2.27) we have

b

b

a

f(x) dx = f(x) dx − f(x) dx

a

x0

x0

= F(b) − F(a),

(2.31)

where x0 is any third ﬁxed point. Using the notation F (x) = dF/dx, we may rewrite (2.28) as F (x) = f(x), and so express (2.31) as
b
F (x) dx = F(b) − F(a) ≡ [F]ba.
a
In contrast to diﬀerentiation, where repeated applications of the product rule and/or the chain rule will always give the required derivative, it is not always possible to ﬁnd the integral of an arbitrary function. Indeed, in most real physical problems exact integration cannot be performed and we have to revert to numerical approximations. Despite this cautionary note, it is in fact possible to integrate many simple functions and the following subsections introduce the most common types. Many of the techniques will be familiar to the reader and so are summarised by example.

2.2.3 Integration by inspection The simplest method of integrating a function is by inspection. Some of the more elementary functions have well-known integrals that should be remembered. The reader will notice that these integrals are precisely the inverses of the derivatives
62

2.2 INTEGRATION

found near the end of subsection 2.1.1. A few are presented below, using the form given in (2.30):

a dx = ax + c,

axn dx = axn+1 + c, n+1

eax dx = eax + c, a

a dx = a ln x + c,
x

a cos bx dx = a sin bx + c, b

a sin bx dx = −a cos bx + c, b

−a ln(cos bx)

a tan bx dx =

b

+ c,

a cos bx sinn bx dx = a sinn+1 bx + c, b(n + 1)

a2

a +

x2

dx

=

tan−1

x a

+ c,

a sin bx cosn bx dx = −a cosn+1 bx + c, b(n + 1)

√ −1 dx = cos−1 x + c,

a2 − x2

a

√ 1 dx = sin−1 x + c,

a2 − x2

a

where the integrals that depend on n are valid for all n = −1 and where a and b are constants. In the two ﬁnal results |x| ≤ a.

2.2.4 Integration of sinusoidal functions
Integrals of the type sinn x dx and cosn x dx may be found by using trigonometric expansions. Two methods are applicable, one for odd n and the other for even n. They are best illustrated by example.

Evaluate the integral I = sin5 x dx. Rewriting the integral as a product of sin x and an even power of sin x, and then using the relation sin2 x = 1 − cos2 x yields
I = sin4 x sin x dx

= (1 − cos2 x)2 sin x dx

= (1 − 2 cos2 x + cos4 x) sin x dx

= (sin x − 2 sin x cos2 x + sin x cos4 x) dx

=

− cos x

+

2 3

cos3

x

−

1 5

cos5

x

+

c,

where the integration has been carried out using the results of subsection 2.2.3.

63

PRELIMINARY CALCULUS

Evaluate the integral I = cos4 x dx.

Rewriting the integral as a power of cos2 x and then using the double-angle formula

cos2 x

=

1 2

(1

+

cos

2x)

yields

I = (cos2 x)2 dx =

1 + cos 2x 2 dx
2

=

1 4

(1

+

2

cos

2x

+

cos2

2x)

dx.

Using

the

double-angle

formula

again

we

may

write

cos2 2x

=

1 2

(1

+

cos 4x),

and

hence

I=

1 4

+

1 2

cos 2x

+

1 8

(1

+

cos 4x)

dx

=

1 4

x

+

1 4

sin 2x

+

1 8

x

+

1 32

sin 4x

+

c

=

3 8

x

+

1 4

sin 2x

+

1 32

sin 4x + c.

2.2.5 Logarithmic integration

Integrals for which the integrand may be written as a fraction in which the numerator is the derivative of the denominator may be evaluated using

f (x) dx = ln f(x) + c.
f(x)

(2.32)

This follows directly from the diﬀerentiation of a logarithm as a function of a function (see subsection 2.1.3).

Evaluate the integral

6x2 + 2 cos x

I=

x3 + sin x dx.

We note ﬁrst that the numerator can be factorised to give 2(3x2 + cos x), and then that the quantity in brackets is the derivative of the denominator. Hence

I =2

3x2 x3

+ cos x + sin x

dx

=

2

ln(x3

+

sin

x)

+

c.

2.2.6 Integration using partial fractions
The method of partial fractions was discussed at some length in section 1.4, but in essence consists of the manipulation of a fraction (here the integrand) in such a way that it can be written as the sum of two or more simpler fractions. Again we illustrate the method by an example.
64

2.2 INTEGRATION

Evaluate the integral

1 I = x2 + x dx.

We note that the denominator factorises to give x(x + 1). Hence

1 I = x(x + 1) dx.

We now separate the fraction into two partial fractions and integrate directly:

I=

1 − 1 dx = ln x − ln(x + 1) + c = ln x + c.

x x+1

x+1

2.2.7 Integration by substitution
Sometimes it is possible to make a substitution of variables that turns a complicated integral into a simpler one, which can then be integrated by a standard method. There are many useful substitutions and knowing which to use is a matter of experience. We now present a few examples of particularly useful substitutions.

Evaluate the integral

I = √ 1 dx. 1 − x2

Making the substitution x = sin u, we note that dx = cos u du, and hence

I= √ 1

cos u du = √ 1 cos u du =

1 − sin2 u

cos2 u

Now substituting back for u,

I = sin−1 x + c.

du = u + c.

This corresponds to one of the results given in subsection 2.2.3.

Another particular example of integration by substitution is aﬀorded by integrals of the form

1

1

I=

dx or I =

dx.

a + b cos x

a + b sin x

(2.33)

In these cases, making the substitution t = tan(x/2) yields integrals that can be solved more easily than the originals. Formulae expressing sin x and cos x in terms of t were derived in equations (1.32) and (1.33) (see p. 14), but before we can use them we must relate dx to dt as follows.

65

PRELIMINARY CALCULUS

Since

dt = 1 sec2 x = 1

1 + tan2 x

1 + t2

=

,

dx 2 2 2

2

2

the required relationship is

2 dx = 1 + t2 dt.

(2.34)

Evaluate the integral

2

I=

dx.

1 + 3 cos x

Rewriting cos x in terms of t and using (2.34) yields

2

2

I = 1 + 3 (1 − t2)(1 + t2)−1 1 + t2 dt

2(1 + t2)

2

= 1 + t2 + 3(1 − t2) 1 + t2 dt

=

2 2 − t2 dt =

√ 2√

dt

( 2 − t)( 2 + t)

= √1 √ 1 + √ 1

dt

2 2−t 2+t

= − √1

√ ln( 2

−

t)

+

√1

√ ln( 2 + t) + c

2

2

√

= √1 ln √2 + tan (x/2) + c.

2

2 − tan (x/2)

Integrals of a similar form to (2.33), but involving sin 2x, cos 2x, tan 2x, sin2 x, cos2 x or tan2 x instead of cos x and sin x, should be evaluated by using the
substitution t = tan x. In this case

sin x = √ t , 1 + t2

cos x = √ 1 1 + t2

and

dt dx = 1 + t2 .

(2.35)

A ﬁnal example of the evaluation of integrals using substitution is the method of completing the square (cf. subsection 1.7.3).
66

2.2 INTEGRATION

Evaluate the integral

1 I = x2 + 4x + 7 dx.

We can write the integral in the form

1 I = (x + 2)2 + 3 dx.

Substituting y = x + 2, we ﬁnd dy = dx and hence

1 I = y2 + 3 dy,

Hence, by comparison with the table of standard integrals (see subsection 2.2.3)

√

√

I = 3 tan−1 √y + c = 3 tan−1 x√+ 2 + c.

3

3

3

3

2.2.8 Integration by parts

Integration by parts is the integration analogy of product diﬀerentiation. The principle is to break down a complicated function into two functions, at least one of which can be integrated by inspection. The method in fact relies on the result for the diﬀerentiation of a product. Recalling from (2.6) that

d (uv) = u dv + du v,

dx

dx dx

where u and v are functions of x, we now integrate to ﬁnd

uv = u dv dx + du v dx.

dx

dx

Rearranging into the standard form for integration by parts gives

u dv dx = uv − du v dx.

dx

dx

(2.36)

Integration by parts is often remembered for practical purposes in the form the integral of a product of two functions is equal to {the ﬁrst times the integral of the second} minus the integral of {the derivative of the ﬁrst times the integral of the second}. Here, u is ‘the ﬁrst’ and dv/dx is ‘the second’; clearly the integral v of ‘the second’ must be determinable by inspection.

Evaluate the integral I = x sin x dx.
In the notation given above, we identify x with u and sin x with dv/dx. Hence v = − cos x and du/dx = 1 and so using (2.36)
I = x(− cos x) − (1)(− cos x) dx = −x cos x + sin x + c.

67

PRELIMINARY CALCULUS

The separation of the functions is not always so apparent, as is illustrated by the following example.

Evaluate the integral I = x3e−x2 dx.

Firstly we rewrite the integral as I=

x2 xe−x2 dx.

Now, using the notation given above, we identify x2 with u and xe−x2 with dv/dx. Hence

v

=

−

1 2

e−x2

and

du/dx

=

2x,

so

that

I

=

−

1 2

x2

e−x2

−

(−x)e−x2

dx

=

−

1 2

x2e−x2

−

1 2

e−x2

+

c.

A trick that is sometimes useful is to take ‘1’ as one factor of the product, as is illustrated by the following example.

Evaluate the integral I = ln x dx.

Firstly we rewrite the integral as

I = (ln x) 1 dx.

Now, using the notation above, we identify ln x with u and 1 with dv/dx. Hence we have v = x and du/dx = 1/x, and so

I = (ln x)(x) −

1 x

x dx = x ln x − x + c.

It is sometimes necessary to integrate by parts more than once. In doing so, we may occasionally re-encounter the original integral I. In such cases we can obtain a linear algebraic equation for I that can be solved to obtain its value.

Evaluate the integral I = eax cos bx dx.

Integrating by parts, taking eax as the ﬁrst function, we ﬁnd

I = eax sin bx − aeax sin bx dx,

b

b

where, for convenience, we have omitted the constant of integration. Integrating by parts a second time,

I = eax

sin bx b

− aeax

− cos bx b2

+

a2eax

− cos bx b2

dx.

Notice that the integral on the RHS is just −a2/b2 times the original integral I. Thus

I = eax

1

a

b sin bx + b2 cos bx

−

a2 b2

I.

68

2.2 INTEGRATION

Rearranging this expression to obtain I explicitly and including the constant of integration

we ﬁnd

eax I = a2 + b2 (b sin bx + a cos bx) + c.

(2.37)

Another method of evaluating this integral, using the exponential of a complex number, is given in section 3.6.

2.2.9 Reduction formulae
Integration using reduction formulae is a process that involves ﬁrst evaluating a simple integral and then, in stages, using it to ﬁnd a more complicated integral.

Using integration by parts, ﬁnd a relationship between In and In−1 where

1
In = (1 − x3)n dx
0

and n is any positive integer. Hence evaluate I2 =

1 0

(1

−

x3

)2

dx.

Writing the integrand as a product and separating the integral into two we ﬁnd

In = =

1
(1 − x3)(1 − x3)n−1 dx

0

1

1

(1 − x3)n−1 dx − x3(1 − x3)n−1 dx.

0

0

The ﬁrst term on the RHS is clearly In−1 and so, writing the integrand in the second term on the RHS as a product,

1
In = In−1 − (x)x2(1 − x3)n−1 dx.
0
Integrating by parts we ﬁnd

In = In−1 +

x

(1 − x3)n

1
−

3n

0

1 1 (1 − x3)n dx 0 3n

=

In−1

+

0

−

1 3n In,

which on rearranging gives

3n In = 3n + 1 In−1.

We now have a relation connecting successive integrals. Hence, if we can evaluate I0, we can ﬁnd I1, I2 etc. Evaluating I0 is trivial:

Hence

1

1

I0 = (1 − x3)0 dx = dx = [x]10 = 1.

0

0

I1

=

(3 × 1) (3 × 1) + 1

×1

=

3 4,

I2

=

(3 × 2) (3 × 2) +

1

×

3 4

=

9 14 .

Although the ﬁrst few In could be evaluated by direct multiplication, this becomes tedious for integrals containing higher values of n; these are therefore best evaluated using the reduction formula.

69

PRELIMINARY CALCULUS

2.2.10 Inﬁnite and improper integrals

The deﬁnition of an integral given previously does not allow for cases in which

either of the limits of integration is inﬁnite (an inﬁnite integral) or for cases

in which f(x) is inﬁnite in some part of the range (an improper integral), e.g. f(x) = (2 − x)−1/4 near the point x = 2. Nevertheless, modiﬁcation of the

deﬁnition of an integral gives inﬁnite and improper integrals each a meaning.

In the case of an integral I =

b a

f(x)

dx,

the

inﬁnite

integral,

in

which

b

tends

to ∞, is deﬁned by

∞

b

I = f(x) dx = lim f(x) dx = lim F(b) − F(a).

a

b→∞ a

b→∞

As previously, F(x) is the indeﬁnite integral of f(x) and limb→∞ F(b) means the limit (or value) that F(b) approaches as b → ∞; it is evaluated after calculating
the integral. The formal concept of a limit will be introduced in chapter 4.

Evaluate the integral

∞

x

I=
0

(x2 + a2)2 dx.

Integrating,

we

ﬁnd

F (x)

=

−

1 2

(x2

+

a2)−1

+

c

and

so

I = lim b→∞

−1 2(b2 + a2)

−

−1 2a2

1 = 2a2 .

For the case of improper integrals, we adopt the approach of excluding the unbounded range from the integral. For example, if the integrand f(x) is inﬁnite at x = c (say), a ≤ c ≤ b then

b

c−δ

b

f(x) dx = lim

f(x) dx + lim f(x) dx.

a

δ→0 a

→0 c+

Evaluate the integral I = 02(2 − x)−1/4 dx.

Integrating directly,

I = lim →0

−

4 3

(2

−

x)3/4

2− 0

= lim →0

−

4 3

3/4

+

4 3

23/4

=

4 3

23/4.

2.2.11 Integration in plane polar coordinates In plane polar coordinates ρ, φ, a curve is deﬁned by its distance ρ from the origin as a function of the angle φ between the line joining a point on the curve to the origin and the x-axis, i.e. ρ = ρ(φ). The area of an element is given by
70

